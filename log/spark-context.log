[34m[INFO ][0;39m [35m[2019-05-02 11:04:21,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running Spark version 2.4.0
[31m[WARN ][0;39m [35m[2019-05-02 11:04:21,724][0;39m [33m[][0;39m [35m[org.apache.hadoop.util.NativeCodeLoader-><clinit>][0;39m | Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[34m[INFO ][0;39m [35m[2019-05-02 11:04:21,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitted application: Spark Structured Streaming Job
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eiti); groups with view permissions: Set(); users  with modify permissions: Set(eiti); groups with modify permissions: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'sparkDriver' on port 55121.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering MapOutputTracker
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManagerMaster
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMasterEndpoint up
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created local directory at /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/blockmgr-cf916a74-1845-4ce1-9dfc-968370a74bf9
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore started with capacity 912.3 MB
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering OutputCommitCoordinator
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'SparkUI' on port 4040.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:22,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Bound SparkUI to 0.0.0.0, and started at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting executor ID driver on host localhost
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55122.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Server created on mac-180:55122
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManager BlockManagerId(driver, mac-180, 55122, None)
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering block manager mac-180:55122 with 912.3 MB RAM, BlockManagerId(driver, mac-180, 55122, None)
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered BlockManager BlockManagerId(driver, mac-180, 55122, None)
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Initialized BlockManager: BlockManagerId(driver, mac-180, 55122, None)
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/').
[34m[INFO ][0;39m [35m[2019-05-02 11:04:23,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Warehouse path is 'file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/'.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:24,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered StateStoreCoordinator endpoint
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting [id = eeb06daf-41d7-4c11-830a-51392556e50b, runId = dfd1489f-ab85-4006-996b-815ebec09125]. Use file:///private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502 to store the query checkpoint.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Set the compact interval to 10 [defaultCompactInterval: 10]
[31m[WARN ][0;39m [35m[2019-05-02 11:04:27,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logWarning][0;39m | 'latestFirst' is true. New files will be processed first, which may affect the watermark
value. In addition, 'maxFileAge' will be ignored.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | maxFilesPerBatch = None, maxFileAgeMs = 604800000
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using Source [FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]] from DataSourceV1 named 'FileSource[/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]' [DataSource(org.apache.spark.sql.SparkSession@4b3a01d8,csv,List(),Some(StructType(StructField(name,StringType,true), StructField(country,StringType,true), StructField(city,StringType,true), StructField(phone,StringType,true), StructField(age,IntegerType,true), StructField(carrier,StringType,true), StructField(marital_status,StringType,true))),List(),None,Map(delimiter -> ;, latestFirst -> true, header -> true, path -> /Users/eiti/git-repository/structured-streaming/dataset/stream_in/*),None)]
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting new streaming query.
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Stream started from {}
[34m[INFO ][0;39m [35m[2019-05-02 11:04:27,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:04:27.330Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 13,
    "triggerExecution" : 27
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:04:38,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:04:38.004Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 5,
    "triggerExecution" : 5
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:04:50,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:04:50.002Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 4,
    "triggerExecution" : 4
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:05:00,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:00.003Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 5,
    "triggerExecution" : 5
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:05:12,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:12.005Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 3,
    "triggerExecution" : 3
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:05:24,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:24.005Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 3,
    "triggerExecution" : 4
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:05:36,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:36.004Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 3,
    "triggerExecution" : 4
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/0 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.0.f34779ed-de6a-4d28-8f27-48d9296bd342.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.0.f34779ed-de6a-4d28-8f27-48d9296bd342.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Log offset set to 0 with 1 new files
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/0 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.0.9ceb10bb-bf71-4df7-ab41-33647081da25.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.0.9ceb10bb-bf71-4df7-ab41-33647081da25.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1556805938390,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Processing 1 files from 0:0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<carrier: string, marital_status: string>
[34m[INFO ][0;39m [35m[2019-05-02 11:05:38,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:05:39,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 293.837545 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:39,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 71.602776 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:39,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 84.883559 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:39,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 62.880425 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:39,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 59.072707 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0 stored as values in memory (estimated size 221.7 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_0_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 0 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1 stored as values in memory (estimated size 220.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_1_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 1 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2 stored as values in memory (estimated size 220.7 KB, free 911.6 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.6 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_2_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 2 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@164ac59c. The input RDD has 200 partitions.
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering RDD 2 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 0 (start at StreamingFile.scala:61) with 200 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 1 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List(ShuffleMapStage 0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List(ShuffleMapStage 0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_3 stored as values in memory (estimated size 28.1 KB, free 911.6 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.6 KB, free 911.6 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_3_piece0 in memory on mac-180:55122 (size: 13.6 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 3 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0))
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 0.0 with 1 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:40,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8357 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 0.0 (TID 0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 9.407817 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 8.614034 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 9.712167 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 16.854098 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/stream_in/user-record.1.csv, range: 0-6730, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,407][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 0.0 (TID 0). 2395 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 0.0 (TID 0) in 434 ms on localhost (executor driver) (1/1)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 0.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ShuffleMapStage 0 (start at StreamingFile.scala:61) finished in 0,512 s
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | looking for newly runnable stages
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | running: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | waiting: Set(ResultStage 1)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | failed: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 1 (MapPartitionsRDD[8] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_4 stored as values in memory (estimated size 55.6 KB, free 911.5 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.5 KB, free 911.5 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_4_piece0 in memory on mac-180:55122 (size: 23.5 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,527][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 4 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 200 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 1.0 with 200 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 1.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 1.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 4.0 in stage 1.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 1.0 (TID 2)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 1.0 (TID 1)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 4.0 in stage 1.0 (TID 4)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 1.0 (TID 3)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | State Store maintenance task started
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fe3b2a7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29ec52a4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55a072e3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33836c07
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b1b0039
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58986a5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60befd68
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655b1252
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.1.delta.eb4f7abd-e0f2-47e4-a3f3-07d8c5e3f41a.TID3.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.1.delta.a70bfa9a-afcf-42ad-8663-7534aa29c628.TID2.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.1.delta.d80a059e-c487-45af-bfcc-1f6eaea1e75c.TID4.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.1.delta.3eea3f8a-797b-46e6-84d0-6cb628947798.TID1.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.1.delta.eb4f7abd-e0f2-47e4-a3f3-07d8c5e3f41a.TID3.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.1.delta.a70bfa9a-afcf-42ad-8663-7534aa29c628.TID2.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.1.delta.d80a059e-c487-45af-bfcc-1f6eaea1e75c.TID4.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.1.delta.3eea3f8a-797b-46e6-84d0-6cb628947798.TID1.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 3 (task 3, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 4 (task 4, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 2 (task 2, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 4 (task 4, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 2 (task 2, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 3 (task 3, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 1 (task 1, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 1 (task 1, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.1.delta.af4d712d-5687-4fba-9e48-43aafeaf68d5.TID3.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.1.delta.2bb12831-47fc-465f-8f86-397182524087.TID2.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.1.delta.0d612da2-1d03-430e-80ef-66f1e5ffe013.TID4.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.1.delta.4206995e-9bdf-450e-a3f5-2514b9acf015.TID1.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 3). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 2). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 5.0 in stage 1.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 3) in 435 ms on localhost (executor driver) (1/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 5.0 in stage 1.0 (TID 5)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 6.0 in stage 1.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 1.0 (TID 4). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 2) in 438 ms on localhost (executor driver) (2/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 6.0 in stage 1.0 (TID 6)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 7.0 in stage 1.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 1.0 (TID 4) in 438 ms on localhost (executor driver) (3/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 7.0 in stage 1.0 (TID 7)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 1). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 8.0 in stage 1.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 8.0 in stage 1.0 (TID 8)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:41,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 1) in 454 ms on localhost (executor driver) (4/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc3f80
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@142741fa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e8f85bf
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5593188f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aa390cf
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bbb2ca8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@756a2aa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53d0424c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.1.delta.9c347165-690a-4ac6-b0ed-12868aca44c0.TID6.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.1.delta.36c8ff6c-91c7-45a5-940e-ee1384d3714e.TID7.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.1.delta.0d7bfc6f-b5e2-4d6d-87fd-920e7a22ed27.TID8.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.1.delta.5b070b2c-d1b1-4dfe-86de-6f73f465f4ea.TID5.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.1.delta.0d7bfc6f-b5e2-4d6d-87fd-920e7a22ed27.TID8.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.1.delta.9c347165-690a-4ac6-b0ed-12868aca44c0.TID6.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 6 (task 6, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 8 (task 8, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 6 (task 6, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 8 (task 8, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.1.delta.5b070b2c-d1b1-4dfe-86de-6f73f465f4ea.TID5.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 5 (task 5, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 5 (task 5, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.1.delta.36c8ff6c-91c7-45a5-940e-ee1384d3714e.TID7.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 7 (task 7, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 7 (task 7, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.1.delta.38f199d1-3243-4531-b568-670db8471204.TID6.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.1.delta.6e100c74-bab7-4374-9e7b-c1a254ac9ba2.TID8.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 1.0 (TID 8). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 1.0 (TID 6). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 9.0 in stage 1.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 1.0 (TID 8) in 418 ms on localhost (executor driver) (5/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,407][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 9.0 in stage 1.0 (TID 9)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 10.0 in stage 1.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 1.0 (TID 6) in 442 ms on localhost (executor driver) (6/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 10.0 in stage 1.0 (TID 10)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.1.delta.a8c6f24a-1f1e-4a1f-b24a-0e97bc691e79.TID7.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.1.delta.b324a7bf-744a-428a-b4d6-57fe31874895.TID5.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 1.0 (TID 7). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 11.0 in stage 1.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 11.0 in stage 1.0 (TID 11)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 1.0 (TID 7) in 458 ms on localhost (executor driver) (7/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 1.0 (TID 5). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 12.0 in stage 1.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 1.0 (TID 5) in 467 ms on localhost (executor driver) (8/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 12.0 in stage 1.0 (TID 12)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55573e33
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11e4f97
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@544d1b1c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@738882a8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51425c2f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10793b4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b90dae9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a2c3ea8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.1.delta.59f2e93e-9a93-4e3c-89eb-2c2512c50074.TID11.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.1.delta.599577fd-1757-42c4-ac72-2361ad5c832f.TID12.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.1.delta.41f461b6-b2d7-4623-9870-c804ab983db2.TID9.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.1.delta.7a94f7b6-e11a-4152-a92d-3bc53c6c2d18.TID10.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.1.delta.41f461b6-b2d7-4623-9870-c804ab983db2.TID9.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.1.delta.59f2e93e-9a93-4e3c-89eb-2c2512c50074.TID11.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.1.delta.599577fd-1757-42c4-ac72-2361ad5c832f.TID12.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 9 (task 9, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 11 (task 11, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 9 (task 9, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 11 (task 11, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 12 (task 12, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 12 (task 12, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.1.delta.7a94f7b6-e11a-4152-a92d-3bc53c6c2d18.TID10.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 10 (task 10, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 10 (task 10, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.1.delta.81304319-6d63-4c7e-968d-8bc91c2b70eb.TID9.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.1.delta.1d8d5982-6957-46b9-9fd6-41ae07d0de50.TID11.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.1.delta.6338ba3c-b517-4ad8-86d5-7213d07a7f70.TID12.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:42,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.1.delta.333fea8f-8592-477e-919b-b81f78c22ad6.TID10.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 1.0 (TID 9). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 1.0 (TID 12). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 13.0 in stage 1.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 1.0 (TID 12) in 573 ms on localhost (executor driver) (9/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 1.0 (TID 10). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 14.0 in stage 1.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 15.0 in stage 1.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 1.0 (TID 9) in 612 ms on localhost (executor driver) (10/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 13.0 in stage 1.0 (TID 13)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 1.0 (TID 10) in 608 ms on localhost (executor driver) (11/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 1.0 (TID 11). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 14.0 in stage 1.0 (TID 14)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 15.0 in stage 1.0 (TID 15)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 16.0 in stage 1.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 1.0 (TID 11) in 588 ms on localhost (executor driver) (12/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed broadcast_3_piece0 on mac-180:55122 in memory (size: 13.6 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 16.0 in stage 1.0 (TID 16)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f8928
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@218cda40
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@400be8a7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3820c8ad
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b606494
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.1.delta.fcdc8065-4289-4f3e-b832-ded11b05e40b.TID14.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77e460b0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ad2493a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c6f2f4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.1.delta.cddec500-4846-44a7-9aab-88a9b96d125e.TID16.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.1.delta.dc11ea8b-2d7c-410c-86ac-c91264247a2f.TID13.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.1.delta.24023a6c-dc09-4f4c-80c0-e6f097c555b5.TID15.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.1.delta.fcdc8065-4289-4f3e-b832-ded11b05e40b.TID14.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 14 (task 14, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 14 (task 14, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.1.delta.cddec500-4846-44a7-9aab-88a9b96d125e.TID16.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 16 (task 16, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 16 (task 16, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.1.delta.ac5fbbae-34a4-4a7d-9147-4b5fda91cc7c.TID14.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 1.0 (TID 14). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,299][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 17.0 in stage 1.0 (TID 17, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 17.0 in stage 1.0 (TID 17)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 1.0 (TID 14) in 288 ms on localhost (executor driver) (13/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.1.delta.dc11ea8b-2d7c-410c-86ac-c91264247a2f.TID13.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 13 (task 13, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 13 (task 13, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.1.delta.61a60cb6-a193-4181-b33b-ee105e9da0c4.TID16.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.1.delta.24023a6c-dc09-4f4c-80c0-e6f097c555b5.TID15.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 1.0 (TID 16). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 18.0 in stage 1.0 (TID 18, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 1.0 (TID 16) in 308 ms on localhost (executor driver) (14/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 18.0 in stage 1.0 (TID 18)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 15 (task 15, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 15 (task 15, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74fb40bb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.1.delta.d6ab2c9e-2a3e-4ca2-bf91-e19a029664ca.TID13.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 1.0 (TID 13). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 20.0 in stage 1.0 (TID 19, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 20.0 in stage 1.0 (TID 19)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 1.0 (TID 13) in 351 ms on localhost (executor driver) (15/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502e3aaf
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67b6998a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.1.delta.cef12abe-2c0b-481f-9772-84fd9bdd2fef.TID15.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 1.0 (TID 15). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 21.0 in stage 1.0 (TID 20, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 1.0 (TID 15) in 432 ms on localhost (executor driver) (16/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 21.0 in stage 1.0 (TID 20)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d38d5c8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437b516a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2586b816
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f6ecdef
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@291f3d7e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.1.delta.7b79995b-ea86-4a64-b1d5-97e118c083df.TID17.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.1.delta.56439768-ca46-4af5-a782-9ec2c10912dd.TID18.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.1.delta.890d1fc4-6441-4136-82c5-65e7c2c8bb49.TID19.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.1.delta.930af7b2-d9e5-46cc-b1aa-dfff080e4d60.TID20.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.1.delta.7b79995b-ea86-4a64-b1d5-97e118c083df.TID17.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 17 (task 17, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 17 (task 17, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.1.delta.56439768-ca46-4af5-a782-9ec2c10912dd.TID18.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 18 (task 18, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 18 (task 18, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.1.delta.890d1fc4-6441-4136-82c5-65e7c2c8bb49.TID19.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 20 (task 19, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 20 (task 19, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.1.delta.eee7fcd3-121c-4ab6-9cbd-131af1e3ec31.TID17.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 1.0 (TID 17). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 22.0 in stage 1.0 (TID 21, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 1.0 (TID 17) in 451 ms on localhost (executor driver) (17/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 22.0 in stage 1.0 (TID 21)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.1.delta.930af7b2-d9e5-46cc-b1aa-dfff080e4d60.TID20.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 21 (task 20, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 21 (task 20, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.1.delta.6c0b24be-1dfe-4fd3-9398-333d18e383a2.TID18.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,762][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 1.0 (TID 18). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 23.0 in stage 1.0 (TID 22, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 1.0 (TID 18) in 441 ms on localhost (executor driver) (18/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 23.0 in stage 1.0 (TID 22)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.1.delta.55446c99-aa36-4d21-8f18-b476867ff575.TID19.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 1.0 (TID 19). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 24.0 in stage 1.0 (TID 23, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 1.0 (TID 19) in 417 ms on localhost (executor driver) (19/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 24.0 in stage 1.0 (TID 23)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1401a159
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.1.delta.0e5d37d6-e3a2-476e-89b9-8101c4f71ee6.TID20.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 1.0 (TID 20). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 25.0 in stage 1.0 (TID 24, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 1.0 (TID 20) in 432 ms on localhost (executor driver) (20/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 25.0 in stage 1.0 (TID 24)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1301feb9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a73bee4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20fa669d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:43,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d6798ce
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c96de95
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ead5354
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.1.delta.06baaa77-e66c-4821-96a2-166e0d6b6890.TID22.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65286b4c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.1.delta.16d02406-8d54-4d49-936b-20cdda89a011.TID21.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.1.delta.7f85c0e0-ed47-4438-9561-4ae97f063be6.TID23.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.1.delta.c9f8f2ff-f0fd-4d33-8a42-ad618d1cac34.TID24.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.1.delta.06baaa77-e66c-4821-96a2-166e0d6b6890.TID22.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 23 (task 22, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 23 (task 22, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.1.delta.16d02406-8d54-4d49-936b-20cdda89a011.TID21.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 22 (task 21, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 22 (task 21, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.1.delta.244ee151-d800-49fa-89b3-5cd084010872.TID22.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 1.0 (TID 22). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 26.0 in stage 1.0 (TID 25, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 1.0 (TID 22) in 496 ms on localhost (executor driver) (21/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 26.0 in stage 1.0 (TID 25)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.1.delta.7f85c0e0-ed47-4438-9561-4ae97f063be6.TID23.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 24 (task 23, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 24 (task 23, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.1.delta.c9f8f2ff-f0fd-4d33-8a42-ad618d1cac34.TID24.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,299][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.1.delta.228ddcc6-ebef-4a8f-8298-01b0a8492044.TID21.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 1.0 (TID 21). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 25 (task 24, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 27.0 in stage 1.0 (TID 26, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 25 (task 24, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 1.0 (TID 21) in 555 ms on localhost (executor driver) (22/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 27.0 in stage 1.0 (TID 26)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fa4ca31
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.1.delta.726ed119-dc53-45fc-9c23-f9999d2154ff.TID23.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 1.0 (TID 23). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 28.0 in stage 1.0 (TID 27, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 1.0 (TID 23) in 550 ms on localhost (executor driver) (23/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 28.0 in stage 1.0 (TID 27)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@623788ac
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.1.delta.fc7a1b48-8a7c-49b7-ba05-c508e5c9f085.TID24.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 1.0 (TID 24). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 29.0 in stage 1.0 (TID 28, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 1.0 (TID 24) in 471 ms on localhost (executor driver) (24/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 29.0 in stage 1.0 (TID 28)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ef75048
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a9a3fd2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1be06813
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b29d2e7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cdb577c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77f19b1c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.1.delta.9e65e0f9-a5fc-4eef-bc72-60e849667ed3.TID25.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.1.delta.d4883872-6f60-47b1-8158-5982813b16f5.TID27.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.1.delta.77e60f75-9060-4cd3-840b-5201f86e6dc1.TID28.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.1.delta.8dbf67e7-9e54-4f92-86b6-d0be88c1a10e.TID26.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.1.delta.d4883872-6f60-47b1-8158-5982813b16f5.TID27.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 28 (task 27, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 28 (task 27, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.1.delta.9e65e0f9-a5fc-4eef-bc72-60e849667ed3.TID25.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 26 (task 25, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 26 (task 25, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.1.delta.77e60f75-9060-4cd3-840b-5201f86e6dc1.TID28.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.1.delta.8dbf67e7-9e54-4f92-86b6-d0be88c1a10e.TID26.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 29 (task 28, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 29 (task 28, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 27 (task 26, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 27 (task 26, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.1.delta.800d1cf1-70e5-4dcd-94cf-b3c0536ceda5.TID27.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 1.0 (TID 27). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 31.0 in stage 1.0 (TID 29, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 31.0 in stage 1.0 (TID 29)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 1.0 (TID 27) in 254 ms on localhost (executor driver) (25/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.1.delta.dd29aed5-80e9-4f3e-8c44-cce97d261694.TID25.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 1.0 (TID 25). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 32.0 in stage 1.0 (TID 30, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 1.0 (TID 25) in 329 ms on localhost (executor driver) (26/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 32.0 in stage 1.0 (TID 30)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3feb2103
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.1.delta.a104ea3c-7d51-4dfe-8673-885eb9902c9f.TID26.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 1.0 (TID 26). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 33.0 in stage 1.0 (TID 31, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 33.0 in stage 1.0 (TID 31)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 1.0 (TID 26) in 316 ms on localhost (executor driver) (27/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.1.delta.fda8e0e3-7117-4c2b-99ca-184663c6f71e.TID28.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 1.0 (TID 28). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 34.0 in stage 1.0 (TID 32, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 1.0 (TID 28) in 284 ms on localhost (executor driver) (28/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 34.0 in stage 1.0 (TID 32)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e8c2e8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@208e65a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e483db9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c1af50e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52ad2493
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@220da22d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75be51c3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.1.delta.3394cda2-8438-4112-8b9e-9c7838c582e1.TID30.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.1.delta.f6b13cde-da51-4749-8342-cf0a65418361.TID29.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.1.delta.55a4cc21-455b-4231-a19d-357974128d66.TID32.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.1.delta.2a65050a-afd2-4954-a164-7b025478bd66.TID31.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.1.delta.f6b13cde-da51-4749-8342-cf0a65418361.TID29.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 31 (task 29, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 31 (task 29, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.1.delta.2a65050a-afd2-4954-a164-7b025478bd66.TID31.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.1.delta.3394cda2-8438-4112-8b9e-9c7838c582e1.TID30.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 33 (task 31, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 33 (task 31, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 32 (task 30, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:44,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 32 (task 30, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.1.delta.55a4cc21-455b-4231-a19d-357974128d66.TID32.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 34 (task 32, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 34 (task 32, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.1.delta.794cbe32-5fe0-4e0d-a5ac-16ad18b4bcdc.TID29.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 1.0 (TID 29). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 35.0 in stage 1.0 (TID 33, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 1.0 (TID 29) in 451 ms on localhost (executor driver) (29/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 35.0 in stage 1.0 (TID 33)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.1.delta.1f9e5c23-7da5-4bb2-a8cb-056c4796c5a4.TID31.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.1.delta.49f65831-0334-4dc8-99ad-ff46ab071df5.TID30.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 1.0 (TID 31). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 36.0 in stage 1.0 (TID 34, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 1.0 (TID 31) in 480 ms on localhost (executor driver) (30/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 36.0 in stage 1.0 (TID 34)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 1.0 (TID 30). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 37.0 in stage 1.0 (TID 35, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 1.0 (TID 30) in 513 ms on localhost (executor driver) (31/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 37.0 in stage 1.0 (TID 35)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a20f566
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.1.delta.6705ffec-6ce9-485f-a05d-730970bc2fc3.TID32.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 1.0 (TID 32). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 38.0 in stage 1.0 (TID 36, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 38.0 in stage 1.0 (TID 36)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 1.0 (TID 32) in 496 ms on localhost (executor driver) (32/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@170cf7aa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b4e0e4a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f5f6756
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1204b7b5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67a0a010
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@180e2ef5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bf49798
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.1.delta.c753b3ef-3b7a-4c5b-aa52-33a4af862673.TID35.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.1.delta.c710b60c-f247-4014-8863-d7cf7e412de9.TID36.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.1.delta.33b56ee4-0ddb-4bb1-bafc-33d8d9a2b4f0.TID34.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.1.delta.db480e07-7423-41ed-9574-d414ddc8bcfa.TID33.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.1.delta.c753b3ef-3b7a-4c5b-aa52-33a4af862673.TID35.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.1.delta.c710b60c-f247-4014-8863-d7cf7e412de9.TID36.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 37 (task 35, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 37 (task 35, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 38 (task 36, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 38 (task 36, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.1.delta.33b56ee4-0ddb-4bb1-bafc-33d8d9a2b4f0.TID34.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 36 (task 34, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 36 (task 34, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.1.delta.db480e07-7423-41ed-9574-d414ddc8bcfa.TID33.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 35 (task 33, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 35 (task 33, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.1.delta.03d61c32-8e63-4d2d-8421-f866a0ac5bf8.TID34.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.1.delta.b4f5f98b-4d87-4a51-945e-b40d40d17d9d.TID36.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.1.delta.313d1e96-dda6-46cd-b8dc-e532283fe315.TID35.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 1.0 (TID 34). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 1.0 (TID 36). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 39.0 in stage 1.0 (TID 37, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 40.0 in stage 1.0 (TID 38, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 39.0 in stage 1.0 (TID 37)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 1.0 (TID 36) in 322 ms on localhost (executor driver) (33/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 40.0 in stage 1.0 (TID 38)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 1.0 (TID 34) in 349 ms on localhost (executor driver) (34/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 1.0 (TID 35). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 41.0 in stage 1.0 (TID 39, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 41.0 in stage 1.0 (TID 39)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 1.0 (TID 35) in 351 ms on localhost (executor driver) (35/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.1.delta.cef0849f-5a1e-44d5-8c2c-79a3e679b5de.TID33.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 1.0 (TID 33). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 42.0 in stage 1.0 (TID 40, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 1.0 (TID 33) in 436 ms on localhost (executor driver) (36/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 42.0 in stage 1.0 (TID 40)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33731ba7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73cefd2c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e76478
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@640a762a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f21247c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,516][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,516][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.1.delta.47c477e3-126e-4fd9-8501-0b5e9d7881d6.TID37.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c4c9f60
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46901af4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@940d2e4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.1.delta.d778ce92-98d0-4757-a5be-f1df4a7ab2ca.TID39.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.1.delta.3a294dfe-7f7c-417d-a984-9a7e6ac643b6.TID38.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.1.delta.1850c535-a414-4563-9c8a-793b86684337.TID40.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.1.delta.47c477e3-126e-4fd9-8501-0b5e9d7881d6.TID37.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 39 (task 37, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 39 (task 37, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.1.delta.d778ce92-98d0-4757-a5be-f1df4a7ab2ca.TID39.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 41 (task 39, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 41 (task 39, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.1.delta.abb941f3-6015-45d9-a30f-ea84ea0f302a.TID37.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 1.0 (TID 37). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 43.0 in stage 1.0 (TID 41, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 1.0 (TID 37) in 302 ms on localhost (executor driver) (37/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 43.0 in stage 1.0 (TID 41)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.1.delta.1850c535-a414-4563-9c8a-793b86684337.TID40.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.1.delta.3a294dfe-7f7c-417d-a984-9a7e6ac643b6.TID38.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 42 (task 40, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 42 (task 40, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 40 (task 38, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 40 (task 38, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2377803f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@498a3892
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.1.delta.0d140e04-4f52-4ca0-bf6d-740ddb44434d.TID39.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 1.0 (TID 39). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 44.0 in stage 1.0 (TID 42, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 1.0 (TID 39) in 336 ms on localhost (executor driver) (38/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 44.0 in stage 1.0 (TID 42)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.1.delta.1db7a2ad-f70d-4af4-917b-ef43391dbb46.TID38.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.1.delta.b9e91d70-3921-4c94-a1e8-b68577c6ce0c.TID40.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 1.0 (TID 38). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 45.0 in stage 1.0 (TID 43, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 45.0 in stage 1.0 (TID 43)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 1.0 (TID 38) in 369 ms on localhost (executor driver) (39/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab9d00
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70746b45
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 1.0 (TID 40). 5065 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 47.0 in stage 1.0 (TID 44, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 1.0 (TID 40) in 359 ms on localhost (executor driver) (40/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 47.0 in stage 1.0 (TID 44)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.1.delta.46986076-038f-485d-bbd0-6cecedb84824.TID41.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e265cb1
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23310d48
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d8924fc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@694766b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.1.delta.bd1bf77e-c0ce-40a2-8bcd-f7bedaff3695.TID42.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.1.delta.fc23c1a5-700d-4134-8e62-2c7818025130.TID43.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.1.delta.46986076-038f-485d-bbd0-6cecedb84824.TID41.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 43 (task 41, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 43 (task 41, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.1.delta.11700bc4-5598-4d2a-812e-2c7d42fb7795.TID44.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.1.delta.bd1bf77e-c0ce-40a2-8bcd-f7bedaff3695.TID42.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 44 (task 42, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 44 (task 42, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.1.delta.e7817841-e2fe-41af-8ef3-6f7442d3c04c.TID41.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 1.0 (TID 41). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 48.0 in stage 1.0 (TID 45, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 1.0 (TID 41) in 235 ms on localhost (executor driver) (41/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:45,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 48.0 in stage 1.0 (TID 45)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55b35b54
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40fafb89
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.1.delta.fc23c1a5-700d-4134-8e62-2c7818025130.TID43.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.1.delta.11700bc4-5598-4d2a-812e-2c7d42fb7795.TID44.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 45 (task 43, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 45 (task 43, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 47 (task 44, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 47 (task 44, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.1.delta.2f38d129-7ff2-4335-a075-ee0fb2762cff.TID42.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 1.0 (TID 42). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 49.0 in stage 1.0 (TID 46, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 1.0 (TID 42) in 242 ms on localhost (executor driver) (42/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 49.0 in stage 1.0 (TID 46)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@460beb85
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f6a667f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.1.delta.d08d7a58-f8a2-4c85-b06e-5f2daa382fed.TID43.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 1.0 (TID 43). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.1.delta.134f78ce-bb3c-473a-a7f5-97e41fa64630.TID44.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 50.0 in stage 1.0 (TID 47, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 1.0 (TID 43) in 257 ms on localhost (executor driver) (43/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 50.0 in stage 1.0 (TID 47)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 1.0 (TID 44). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 51.0 in stage 1.0 (TID 48, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 1.0 (TID 44) in 253 ms on localhost (executor driver) (44/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 51.0 in stage 1.0 (TID 48)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.1.delta.ea1e47ab-4c63-42bb-8f97-ead269d19e0f.TID45.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e5c5636
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@da154b2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.1.delta.d948dae4-7359-4f82-8a8b-ae7e4a86a8a3.TID46.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10f03350
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54f563d3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.1.delta.ea1e47ab-4c63-42bb-8f97-ead269d19e0f.TID45.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 48 (task 45, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 48 (task 45, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.1.delta.b0cc25dd-3782-43b3-8994-73452ff5c6db.TID48.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.1.delta.15ce6e2b-5e89-4f1d-bca1-0917743b910d.TID47.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.1.delta.d948dae4-7359-4f82-8a8b-ae7e4a86a8a3.TID46.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.1.delta.3c40a9e5-db8a-4680-9575-8d9be6456424.TID45.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 49 (task 46, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 1.0 (TID 45). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 49 (task 46, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 52.0 in stage 1.0 (TID 49, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 1.0 (TID 45) in 337 ms on localhost (executor driver) (45/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 52.0 in stage 1.0 (TID 49)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ccb6acb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13fb0b87
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.1.delta.55921eb2-912d-4eb1-8089-4adbad27c50d.TID46.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 1.0 (TID 46). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.1.delta.15ce6e2b-5e89-4f1d-bca1-0917743b910d.TID47.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 53.0 in stage 1.0 (TID 50, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 53.0 in stage 1.0 (TID 50)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 1.0 (TID 46) in 340 ms on localhost (executor driver) (46/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 50 (task 47, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 50 (task 47, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.1.delta.b0cc25dd-3782-43b3-8994-73452ff5c6db.TID48.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 51 (task 48, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 51 (task 48, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a7e5fee
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39018a85
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.1.delta.e4d9bdf7-7374-4d1a-91d4-7f932d7b9a89.TID49.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.1.delta.6bcdd904-0be5-4553-868c-449835cc89e8.TID47.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 1.0 (TID 47). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 54.0 in stage 1.0 (TID 51, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 54.0 in stage 1.0 (TID 51)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 1.0 (TID 47) in 355 ms on localhost (executor driver) (47/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.1.delta.a94d5f39-a64d-410f-b71d-b9ea138a1f76.TID48.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 1.0 (TID 48). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 55.0 in stage 1.0 (TID 52, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 1.0 (TID 48) in 360 ms on localhost (executor driver) (48/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 55.0 in stage 1.0 (TID 52)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@737566d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.1.delta.a2f67383-b76f-483d-97ee-f7de5b342c84.TID50.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63c51c73
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d9432e2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@166438e6
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.1.delta.e4d9bdf7-7374-4d1a-91d4-7f932d7b9a89.TID49.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 52 (task 49, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 52 (task 49, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.1.delta.593665f6-85b2-4aaa-b8f1-21bd7e1428ea.TID52.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.1.delta.ced968f2-f6bd-4034-a8a5-b7539edabfac.TID51.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.1.delta.a2f67383-b76f-483d-97ee-f7de5b342c84.TID50.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 53 (task 50, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 53 (task 50, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.1.delta.990e5223-9080-48bb-ab6e-b7141666b38a.TID49.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 1.0 (TID 49). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 57.0 in stage 1.0 (TID 53, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 1.0 (TID 49) in 249 ms on localhost (executor driver) (49/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 57.0 in stage 1.0 (TID 53)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@636eaeef
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59d14a88
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.1.delta.6f25631f-31cb-44cd-b2b9-a09e1a1e6bd8.TID50.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 1.0 (TID 50). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 58.0 in stage 1.0 (TID 54, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 1.0 (TID 50) in 248 ms on localhost (executor driver) (50/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 58.0 in stage 1.0 (TID 54)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.1.delta.ced968f2-f6bd-4034-a8a5-b7539edabfac.TID51.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 54 (task 51, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 54 (task 51, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3912e049
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63444b74
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.1.delta.4a41255c-fab9-4a10-b0c6-9fee0eb7340e.TID53.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.1.delta.858c1e19-8c30-4be3-8fc4-6d1b664f0543.TID51.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 1.0 (TID 51). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 59.0 in stage 1.0 (TID 55, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.1.delta.593665f6-85b2-4aaa-b8f1-21bd7e1428ea.TID52.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 1.0 (TID 51) in 273 ms on localhost (executor driver) (51/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 59.0 in stage 1.0 (TID 55)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 55 (task 52, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 55 (task 52, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.1.delta.172e4e7a-4f60-461d-9037-90da59a98d8a.TID54.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d58ca51
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ef5ba8b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.1.delta.3c893de5-2851-4b7b-b894-02d599408158.TID52.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.1.delta.4a41255c-fab9-4a10-b0c6-9fee0eb7340e.TID53.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 1.0 (TID 52). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 60.0 in stage 1.0 (TID 56, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 60.0 in stage 1.0 (TID 56)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 1.0 (TID 52) in 346 ms on localhost (executor driver) (52/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 57 (task 53, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 57 (task 53, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.1.delta.a099cdaf-1aa6-4299-ba31-9c79e5ae7733.TID55.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.1.delta.172e4e7a-4f60-461d-9037-90da59a98d8a.TID54.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29ab7e9c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68a19a68
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 58 (task 54, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 58 (task 54, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.1.delta.a5628365-ef1e-419e-ba37-020db170f963.TID53.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 1.0 (TID 53). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 61.0 in stage 1.0 (TID 57, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 1.0 (TID 53) in 277 ms on localhost (executor driver) (53/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 61.0 in stage 1.0 (TID 57)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.1.delta.64c219ad-6311-4bcb-bc2d-7c871d55d64f.TID54.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 1.0 (TID 54). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 62.0 in stage 1.0 (TID 58, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 1.0 (TID 54) in 251 ms on localhost (executor driver) (54/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 62.0 in stage 1.0 (TID 58)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c9ef390
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.1.delta.db6b3a90-42c0-476b-8ebd-7b06ed49e0d1.TID56.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.1.delta.a099cdaf-1aa6-4299-ba31-9c79e5ae7733.TID55.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 59 (task 55, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 59 (task 55, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26fe5613
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33415284
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28da530d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.1.delta.29c59157-37f6-4744-9f87-1d368b404be1.TID55.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 1.0 (TID 55). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 63.0 in stage 1.0 (TID 59, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 1.0 (TID 55) in 277 ms on localhost (executor driver) (55/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 63.0 in stage 1.0 (TID 59)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.1.delta.afb9d72c-a016-4a1d-9d37-73f85bf1b577.TID57.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.1.delta.7cbf1f5a-3f91-4112-b366-4e68bffcb8e0.TID58.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.1.delta.db6b3a90-42c0-476b-8ebd-7b06ed49e0d1.TID56.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 60 (task 56, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:46,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 60 (task 56, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e0f10e8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51d9ca67
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.1.delta.f57c9dd5-b8fc-49f6-a994-9c203548bbfa.TID56.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 1.0 (TID 56). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 64.0 in stage 1.0 (TID 60, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 1.0 (TID 56) in 256 ms on localhost (executor driver) (56/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 64.0 in stage 1.0 (TID 60)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.1.delta.57577015-3227-421e-8f1d-2e36629925a8.TID59.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f69ccb5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@173034f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.1.delta.afb9d72c-a016-4a1d-9d37-73f85bf1b577.TID57.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 61 (task 57, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 61 (task 57, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.1.delta.7cbf1f5a-3f91-4112-b366-4e68bffcb8e0.TID58.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 62 (task 58, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 62 (task 58, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.1.delta.2bd2c559-8f47-4ab2-b80e-724a72420aa6.TID57.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 1.0 (TID 57). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 65.0 in stage 1.0 (TID 61, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 65.0 in stage 1.0 (TID 61)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 1.0 (TID 57) in 280 ms on localhost (executor driver) (57/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.1.delta.dd331042-4136-4b0c-af4a-71beb3eb218a.TID60.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.1.delta.489bf01f-962d-49cb-b047-b8b47d76e389.TID58.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 1.0 (TID 58). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 68.0 in stage 1.0 (TID 62, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 1.0 (TID 58) in 270 ms on localhost (executor driver) (58/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 68.0 in stage 1.0 (TID 62)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23e860b0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.1.delta.57577015-3227-421e-8f1d-2e36629925a8.TID59.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 63 (task 59, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 63 (task 59, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76eb5918
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4655fb82
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1652e0be
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.1.delta.847e9b93-e57a-4698-a90a-03ef38ec435f.TID59.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.1.delta.d6fe6fed-c8d3-42cd-af89-24513f5623a0.TID61.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 1.0 (TID 59). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 69.0 in stage 1.0 (TID 63, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 1.0 (TID 59) in 256 ms on localhost (executor driver) (59/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 69.0 in stage 1.0 (TID 63)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.1.delta.ff38876e-930c-469e-8bf2-5aaf1a03c5f9.TID62.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.1.delta.dd331042-4136-4b0c-af4a-71beb3eb218a.TID60.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 64 (task 60, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 64 (task 60, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@603b5513
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58f1056c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.1.delta.376e3931-8976-4ee0-8e28-09d8276f2dad.TID60.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 1.0 (TID 60). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 70.0 in stage 1.0 (TID 64, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 1.0 (TID 60) in 314 ms on localhost (executor driver) (60/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 70.0 in stage 1.0 (TID 64)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.1.delta.ffb722dc-f6c1-4c14-bfb9-3e24c5f9d610.TID63.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41227362
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b2d139d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.1.delta.ff38876e-930c-469e-8bf2-5aaf1a03c5f9.TID62.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 68 (task 62, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,392][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 68 (task 62, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.1.delta.d6fe6fed-c8d3-42cd-af89-24513f5623a0.TID61.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 65 (task 61, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 65 (task 61, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.1.delta.d78aee7f-440f-4d01-b1f2-43c457464f5c.TID64.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.1.delta.ad633cbc-dae3-4725-a566-25a04fa4c8bc.TID62.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 1.0 (TID 62). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 71.0 in stage 1.0 (TID 65, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 71.0 in stage 1.0 (TID 65)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 1.0 (TID 62) in 310 ms on localhost (executor driver) (61/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.1.delta.1fe77747-e2ac-4815-8138-f322d0e3c4c4.TID61.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 1.0 (TID 61). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 73.0 in stage 1.0 (TID 66, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 73.0 in stage 1.0 (TID 66)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 1.0 (TID 61) in 337 ms on localhost (executor driver) (62/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.1.delta.ffb722dc-f6c1-4c14-bfb9-3e24c5f9d610.TID63.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 69 (task 63, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 69 (task 63, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b4afe8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,497][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@901d63e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30e0d17f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2efa9c4c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.1.delta.575682dc-ccba-421e-b232-9af6d65d1e4b.TID63.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 1.0 (TID 63). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 74.0 in stage 1.0 (TID 67, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 1.0 (TID 63) in 300 ms on localhost (executor driver) (63/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 74.0 in stage 1.0 (TID 67)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.1.delta.d78aee7f-440f-4d01-b1f2-43c457464f5c.TID64.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 70 (task 64, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 70 (task 64, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cbf493a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.1.delta.71663ed8-0049-45d4-8e2c-bcf1388bf1c5.TID66.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39d673d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.1.delta.5ec7266d-728d-4510-af15-08f0ae8d31ea.TID65.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,585][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.1.delta.6bace8e7-f6c3-489a-adb6-a4b19c36acf9.TID64.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 1.0 (TID 64). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 75.0 in stage 1.0 (TID 68, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 1.0 (TID 64) in 238 ms on localhost (executor driver) (64/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 75.0 in stage 1.0 (TID 68)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.1.delta.50858c0f-4df5-4d9d-b4c3-ca53d480b90d.TID67.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c336413
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad3b2ca
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.1.delta.71663ed8-0049-45d4-8e2c-bcf1388bf1c5.TID66.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 73 (task 66, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 73 (task 66, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.1.delta.5ec7266d-728d-4510-af15-08f0ae8d31ea.TID65.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 71 (task 65, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 71 (task 65, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.1.delta.3c4e67d5-df48-4000-ad04-d40ce54a403f.TID68.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.1.delta.6f1b8c36-1999-44df-97b4-217784c61a99.TID66.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 1.0 (TID 66). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 76.0 in stage 1.0 (TID 69, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 76.0 in stage 1.0 (TID 69)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 1.0 (TID 66) in 227 ms on localhost (executor driver) (65/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.1.delta.50858c0f-4df5-4d9d-b4c3-ca53d480b90d.TID67.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.1.delta.24ee1928-83bc-4668-a32d-6393f06a02b6.TID65.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 74 (task 67, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 74 (task 67, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 1.0 (TID 65). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 77.0 in stage 1.0 (TID 70, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 77.0 in stage 1.0 (TID 70)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 1.0 (TID 65) in 252 ms on localhost (executor driver) (66/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@155111af
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54321db0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.1.delta.7d002f0d-2512-4a99-afac-465d57409e43.TID67.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@401ef51
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fd384d3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 1.0 (TID 67). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 78.0 in stage 1.0 (TID 71, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 1.0 (TID 67) in 224 ms on localhost (executor driver) (67/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 78.0 in stage 1.0 (TID 71)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.1.delta.3c4e67d5-df48-4000-ad04-d40ce54a403f.TID68.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 75 (task 68, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 75 (task 68, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ec66d24
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@431b4b5a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.1.delta.742b4659-386d-4b8a-bf48-7282f89e58c6.TID69.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.1.delta.cca4e24f-6f3d-4ee0-a8fb-a7b0cd18ee3d.TID70.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.1.delta.e3a6dad1-a5ab-48d6-90b3-4e77ef0f0f92.TID68.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 1.0 (TID 68). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 79.0 in stage 1.0 (TID 72, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 1.0 (TID 68) in 237 ms on localhost (executor driver) (68/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 79.0 in stage 1.0 (TID 72)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.1.delta.66e589eb-4b77-4cea-8631-fb3c85491e3d.TID71.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668e5f36
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37efa0b3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.1.delta.742b4659-386d-4b8a-bf48-7282f89e58c6.TID69.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 76 (task 69, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 76 (task 69, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.1.delta.cca4e24f-6f3d-4ee0-a8fb-a7b0cd18ee3d.TID70.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 77 (task 70, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 77 (task 70, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.1.delta.bcb7baf0-1c1c-4eaa-9004-4cb0bd2b61b5.TID72.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.1.delta.66e589eb-4b77-4cea-8631-fb3c85491e3d.TID71.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.1.delta.492298c6-423b-4186-94d8-8f5c64862816.TID69.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 1.0 (TID 69). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 78 (task 71, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 78 (task 71, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 80.0 in stage 1.0 (TID 73, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 1.0 (TID 69) in 257 ms on localhost (executor driver) (69/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 80.0 in stage 1.0 (TID 73)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.1.delta.d6985784-acba-4429-bdfa-a738b1a6ad21.TID70.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 1.0 (TID 70). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 81.0 in stage 1.0 (TID 74, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 1.0 (TID 70) in 266 ms on localhost (executor driver) (70/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 81.0 in stage 1.0 (TID 74)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a4c8705
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:47,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.1.delta.06ee95d1-ba30-4dc8-90c1-514a49bc2ef4.TID71.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 1.0 (TID 71). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 82.0 in stage 1.0 (TID 75, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 1.0 (TID 71) in 275 ms on localhost (executor driver) (71/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 82.0 in stage 1.0 (TID 75)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ecfa07c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.1.delta.bcb7baf0-1c1c-4eaa-9004-4cb0bd2b61b5.TID72.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 79 (task 72, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 79 (task 72, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77fabc0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2de3e83e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49cdc030
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@776ab171
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.1.delta.41aa5a17-522c-4c00-90f3-a609063573ae.TID72.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 1.0 (TID 72). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 83.0 in stage 1.0 (TID 76, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 1.0 (TID 72) in 433 ms on localhost (executor driver) (72/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 83.0 in stage 1.0 (TID 76)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.1.delta.28a14897-eea8-44c7-9f7f-7189e4b4a8bd.TID74.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.1.delta.1167e8f7-d501-47d7-804d-df5cbd0cdeed.TID75.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.1.delta.527700c5-0573-4591-8138-f1af5b8ad0d8.TID73.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7238bf7f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b5501
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.1.delta.c9308819-df9b-4584-a631-26b1d81a5c0c.TID76.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.1.delta.1167e8f7-d501-47d7-804d-df5cbd0cdeed.TID75.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 82 (task 75, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 82 (task 75, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.1.delta.28a14897-eea8-44c7-9f7f-7189e4b4a8bd.TID74.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 81 (task 74, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 81 (task 74, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.1.delta.527700c5-0573-4591-8138-f1af5b8ad0d8.TID73.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 80 (task 73, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,493][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 80 (task 73, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.1.delta.d7f42471-fcfb-4fcd-9660-0713c54873e3.TID75.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.1.delta.0001122b-9738-4561-a35a-610229e127f1.TID74.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,534][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 1.0 (TID 75). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 84.0 in stage 1.0 (TID 77, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 1.0 (TID 75) in 519 ms on localhost (executor driver) (73/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 84.0 in stage 1.0 (TID 77)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 1.0 (TID 74). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 85.0 in stage 1.0 (TID 78, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 1.0 (TID 74) in 579 ms on localhost (executor driver) (74/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 85.0 in stage 1.0 (TID 78)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.1.delta.6b289daa-57ce-4273-ac4f-f385c9704c01.TID73.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 1.0 (TID 73). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 86.0 in stage 1.0 (TID 79, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 1.0 (TID 73) in 612 ms on localhost (executor driver) (75/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 86.0 in stage 1.0 (TID 79)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@362b758c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,575][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.1.delta.c9308819-df9b-4584-a631-26b1d81a5c0c.TID76.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,575][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 83 (task 76, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 83 (task 76, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73389f40
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47a4ce27
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39b250c7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1347ccfc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3834ef7a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.1.delta.5f5a4a31-bc51-43f6-b642-d62171de855c.TID76.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 1.0 (TID 76). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 87.0 in stage 1.0 (TID 80, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 1.0 (TID 76) in 389 ms on localhost (executor driver) (76/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 87.0 in stage 1.0 (TID 80)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44896fc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.1.delta.877e28a4-f218-491a-b77d-d85c8ba2f304.TID77.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1222a418
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.1.delta.d71e4209-fcca-477f-b703-41042320b5fb.TID79.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.1.delta.8fba2efd-253b-4895-9399-0741e3f4371f.TID78.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.1.delta.4d3fe036-2500-4589-80c8-93a6a2c03cd4.TID80.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.1.delta.d71e4209-fcca-477f-b703-41042320b5fb.TID79.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.1.delta.877e28a4-f218-491a-b77d-d85c8ba2f304.TID77.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.1.delta.8fba2efd-253b-4895-9399-0741e3f4371f.TID78.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 86 (task 79, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 84 (task 77, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 86 (task 79, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 84 (task 77, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 85 (task 78, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:48,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 85 (task 78, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.1.delta.4ce0dd45-7920-448f-a171-a995a070d262.TID77.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.1.delta.789bca55-35db-4e1d-a538-3063cdadfab3.TID78.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.1.delta.aa41c558-26a7-4394-8f91-77091e8b6d92.TID79.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 1.0 (TID 78). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 1.0 (TID 77). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 88.0 in stage 1.0 (TID 81, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 89.0 in stage 1.0 (TID 82, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 88.0 in stage 1.0 (TID 81)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 1.0 (TID 78) in 480 ms on localhost (executor driver) (77/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 89.0 in stage 1.0 (TID 82)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 1.0 (TID 79). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 1.0 (TID 77) in 482 ms on localhost (executor driver) (78/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 90.0 in stage 1.0 (TID 83, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 1.0 (TID 79) in 477 ms on localhost (executor driver) (79/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 90.0 in stage 1.0 (TID 83)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.1.delta.4d3fe036-2500-4589-80c8-93a6a2c03cd4.TID80.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 87 (task 80, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 87 (task 80, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e5e79c7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.1.delta.631d32c4-b5a0-46f3-8f98-206d10f03f83.TID80.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dab4523
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 1.0 (TID 80). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 91.0 in stage 1.0 (TID 84, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 1.0 (TID 80) in 444 ms on localhost (executor driver) (80/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 91.0 in stage 1.0 (TID 84)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2291ac53
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2bbd05
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f357bd8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ec22e50
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c7b395
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@117b85ba
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.1.delta.ba5afc18-3e79-4ef6-88b2-1f15e7ba221e.TID81.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.1.delta.4d302066-f8ca-4cd4-9828-e60a67be6b1b.TID82.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.1.delta.8d0986de-b4e4-4618-a6a2-ef561cf4bef1.TID84.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.1.delta.93ad26f3-a79a-4772-8370-9ad8b494d739.TID83.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.1.delta.ba5afc18-3e79-4ef6-88b2-1f15e7ba221e.TID81.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 88 (task 81, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 88 (task 81, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.1.delta.4d302066-f8ca-4cd4-9828-e60a67be6b1b.TID82.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 89 (task 82, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 89 (task 82, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.1.delta.8d0986de-b4e4-4618-a6a2-ef561cf4bef1.TID84.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 91 (task 84, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 91 (task 84, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.1.delta.93ad26f3-a79a-4772-8370-9ad8b494d739.TID83.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 90 (task 83, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 90 (task 83, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.1.delta.ee0514f5-ac8e-4e0c-845a-adc2eb9277ee.TID81.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 1.0 (TID 81). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 92.0 in stage 1.0 (TID 85, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 1.0 (TID 81) in 344 ms on localhost (executor driver) (81/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 92.0 in stage 1.0 (TID 85)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.1.delta.93128609-5e02-498a-ad0d-dc3f476da32d.TID82.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 1.0 (TID 82). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 93.0 in stage 1.0 (TID 86, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 1.0 (TID 82) in 356 ms on localhost (executor driver) (82/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 93.0 in stage 1.0 (TID 86)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.1.delta.bbebfc23-94a6-4bf6-b5bb-c84caa00c12b.TID84.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 1.0 (TID 84). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 94.0 in stage 1.0 (TID 87, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 1.0 (TID 84) in 296 ms on localhost (executor driver) (83/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 94.0 in stage 1.0 (TID 87)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a55b5ae
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@96e1827
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.1.delta.7dcd41a8-6732-4b9c-bc14-07360e2137e5.TID83.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 1.0 (TID 83). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 95.0 in stage 1.0 (TID 88, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 95.0 in stage 1.0 (TID 88)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 1.0 (TID 83) in 408 ms on localhost (executor driver) (84/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24a26d5c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28c1b7b0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.1.delta.c82a1e1f-26ab-4694-8149-850b95cd965c.TID85.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f14083
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fcd0506
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1655d4d7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e666377
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,491][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,491][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.1.delta.a1185aa1-3f2c-411c-9030-bb3fae01b7c6.TID87.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.1.delta.a8cacb90-4899-4ffd-a635-82b69a076345.TID88.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.1.delta.285bf7da-36b4-44b9-9825-5fc2301f68d1.TID86.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.1.delta.c82a1e1f-26ab-4694-8149-850b95cd965c.TID85.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 92 (task 85, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 92 (task 85, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.1.delta.a1185aa1-3f2c-411c-9030-bb3fae01b7c6.TID87.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 94 (task 87, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 94 (task 87, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.1.delta.c6d8b402-cb95-475e-9d95-5a9ed343e95f.TID85.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 1.0 (TID 85). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 96.0 in stage 1.0 (TID 89, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 1.0 (TID 85) in 238 ms on localhost (executor driver) (85/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 96.0 in stage 1.0 (TID 89)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.1.delta.a8cacb90-4899-4ffd-a635-82b69a076345.TID88.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 95 (task 88, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 95 (task 88, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.1.delta.c7e0eae0-4d4e-4cf7-bee5-80d1c750c29f.TID87.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.1.delta.285bf7da-36b4-44b9-9825-5fc2301f68d1.TID86.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 1.0 (TID 87). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 97.0 in stage 1.0 (TID 90, localhost, executor driver, partition 97, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 1.0 (TID 87) in 238 ms on localhost (executor driver) (86/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 97.0 in stage 1.0 (TID 90)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 93 (task 86, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 93 (task 86, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37d29c9c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f8dc0b0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@339c2c8e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eb6d94e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.1.delta.5b900c2c-431b-4e72-ab9d-a7fa53a23365.TID88.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 1.0 (TID 88). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 98.0 in stage 1.0 (TID 91, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 1.0 (TID 88) in 229 ms on localhost (executor driver) (87/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 98.0 in stage 1.0 (TID 91)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.1.delta.806c550d-e038-4c1a-b234-22581c80a7d3.TID86.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 1.0 (TID 86). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 99.0 in stage 1.0 (TID 92, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 1.0 (TID 86) in 300 ms on localhost (executor driver) (88/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 99.0 in stage 1.0 (TID 92)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25340d77
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.1.delta.8cf68051-1971-4781-9733-1e697a1f9d8e.TID89.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.1.delta.5d13dd65-34e6-4540-bbe6-deb99b2ee896.TID90.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ddada9f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25b66483
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c1ce8b5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.1.delta.bc12b25c-d4de-4fc2-bfc5-768ffa4a890d.TID92.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.1.delta.42ae710f-cff6-4bae-a121-461887658871.TID91.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.1.delta.8cf68051-1971-4781-9733-1e697a1f9d8e.TID89.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.1.delta.5d13dd65-34e6-4540-bbe6-deb99b2ee896.TID90.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 96 (task 89, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 96 (task 89, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 97 (task 90, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 97 (task 90, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.1.delta.9b0415ef-928b-4c65-8385-1969868d24cc.TID90.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.1.delta.d937b4d7-d6f6-4377-9bc1-9d557ba5ef76.TID89.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 1.0 (TID 89). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 1.0 (TID 90). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 100.0 in stage 1.0 (TID 93, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 1.0 (TID 89) in 246 ms on localhost (executor driver) (89/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 1.0 (TID 90) in 221 ms on localhost (executor driver) (90/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 101.0 in stage 1.0 (TID 94, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 100.0 in stage 1.0 (TID 93)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 101.0 in stage 1.0 (TID 94)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.1.delta.bc12b25c-d4de-4fc2-bfc5-768ffa4a890d.TID92.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 99 (task 92, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 99 (task 92, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b00e8cc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23892a2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.1.delta.42ae710f-cff6-4bae-a121-461887658871.TID91.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 98 (task 91, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 98 (task 91, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ab82e0f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21055483
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.1.delta.abec9342-3e6a-4d52-90ca-814a67298b29.TID92.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 1.0 (TID 92). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 102.0 in stage 1.0 (TID 95, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 1.0 (TID 92) in 243 ms on localhost (executor driver) (91/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 102.0 in stage 1.0 (TID 95)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.1.delta.66c51d06-2b16-4672-941b-5e6356572de2.TID91.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.1.delta.ff157d69-66c4-4b29-90ad-7c1688e8251f.TID93.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 1.0 (TID 91). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 103.0 in stage 1.0 (TID 96, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 1.0 (TID 91) in 259 ms on localhost (executor driver) (92/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 103.0 in stage 1.0 (TID 96)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b02455e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.1.delta.8ba22bd2-8c6f-416e-847e-d077b8bc71d5.TID94.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56ab034e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6eb1ebec
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56c001e7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:49,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.1.delta.ff157d69-66c4-4b29-90ad-7c1688e8251f.TID93.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 100 (task 93, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 100 (task 93, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.1.delta.e2606c38-bcc3-4ff3-8921-64278c5c1554.TID95.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.1.delta.ae2ac414-a529-405a-bac5-44dca3a23129.TID96.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.1.delta.8ba22bd2-8c6f-416e-847e-d077b8bc71d5.TID94.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 101 (task 94, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 101 (task 94, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.1.delta.12ecef59-f3c4-48c9-ba35-18565ce39196.TID93.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 1.0 (TID 93). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 104.0 in stage 1.0 (TID 97, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 104.0 in stage 1.0 (TID 97)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 1.0 (TID 93) in 220 ms on localhost (executor driver) (93/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.1.delta.47758542-d235-4172-9e78-39132e384295.TID94.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 1.0 (TID 94). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 105.0 in stage 1.0 (TID 98, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 1.0 (TID 94) in 238 ms on localhost (executor driver) (94/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 105.0 in stage 1.0 (TID 98)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7be8fdb3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19b3e219
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.1.delta.e2606c38-bcc3-4ff3-8921-64278c5c1554.TID95.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.1.delta.ae2ac414-a529-405a-bac5-44dca3a23129.TID96.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 102 (task 95, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 102 (task 95, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 103 (task 96, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 103 (task 96, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d00df81
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e60845d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.1.delta.68651c50-5b34-4021-b80d-cebb1cef6818.TID97.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.1.delta.6e41d131-29b4-47da-9221-0c6d10ab791d.TID95.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.1.delta.41d0e6a3-9fa5-44b0-ad16-ce9bb557bdd6.TID96.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 1.0 (TID 95). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 106.0 in stage 1.0 (TID 99, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 1.0 (TID 95) in 266 ms on localhost (executor driver) (95/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 106.0 in stage 1.0 (TID 99)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 1.0 (TID 96). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 107.0 in stage 1.0 (TID 100, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 1.0 (TID 96) in 259 ms on localhost (executor driver) (96/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 107.0 in stage 1.0 (TID 100)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,204][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.1.delta.32245cc1-bd9a-4737-8360-c230c32ca5c9.TID98.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@523ee87d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b473261
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e9ae245
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b21bd15
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.1.delta.68651c50-5b34-4021-b80d-cebb1cef6818.TID97.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 104 (task 97, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 104 (task 97, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.1.delta.32245cc1-bd9a-4737-8360-c230c32ca5c9.TID98.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 105 (task 98, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 105 (task 98, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.1.delta.b46bb757-63e8-49f2-8287-5d9c0f536d35.TID99.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.1.delta.af319490-f57e-4b7b-a18a-78be607be0ee.TID100.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.1.delta.0d5a2b9d-77a6-4302-ad62-f4bc6583bf2d.TID97.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 1.0 (TID 97). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 109.0 in stage 1.0 (TID 101, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 1.0 (TID 97) in 309 ms on localhost (executor driver) (97/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 109.0 in stage 1.0 (TID 101)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.1.delta.b93c5666-0a6e-40da-997e-f054c596af83.TID98.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 1.0 (TID 98). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 110.0 in stage 1.0 (TID 102, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 1.0 (TID 98) in 304 ms on localhost (executor driver) (98/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 110.0 in stage 1.0 (TID 102)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@acef1d2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d2cfaf8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b2933ab
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75eea30b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.1.delta.b46bb757-63e8-49f2-8287-5d9c0f536d35.TID99.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 106 (task 99, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 106 (task 99, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.1.delta.af319490-f57e-4b7b-a18a-78be607be0ee.TID100.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 107 (task 100, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 107 (task 100, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.1.delta.3fc96fb8-89b2-40b7-897b-0eda59123b68.TID101.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.1.delta.19dc5e1b-f354-4f74-ba2a-791d38b4a899.TID99.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.1.delta.fe4d0649-40ab-4ae4-b56d-283974a34147.TID102.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,542][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 1.0 (TID 99). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 111.0 in stage 1.0 (TID 103, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 1.0 (TID 99) in 365 ms on localhost (executor driver) (99/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 111.0 in stage 1.0 (TID 103)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.1.delta.c143b8ef-50ae-4bfb-afcb-833e9e6fdb4a.TID100.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fb44a00
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 1.0 (TID 100). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a02d0bc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 112.0 in stage 1.0 (TID 104, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 1.0 (TID 100) in 387 ms on localhost (executor driver) (100/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 112.0 in stage 1.0 (TID 104)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d0b38b5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a6b36ff
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.1.delta.3fc96fb8-89b2-40b7-897b-0eda59123b68.TID101.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.1.delta.7eb30d8f-4954-46ea-8348-5a73ddf5d857.TID103.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 109 (task 101, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 109 (task 101, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.1.delta.fe4d0649-40ab-4ae4-b56d-283974a34147.TID102.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 110 (task 102, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 110 (task 102, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.1.delta.efb71193-3569-46e8-9e00-1871be6e0f31.TID104.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.1.delta.cff44d5f-a504-4ba6-88eb-e6c8d2ff2e64.TID101.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 1.0 (TID 101). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 113.0 in stage 1.0 (TID 105, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 1.0 (TID 101) in 337 ms on localhost (executor driver) (101/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 113.0 in stage 1.0 (TID 105)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.1.delta.3b3865a9-55d7-457e-aa20-9ce125131a68.TID102.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 1.0 (TID 102). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 114.0 in stage 1.0 (TID 106, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 1.0 (TID 102) in 334 ms on localhost (executor driver) (102/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 114.0 in stage 1.0 (TID 106)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@174135e7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.1.delta.7eb30d8f-4954-46ea-8348-5a73ddf5d857.TID103.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 111 (task 103, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 111 (task 103, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@97ae5e7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,790][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@172bfdb2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@469dcc55
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.1.delta.efb71193-3569-46e8-9e00-1871be6e0f31.TID104.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 112 (task 104, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 112 (task 104, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.1.delta.a888e447-a2a9-4bbc-b8a9-474ce404785b.TID103.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 1.0 (TID 103). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 115.0 in stage 1.0 (TID 107, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 1.0 (TID 103) in 294 ms on localhost (executor driver) (103/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 115.0 in stage 1.0 (TID 107)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.1.delta.7f9d0523-955c-4e4d-968c-09abf46748f7.TID106.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.1.delta.db862b34-d8de-42e7-9cf1-b3b44de98d8c.TID105.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48c95106
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6117c5f6
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.1.delta.6927c3ed-a124-4b1b-a061-9f7995cb5658.TID104.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 1.0 (TID 104). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 117.0 in stage 1.0 (TID 108, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 117.0 in stage 1.0 (TID 108)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 1.0 (TID 104) in 307 ms on localhost (executor driver) (104/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@707b0d57
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de64eae
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.1.delta.68bcb6aa-ba1c-4d88-a888-5c4255172689.TID107.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.1.delta.7f9d0523-955c-4e4d-968c-09abf46748f7.TID106.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.1.delta.db862b34-d8de-42e7-9cf1-b3b44de98d8c.TID105.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 114 (task 106, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 114 (task 106, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 113 (task 105, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 113 (task 105, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.1.delta.a3a0804d-db8d-4613-b3a7-2985d517175b.TID108.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.1.delta.9546377c-c928-4c91-b980-2143ded15184.TID106.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.1.delta.e3fb71dd-db11-47da-9f49-5a8e387b7e94.TID105.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 1.0 (TID 106). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 1.0 (TID 105). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 119.0 in stage 1.0 (TID 109, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 120.0 in stage 1.0 (TID 110, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 119.0 in stage 1.0 (TID 109)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 1.0 (TID 106) in 275 ms on localhost (executor driver) (105/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 120.0 in stage 1.0 (TID 110)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:50,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 1.0 (TID 105) in 287 ms on localhost (executor driver) (106/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.1.delta.68bcb6aa-ba1c-4d88-a888-5c4255172689.TID107.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 115 (task 107, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 115 (task 107, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33db2e37
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e540836
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.1.delta.a3a0804d-db8d-4613-b3a7-2985d517175b.TID108.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24b9915e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 117 (task 108, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 117 (task 108, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8f362bb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.1.delta.8f620756-50b6-4aaa-9f8f-9f026742f9cb.TID107.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 1.0 (TID 107). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 121.0 in stage 1.0 (TID 111, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 121.0 in stage 1.0 (TID 111)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 1.0 (TID 107) in 223 ms on localhost (executor driver) (107/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.1.delta.5f715ff4-9c43-4b4d-b87b-8800be3b3dd2.TID109.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71711e05
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b9ff975
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.1.delta.8e3c0c73-d2ec-4d44-b948-7216bb5c9a6a.TID108.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 1.0 (TID 108). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 122.0 in stage 1.0 (TID 112, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 1.0 (TID 108) in 225 ms on localhost (executor driver) (108/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 122.0 in stage 1.0 (TID 112)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.1.delta.ede7af5a-bebf-413b-a214-cdde5135c5e2.TID110.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d64ce8d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b2bdf10
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.1.delta.c5cf0c35-51e4-41e9-b376-cc9f83dbf947.TID111.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.1.delta.5f715ff4-9c43-4b4d-b87b-8800be3b3dd2.TID109.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 119 (task 109, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 119 (task 109, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.1.delta.7ef36390-a55f-4966-83ad-bfd359ea0cc3.TID112.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.1.delta.ede7af5a-bebf-413b-a214-cdde5135c5e2.TID110.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 120 (task 110, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 120 (task 110, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.1.delta.70317734-aa0b-4728-8e98-8fcd2ce0d98c.TID109.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 1.0 (TID 109). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 123.0 in stage 1.0 (TID 113, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 1.0 (TID 109) in 234 ms on localhost (executor driver) (109/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 123.0 in stage 1.0 (TID 113)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.1.delta.c5cf0c35-51e4-41e9-b376-cc9f83dbf947.TID111.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,233][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 121 (task 111, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 121 (task 111, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.1.delta.8134ca56-e3fa-4c87-8f8d-1311c79c7781.TID110.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d7038a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 1.0 (TID 110). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 124.0 in stage 1.0 (TID 114, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 1.0 (TID 110) in 285 ms on localhost (executor driver) (110/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 124.0 in stage 1.0 (TID 114)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66b72b59
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.1.delta.8e0ea97d-8376-4e5d-8f4f-354af1ffc5ad.TID111.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.1.delta.7ef36390-a55f-4966-83ad-bfd359ea0cc3.TID112.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 1.0 (TID 111). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 122 (task 112, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 122 (task 112, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 125.0 in stage 1.0 (TID 115, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 1.0 (TID 111) in 278 ms on localhost (executor driver) (111/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 125.0 in stage 1.0 (TID 115)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f2e70a9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,338][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4793a31c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.1.delta.aff1a55f-9945-4d33-8f04-a65430c4b5d8.TID113.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59217205
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b22c80c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.1.delta.4474b71a-1b76-4eb1-bd2a-fda0bb13f44a.TID112.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 1.0 (TID 112). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 126.0 in stage 1.0 (TID 116, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 1.0 (TID 112) in 292 ms on localhost (executor driver) (112/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 126.0 in stage 1.0 (TID 116)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,392][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.1.delta.97aea448-78aa-4b4a-a7af-98a22fd62014.TID114.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.1.delta.8261635a-1977-4a1c-8f27-6564d4b4edf9.TID115.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3097ff79
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc126de
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.1.delta.aff1a55f-9945-4d33-8f04-a65430c4b5d8.TID113.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 123 (task 113, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 123 (task 113, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.1.delta.b6ec9a5d-53de-47ac-b17a-3c0bafc43346.TID116.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.1.delta.97aea448-78aa-4b4a-a7af-98a22fd62014.TID114.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 124 (task 114, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 124 (task 114, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.1.delta.0296518f-65a7-4644-bc25-49e7c331ad15.TID113.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 1.0 (TID 113). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 127.0 in stage 1.0 (TID 117, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 1.0 (TID 113) in 263 ms on localhost (executor driver) (113/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 127.0 in stage 1.0 (TID 117)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.1.delta.8261635a-1977-4a1c-8f27-6564d4b4edf9.TID115.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 125 (task 115, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 125 (task 115, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.1.delta.506ed92f-5d48-431f-86cd-1cf40c4ab9ea.TID114.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2de1d9fe
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 1.0 (TID 114). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@648ab5fa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 128.0 in stage 1.0 (TID 118, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 1.0 (TID 114) in 237 ms on localhost (executor driver) (114/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 128.0 in stage 1.0 (TID 118)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.1.delta.74ce52b0-48c7-4cbd-8abc-e1a08699e29f.TID115.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93090f4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 1.0 (TID 115). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 130.0 in stage 1.0 (TID 119, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e428b70
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 1.0 (TID 115) in 204 ms on localhost (executor driver) (115/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 130.0 in stage 1.0 (TID 119)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.1.delta.b6ec9a5d-53de-47ac-b17a-3c0bafc43346.TID116.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 126 (task 116, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 126 (task 116, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.1.delta.e7b129a5-fe9c-423d-ad44-3fc468da8942.TID117.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29d2d91e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb8ae6b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.1.delta.e6429e19-acfa-4a5b-9fac-952141d7081c.TID116.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.1.delta.198f452a-2ad1-4b41-ad4e-68da7a51b3ae.TID118.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 1.0 (TID 116). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 131.0 in stage 1.0 (TID 120, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 1.0 (TID 116) in 206 ms on localhost (executor driver) (116/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 131.0 in stage 1.0 (TID 120)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.1.delta.681ac26d-4733-4e20-956d-cc3b1cf0ed15.TID119.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e2e5f5f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d1fe603
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.1.delta.e7b129a5-fe9c-423d-ad44-3fc468da8942.TID117.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 127 (task 117, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 127 (task 117, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.1.delta.8e47a7ab-8f0d-4dad-b105-8ad54775ff43.TID120.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.1.delta.198f452a-2ad1-4b41-ad4e-68da7a51b3ae.TID118.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 128 (task 118, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 128 (task 118, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.1.delta.6ea996ab-9ee1-457b-b2a2-52150c9e9449.TID117.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.1.delta.681ac26d-4733-4e20-956d-cc3b1cf0ed15.TID119.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 1.0 (TID 117). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 132.0 in stage 1.0 (TID 121, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 1.0 (TID 117) in 225 ms on localhost (executor driver) (117/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 132.0 in stage 1.0 (TID 121)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 130 (task 119, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 130 (task 119, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.1.delta.973b696e-6763-406b-8e17-74bbe13af5ec.TID118.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 1.0 (TID 118). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 133.0 in stage 1.0 (TID 122, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 1.0 (TID 118) in 222 ms on localhost (executor driver) (118/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 133.0 in stage 1.0 (TID 122)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3051e625
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@193d78fc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,762][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.1.delta.a0ac2011-d37e-4d28-bbbe-ff0523d70419.TID119.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 1.0 (TID 119). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 134.0 in stage 1.0 (TID 123, localhost, executor driver, partition 134, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 1.0 (TID 119) in 227 ms on localhost (executor driver) (119/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 134.0 in stage 1.0 (TID 123)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13463ebf
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.1.delta.8e47a7ab-8f0d-4dad-b105-8ad54775ff43.TID120.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 131 (task 120, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 131 (task 120, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.1.delta.6ef14f9f-3024-4878-a6b6-f3132413fec1.TID121.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c677345
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@435e5c47
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fba126
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.1.delta.b97e566c-7154-408c-9d22-97b982e8bdcf.TID120.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 1.0 (TID 120). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 135.0 in stage 1.0 (TID 124, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 1.0 (TID 120) in 231 ms on localhost (executor driver) (120/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 135.0 in stage 1.0 (TID 124)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.1.delta.40897d70-e5eb-4d1b-b771-97b65cba88b3.TID123.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.1.delta.ab9dcbbf-f9b9-487d-a665-cf3b9d3b94b8.TID122.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30e1b918
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f27476c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.1.delta.6ef14f9f-3024-4878-a6b6-f3132413fec1.TID121.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 132 (task 121, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 132 (task 121, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.1.delta.0e35d674-70b1-42be-8252-83a7af3775e7.TID124.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.1.delta.416f0659-84bd-4a8e-9ed1-aefa33fe0d0f.TID121.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.1.delta.40897d70-e5eb-4d1b-b771-97b65cba88b3.TID123.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 1.0 (TID 121). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 136.0 in stage 1.0 (TID 125, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 134 (task 123, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 136.0 in stage 1.0 (TID 125)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 1.0 (TID 121) in 204 ms on localhost (executor driver) (121/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 134 (task 123, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.1.delta.ab9dcbbf-f9b9-487d-a665-cf3b9d3b94b8.TID122.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 133 (task 122, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 133 (task 122, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28f2b4d4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43753d70
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.1.delta.44b26500-ae2c-464f-afa4-c197a2f8e581.TID123.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 1.0 (TID 123). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 137.0 in stage 1.0 (TID 126, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 1.0 (TID 123) in 193 ms on localhost (executor driver) (122/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 137.0 in stage 1.0 (TID 126)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.1.delta.dec53121-a02b-402e-ad8f-2517bcba891a.TID122.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 1.0 (TID 122). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 138.0 in stage 1.0 (TID 127, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 1.0 (TID 122) in 243 ms on localhost (executor driver) (123/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 138.0 in stage 1.0 (TID 127)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.1.delta.0e35d674-70b1-42be-8252-83a7af3775e7.TID124.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.1.delta.3e0a1633-07e3-4d9b-a64e-1725fd4d5594.TID125.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 135 (task 124, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 135 (task 124, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2085ad20
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65d7e22a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:51,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1350bf32
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7020bdbe
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.1.delta.bd187200-16b8-4513-80f9-07b6d8ab57d0.TID124.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 1.0 (TID 124). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 139.0 in stage 1.0 (TID 128, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 1.0 (TID 124) in 202 ms on localhost (executor driver) (124/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 139.0 in stage 1.0 (TID 128)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f72ba94
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ffd547b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.1.delta.dc4c60dd-2fe4-40f9-a015-4af0b65656f4.TID126.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.1.delta.19456cd3-5a0c-40cd-b8f3-2240ceb54471.TID127.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.1.delta.3e0a1633-07e3-4d9b-a64e-1725fd4d5594.TID125.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 136 (task 125, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 136 (task 125, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.1.delta.1d93e01d-f53c-4d4c-a370-4794f750f47e.TID128.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.1.delta.7abbbaa1-0699-4b0a-a217-62c8bb6f55f9.TID125.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 1.0 (TID 125). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 140.0 in stage 1.0 (TID 129, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 1.0 (TID 125) in 421 ms on localhost (executor driver) (125/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 140.0 in stage 1.0 (TID 129)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5042492d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45628044
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.1.delta.dc4c60dd-2fe4-40f9-a015-4af0b65656f4.TID126.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.1.delta.19456cd3-5a0c-40cd-b8f3-2240ceb54471.TID127.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 137 (task 126, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 137 (task 126, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 138 (task 127, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 138 (task 127, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.1.delta.0efddf4a-0e79-49f3-bdda-37ff8b40ecf0.TID129.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.1.delta.e0554db1-a44f-4877-b915-5eba4b718f87.TID126.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.1.delta.1d93e01d-f53c-4d4c-a370-4794f750f47e.TID128.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 1.0 (TID 126). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.1.delta.e49356be-a230-4b42-aba7-be4b589ea3a6.TID127.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 141.0 in stage 1.0 (TID 130, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 1.0 (TID 126) in 495 ms on localhost (executor driver) (126/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 141.0 in stage 1.0 (TID 130)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 139 (task 128, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 1.0 (TID 127). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 139 (task 128, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 142.0 in stage 1.0 (TID 131, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 1.0 (TID 127) in 482 ms on localhost (executor driver) (127/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 142.0 in stage 1.0 (TID 131)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,494][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cc35448
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb75ad0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,497][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,497][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79917b58
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.1.delta.0ce96b52-49db-4635-86db-dc14a0d7e873.TID128.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45548d57
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 1.0 (TID 128). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 143.0 in stage 1.0 (TID 132, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,534][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 143.0 in stage 1.0 (TID 132)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,534][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 1.0 (TID 128) in 507 ms on localhost (executor driver) (128/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.1.delta.5ad880bb-0e01-448b-9a9c-6664b50ff824.TID130.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c99858f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d8c12c4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.1.delta.0efddf4a-0e79-49f3-bdda-37ff8b40ecf0.TID129.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 140 (task 129, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 140 (task 129, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.1.delta.d25c84e4-a259-422b-9478-0e93c2669131.TID131.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.1.delta.51d4bb04-a01f-4a98-8b5c-0fcb8f76b470.TID129.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 1.0 (TID 129). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 144.0 in stage 1.0 (TID 133, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 1.0 (TID 129) in 280 ms on localhost (executor driver) (129/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 144.0 in stage 1.0 (TID 133)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.1.delta.705ea977-2f93-413a-a8ff-b46293c8320d.TID132.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.1.delta.5ad880bb-0e01-448b-9a9c-6664b50ff824.TID130.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e5ef82
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@173863a5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 141 (task 130, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 141 (task 130, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.1.delta.d25c84e4-a259-422b-9478-0e93c2669131.TID131.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 142 (task 131, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 142 (task 131, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.1.delta.5f849769-e6c0-4479-a17f-3cf762c2cc30.TID130.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 1.0 (TID 130). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 145.0 in stage 1.0 (TID 134, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 1.0 (TID 130) in 241 ms on localhost (executor driver) (130/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 145.0 in stage 1.0 (TID 134)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.1.delta.4f9b847a-89d4-43db-b8c7-40ff45bd08db.TID133.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.1.delta.705ea977-2f93-413a-a8ff-b46293c8320d.TID132.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 143 (task 132, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 143 (task 132, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ae1550
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@532e372a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.1.delta.f2d2ff9c-41b6-4161-bd23-9ef5f473a2e7.TID131.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 1.0 (TID 131). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 146.0 in stage 1.0 (TID 135, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 1.0 (TID 131) in 271 ms on localhost (executor driver) (131/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 146.0 in stage 1.0 (TID 135)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eeabf37
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a2a6867
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.1.delta.bd441b64-aebc-4d08-8d7f-87fbe736fde7.TID132.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,768][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 1.0 (TID 132). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,768][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 147.0 in stage 1.0 (TID 136, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 147.0 in stage 1.0 (TID 136)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 1.0 (TID 132) in 236 ms on localhost (executor driver) (132/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.1.delta.fdecff06-830a-4c22-ac48-d3de6e6c2db8.TID134.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2facc27a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.1.delta.4f9b847a-89d4-43db-b8c7-40ff45bd08db.TID133.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@679a9e40
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 144 (task 133, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 144 (task 133, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.1.delta.494f42b4-0003-48d5-b9af-7fa83e776e9d.TID135.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.1.delta.0fb0193d-d890-4ed9-ba0e-754f3bb3efdf.TID133.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 1.0 (TID 133). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 148.0 in stage 1.0 (TID 137, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 1.0 (TID 133) in 242 ms on localhost (executor driver) (133/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 148.0 in stage 1.0 (TID 137)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.1.delta.7f3ae9a7-0f20-4d55-88a3-b7d867795178.TID136.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@204a3c6c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@498a9c09
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.1.delta.fdecff06-830a-4c22-ac48-d3de6e6c2db8.TID134.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 145 (task 134, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 145 (task 134, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.1.delta.494f42b4-0003-48d5-b9af-7fa83e776e9d.TID135.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,908][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 146 (task 135, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 146 (task 135, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.1.delta.a9e5ebc6-1101-457c-9333-646f8bb11619.TID134.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 1.0 (TID 134). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 149.0 in stage 1.0 (TID 138, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 149.0 in stage 1.0 (TID 138)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 1.0 (TID 134) in 236 ms on localhost (executor driver) (134/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.1.delta.286d42fe-79a9-4b33-9b93-5011d9f0101e.TID137.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.1.delta.7f3ae9a7-0f20-4d55-88a3-b7d867795178.TID136.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 147 (task 136, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 147 (task 136, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5f5862
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3472d09a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.1.delta.eb820db4-07b3-4412-912a-d9c6a6d4e913.TID135.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 1.0 (TID 135). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 150.0 in stage 1.0 (TID 139, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 1.0 (TID 135) in 236 ms on localhost (executor driver) (135/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 150.0 in stage 1.0 (TID 139)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@604c7a50
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e6ea0e9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.1.delta.5698a00b-f359-4ea3-a0e5-d65bcdc07e6e.TID136.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 1.0 (TID 136). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 151.0 in stage 1.0 (TID 140, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 1.0 (TID 136) in 226 ms on localhost (executor driver) (136/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:52,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 151.0 in stage 1.0 (TID 140)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.1.delta.599779dd-344e-4a93-b585-7bab471aef03.TID138.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.1.delta.286d42fe-79a9-4b33-9b93-5011d9f0101e.TID137.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c70ab53
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 148 (task 137, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1042be9c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 148 (task 137, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.1.delta.f6f1cdc7-894c-436c-ba76-34801c494f0d.TID139.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.1.delta.74d5221d-4977-4060-a034-524fcfa17370.TID137.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 1.0 (TID 137). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 152.0 in stage 1.0 (TID 141, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 1.0 (TID 137) in 215 ms on localhost (executor driver) (137/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 152.0 in stage 1.0 (TID 141)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.1.delta.701d9f0d-1db0-4737-af8f-527cc79b31ef.TID140.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.1.delta.599779dd-344e-4a93-b585-7bab471aef03.TID138.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 149 (task 138, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 149 (task 138, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cfcf8c1
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bf65c23
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.1.delta.f6f1cdc7-894c-436c-ba76-34801c494f0d.TID139.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 150 (task 139, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 150 (task 139, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.1.delta.23ff8b04-d159-4bab-bf4a-3e1d5bc7fb7d.TID138.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 1.0 (TID 138). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 153.0 in stage 1.0 (TID 142, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 1.0 (TID 138) in 212 ms on localhost (executor driver) (138/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 153.0 in stage 1.0 (TID 142)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.1.delta.701d9f0d-1db0-4737-af8f-527cc79b31ef.TID140.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.1.delta.33259f3d-71bd-4b1d-89b4-7f60886644a2.TID141.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 151 (task 140, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 151 (task 140, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e4e205b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5e6a7f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.1.delta.a53eb898-b44e-46dc-bf32-8955b507ca26.TID139.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 1.0 (TID 139). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 154.0 in stage 1.0 (TID 143, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 1.0 (TID 139) in 208 ms on localhost (executor driver) (139/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 154.0 in stage 1.0 (TID 143)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.1.delta.f3f9a26e-861f-467a-af7d-f0c48a02f2ed.TID140.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d1b0559
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16eb7ed5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 1.0 (TID 140). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 155.0 in stage 1.0 (TID 144, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 1.0 (TID 140) in 202 ms on localhost (executor driver) (140/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 155.0 in stage 1.0 (TID 144)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.1.delta.ba612f21-cf7d-4170-9941-266aeb741dc0.TID142.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22211b3d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c440381
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.1.delta.33259f3d-71bd-4b1d-89b4-7f60886644a2.TID141.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 152 (task 141, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 152 (task 141, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.1.delta.07b27b52-acc6-4b8b-9038-394c1c5792dc.TID143.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.1.delta.524010b4-b371-4d3b-bd14-d141d3e9ed16.TID144.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.1.delta.102ba154-1c08-4c4b-a666-5dceb1b24246.TID141.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 1.0 (TID 141). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 156.0 in stage 1.0 (TID 145, localhost, executor driver, partition 156, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 1.0 (TID 141) in 276 ms on localhost (executor driver) (141/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 156.0 in stage 1.0 (TID 145)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.1.delta.ba612f21-cf7d-4170-9941-266aeb741dc0.TID142.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 153 (task 142, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 153 (task 142, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6004b5d2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,156,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30619d02
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,156,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.1.delta.07b27b52-acc6-4b8b-9038-394c1c5792dc.TID143.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 154 (task 143, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 154 (task 143, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.1.delta.dc597ac6-d32c-42bb-8f16-30db2a83790e.TID142.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 1.0 (TID 142). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 157.0 in stage 1.0 (TID 146, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 157.0 in stage 1.0 (TID 146)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 1.0 (TID 142) in 276 ms on localhost (executor driver) (142/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.1.delta.36b9b075-fed9-4e66-ac8d-784f40501c10.TID145.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.1.delta.524010b4-b371-4d3b-bd14-d141d3e9ed16.TID144.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 155 (task 144, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 155 (task 144, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.1.delta.285c68cb-ac22-4822-9daf-9a619fc0dece.TID143.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 1.0 (TID 143). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 158.0 in stage 1.0 (TID 147, localhost, executor driver, partition 158, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 1.0 (TID 143) in 268 ms on localhost (executor driver) (143/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 158.0 in stage 1.0 (TID 147)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@693f5061
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,157,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23813e0a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,157,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ae83f90
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,158,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20dfa739
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,158,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.1.delta.b576de47-a12f-4243-a854-52e45fc4682c.TID144.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 1.0 (TID 144). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 160.0 in stage 1.0 (TID 148, localhost, executor driver, partition 160, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 1.0 (TID 144) in 275 ms on localhost (executor driver) (144/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 160.0 in stage 1.0 (TID 148)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.1.delta.90b24ce0-71b0-4d7d-87ae-0e1314e5a909.TID146.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c8f4149
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,160,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11a436cb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,160,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.1.delta.36b9b075-fed9-4e66-ac8d-784f40501c10.TID145.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 156 (task 145, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 156 (task 145, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,516][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.1.delta.d7e0999a-4834-479a-9fc5-0a433cd6c591.TID147.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.1.delta.8771edfe-540f-432e-93aa-da76c90cdfab.TID145.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,542][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 1.0 (TID 145). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 161.0 in stage 1.0 (TID 149, localhost, executor driver, partition 161, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.1.delta.1904d750-f65e-47b8-9e54-adf90f4a6a78.TID148.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 161.0 in stage 1.0 (TID 149)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 1.0 (TID 145) in 203 ms on localhost (executor driver) (145/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.1.delta.90b24ce0-71b0-4d7d-87ae-0e1314e5a909.TID146.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 157 (task 146, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 157 (task 146, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@688b427c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,161,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@363db824
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,161,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.1.delta.d7e0999a-4834-479a-9fc5-0a433cd6c591.TID147.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 158 (task 147, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 158 (task 147, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.1.delta.1d9c9cdb-8212-409c-9a51-d0501da9a787.TID146.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 1.0 (TID 146). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 162.0 in stage 1.0 (TID 150, localhost, executor driver, partition 162, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 1.0 (TID 146) in 208 ms on localhost (executor driver) (146/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 162.0 in stage 1.0 (TID 150)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.1.delta.9e4323f2-cb34-4f51-83e9-761a744cf0f9.TID149.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.1.delta.1904d750-f65e-47b8-9e54-adf90f4a6a78.TID148.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 160 (task 148, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 160 (task 148, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af1642d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,162,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53a1a6c0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,162,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.1.delta.54b6a360-cd5e-4227-9e69-358d345f28ef.TID147.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 1.0 (TID 147). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 163.0 in stage 1.0 (TID 151, localhost, executor driver, partition 163, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 1.0 (TID 147) in 226 ms on localhost (executor driver) (147/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 163.0 in stage 1.0 (TID 151)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.1.delta.6096c2f9-31f8-4ec7-b9f6-855d5f75d9b5.TID148.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25619ef2
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,163,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bc68c86
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,163,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 1.0 (TID 148). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 164.0 in stage 1.0 (TID 152, localhost, executor driver, partition 164, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 1.0 (TID 148) in 248 ms on localhost (executor driver) (148/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 164.0 in stage 1.0 (TID 152)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.1.delta.963e5bab-52fd-48f2-8c7d-b8b9bbfe6ff1.TID150.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.1.delta.9e4323f2-cb34-4f51-83e9-761a744cf0f9.TID149.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 161 (task 149, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 161 (task 149, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c7fcb2d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,164,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e64aa2d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,164,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.1.delta.e6d33b54-fb36-4751-96cd-660f02dfb119.TID151.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.1.delta.1bf94132-11f7-4b61-88b9-db2f6fcf44bf.TID149.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 1.0 (TID 149). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 165.0 in stage 1.0 (TID 153, localhost, executor driver, partition 165, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 165.0 in stage 1.0 (TID 153)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 1.0 (TID 149) in 250 ms on localhost (executor driver) (149/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.1.delta.9501db3c-afc3-4b1d-ad52-fa86ecf4b408.TID152.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.1.delta.963e5bab-52fd-48f2-8c7d-b8b9bbfe6ff1.TID150.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 162 (task 150, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 162 (task 150, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bbec71f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,165,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20048e7f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,165,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.1.delta.e6d33b54-fb36-4751-96cd-660f02dfb119.TID151.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.1.delta.de63bbab-f0e7-4674-aa65-6fcc198dcbf4.TID150.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 163 (task 151, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 1.0 (TID 150). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 163 (task 151, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 166.0 in stage 1.0 (TID 154, localhost, executor driver, partition 166, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 1.0 (TID 150) in 244 ms on localhost (executor driver) (150/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 166.0 in stage 1.0 (TID 154)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.1.delta.cf8ccc52-0980-4dfe-a076-6d471fcb95fd.TID153.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25090f7a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,888][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,166,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,888][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@441b2974
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,166,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.1.delta.9501db3c-afc3-4b1d-ad52-fa86ecf4b408.TID152.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 164 (task 152, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 164 (task 152, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,901][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.1.delta.de434fc4-f1c3-43b5-be99-1ccef91a88e2.TID151.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 1.0 (TID 151). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 167.0 in stage 1.0 (TID 155, localhost, executor driver, partition 167, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 1.0 (TID 151) in 245 ms on localhost (executor driver) (151/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 167.0 in stage 1.0 (TID 155)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a0fdb7b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,167,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28e0ba78
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,167,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.1.delta.de404af0-b849-4cf3-ab05-8e923b0ce4b9.TID154.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.1.delta.64decccd-96ad-4914-b98d-5dc531dabb8e.TID152.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 1.0 (TID 152). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 168.0 in stage 1.0 (TID 156, localhost, executor driver, partition 168, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 1.0 (TID 152) in 234 ms on localhost (executor driver) (152/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 168.0 in stage 1.0 (TID 156)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.1.delta.cf8ccc52-0980-4dfe-a076-6d471fcb95fd.TID153.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 165 (task 153, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 165 (task 153, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ab385fc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,168,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c647ffa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,168,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:53,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.1.delta.6f06649c-feea-4af0-a5d5-2b090e60363d.TID155.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.1.delta.33a0f079-74bd-49b8-a675-25cf86db0a09.TID153.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 1.0 (TID 153). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 169.0 in stage 1.0 (TID 157, localhost, executor driver, partition 169, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 1.0 (TID 153) in 225 ms on localhost (executor driver) (153/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 169.0 in stage 1.0 (TID 157)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.1.delta.1022517d-0118-4afa-af70-941a0f9ae7d6.TID156.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.1.delta.de404af0-b849-4cf3-ab05-8e923b0ce4b9.TID154.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 166 (task 154, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 166 (task 154, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6afe2d97
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,169,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@714fd022
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,169,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.1.delta.6f06649c-feea-4af0-a5d5-2b090e60363d.TID155.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 167 (task 155, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 167 (task 155, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.1.delta.66912aa4-70a4-4d3b-82f5-2f434a5ee3c7.TID154.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 1.0 (TID 154). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 170.0 in stage 1.0 (TID 158, localhost, executor driver, partition 170, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 1.0 (TID 154) in 211 ms on localhost (executor driver) (154/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 170.0 in stage 1.0 (TID 158)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.1.delta.5e6f2c6d-d446-403c-ba34-3fc50a750189.TID157.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@365e9c54
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,170,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.1.delta.1022517d-0118-4afa-af70-941a0f9ae7d6.TID156.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a124573
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,170,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 168 (task 156, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 168 (task 156, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.1.delta.be58966e-5510-436d-90cd-2550794ccae9.TID155.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 1.0 (TID 155). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 171.0 in stage 1.0 (TID 159, localhost, executor driver, partition 171, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 1.0 (TID 155) in 210 ms on localhost (executor driver) (155/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 171.0 in stage 1.0 (TID 159)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e956e0a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,171,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f86e880
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,171,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.1.delta.2d01e7ef-6ebc-4469-954a-d9373a9a9664.TID156.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.1.delta.62c9f491-074e-450c-ae40-3976a5be6573.TID158.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 1.0 (TID 156). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 172.0 in stage 1.0 (TID 160, localhost, executor driver, partition 172, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 1.0 (TID 156) in 240 ms on localhost (executor driver) (156/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 172.0 in stage 1.0 (TID 160)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f75d857
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.1.delta.5e6f2c6d-d446-403c-ba34-3fc50a750189.TID157.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,172,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.1.delta.4169174e-10b8-4009-b92b-009e28b89fbc.TID159.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,213][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36baf673
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,172,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 169 (task 157, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 169 (task 157, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.1.delta.5b531bce-0f42-4b74-ba30-add67a27a433.TID157.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 1.0 (TID 157). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 173.0 in stage 1.0 (TID 161, localhost, executor driver, partition 173, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 1.0 (TID 157) in 256 ms on localhost (executor driver) (157/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 173.0 in stage 1.0 (TID 161)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.1.delta.b969c8f4-cce5-44fc-9e1a-24f3163e7354.TID160.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.1.delta.62c9f491-074e-450c-ae40-3976a5be6573.TID158.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 170 (task 158, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 170 (task 158, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@148e49f7
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,173,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c0e5a10
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,173,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.1.delta.4169174e-10b8-4009-b92b-009e28b89fbc.TID159.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 171 (task 159, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 171 (task 159, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.1.delta.98620edf-a402-4658-be16-bf55d13aa333.TID158.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 1.0 (TID 158). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 174.0 in stage 1.0 (TID 162, localhost, executor driver, partition 174, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 1.0 (TID 158) in 269 ms on localhost (executor driver) (158/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 174.0 in stage 1.0 (TID 162)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.1.delta.d93f2c2a-dca9-4514-a66d-cd7a5b79671a.TID161.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.1.delta.1f6158cc-c858-4c44-b46a-e564645791aa.TID159.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 1.0 (TID 159). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27768ca9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 175.0 in stage 1.0 (TID 163, localhost, executor driver, partition 175, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,174,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 1.0 (TID 159) in 259 ms on localhost (executor driver) (159/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 175.0 in stage 1.0 (TID 163)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5d68f0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,174,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.1.delta.b969c8f4-cce5-44fc-9e1a-24f3163e7354.TID160.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 172 (task 160, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 172 (task 160, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@86321d0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,175,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc5d1f4
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,175,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.1.delta.5688de95-8ee9-48a3-99d9-c527d5fe3cd6.TID160.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.1.delta.ef896a9c-c30c-4fe9-9e9d-39c1624b5adc.TID162.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 1.0 (TID 160). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 176.0 in stage 1.0 (TID 164, localhost, executor driver, partition 176, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 176.0 in stage 1.0 (TID 164)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 1.0 (TID 160) in 261 ms on localhost (executor driver) (160/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.1.delta.f95f21b1-3d4b-4687-8742-057004e5e8da.TID163.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.1.delta.d93f2c2a-dca9-4514-a66d-cd7a5b79671a.TID161.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 173 (task 161, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 173 (task 161, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@684f746c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,176,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5402507c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,176,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.1.delta.04c54b9d-bb20-499f-bd49-8c05fbc6e394.TID161.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 1.0 (TID 161). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 177.0 in stage 1.0 (TID 165, localhost, executor driver, partition 177, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 1.0 (TID 161) in 247 ms on localhost (executor driver) (161/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.1.delta.e344814a-499b-4f3b-afe6-8fc1bbda16a3.TID164.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 177.0 in stage 1.0 (TID 165)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.1.delta.ef896a9c-c30c-4fe9-9e9d-39c1624b5adc.TID162.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 174 (task 162, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 174 (task 162, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c4bd6ae
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.1.delta.f95f21b1-3d4b-4687-8742-057004e5e8da.TID163.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,177,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41fa30f8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,177,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 175 (task 163, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 175 (task 163, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.1.delta.82470b5e-a605-4ee2-babd-4a514b4e5aa0.TID162.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 1.0 (TID 162). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 178.0 in stage 1.0 (TID 166, localhost, executor driver, partition 178, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 1.0 (TID 162) in 235 ms on localhost (executor driver) (162/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 178.0 in stage 1.0 (TID 166)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.1.delta.a4196b1c-48f6-49a5-8376-b6f1008089e6.TID163.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 1.0 (TID 163). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 179.0 in stage 1.0 (TID 167, localhost, executor driver, partition 179, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 1.0 (TID 163) in 231 ms on localhost (executor driver) (163/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 179.0 in stage 1.0 (TID 167)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41aa834e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,178,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.1.delta.e344814a-499b-4f3b-afe6-8fc1bbda16a3.TID164.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 176 (task 164, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 176 (task 164, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.1.delta.3662227d-513c-4b3f-b3e8-a5c8be39b274.TID165.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748d2e08
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,179,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78b1ee5f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,178,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52b25046
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,179,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.1.delta.3b63215f-ea2f-4d08-a04b-c3cba25103f1.TID164.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 1.0 (TID 164). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 180.0 in stage 1.0 (TID 168, localhost, executor driver, partition 180, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 1.0 (TID 164) in 215 ms on localhost (executor driver) (164/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 180.0 in stage 1.0 (TID 168)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.1.delta.59147e54-cc38-4124-a75c-459e7b7e7bf1.TID167.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.1.delta.c7cc6c6e-3a07-4c33-a33e-33ba6a9168cb.TID166.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20356c04
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,180,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f7ae5b3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,180,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.1.delta.3662227d-513c-4b3f-b3e8-a5c8be39b274.TID165.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 177 (task 165, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 177 (task 165, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.1.delta.1a4070da-5e38-41dd-9577-757fa3382e31.TID168.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.1.delta.0c5d6086-2790-4cb4-b0e5-f0cf1de06894.TID165.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.1.delta.59147e54-cc38-4124-a75c-459e7b7e7bf1.TID167.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.1.delta.c7cc6c6e-3a07-4c33-a33e-33ba6a9168cb.TID166.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 178 (task 166, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 178 (task 166, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 179 (task 167, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 1.0 (TID 165). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 179 (task 167, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 181.0 in stage 1.0 (TID 169, localhost, executor driver, partition 181, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 1.0 (TID 165) in 239 ms on localhost (executor driver) (165/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 181.0 in stage 1.0 (TID 169)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c84160a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,181,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17b10560
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,181,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.1.delta.ff873087-5424-4358-9455-edba99c8db33.TID166.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.1.delta.c713d6a8-9de0-44e2-bf83-1adca0757ebf.TID167.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 1.0 (TID 166). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 1.0 (TID 167). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 182.0 in stage 1.0 (TID 170, localhost, executor driver, partition 182, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 182.0 in stage 1.0 (TID 170)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 183.0 in stage 1.0 (TID 171, localhost, executor driver, partition 183, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 1.0 (TID 166) in 262 ms on localhost (executor driver) (166/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 183.0 in stage 1.0 (TID 171)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 1.0 (TID 167) in 238 ms on localhost (executor driver) (167/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.1.delta.1a4070da-5e38-41dd-9577-757fa3382e31.TID168.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 180 (task 168, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 180 (task 168, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.1.delta.597a8059-176a-4093-8fe5-de944be1ef11.TID169.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@160d8eda
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,182,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fe211cb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,183,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b156d7e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,182,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47dfe544
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,183,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.1.delta.f8d91f1c-0ad9-44ff-949d-ee5b3220c128.TID168.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 1.0 (TID 168). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 184.0 in stage 1.0 (TID 172, localhost, executor driver, partition 184, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 1.0 (TID 168) in 240 ms on localhost (executor driver) (168/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 184.0 in stage 1.0 (TID 172)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.1.delta.cb0ee5e7-c455-403b-806d-d504c90105fe.TID170.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24be8ab9
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,184,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e86f2c5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,184,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.1.delta.0a49b505-75db-465f-a4e4-93a529a1518e.TID171.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.1.delta.597a8059-176a-4093-8fe5-de944be1ef11.TID169.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 181 (task 169, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 181 (task 169, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.1.delta.dec1c2f7-c832-487b-a460-ccc93a7c42ac.TID172.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.1.delta.13c9bcc9-a584-4390-ab3d-f87607254081.TID169.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 1.0 (TID 169). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 185.0 in stage 1.0 (TID 173, localhost, executor driver, partition 185, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 1.0 (TID 169) in 235 ms on localhost (executor driver) (169/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:54,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 185.0 in stage 1.0 (TID 173)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@543d22dc
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.1.delta.cb0ee5e7-c455-403b-806d-d504c90105fe.TID170.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,185,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2171799a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,185,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 182 (task 170, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 182 (task 170, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.1.delta.0a49b505-75db-465f-a4e4-93a529a1518e.TID171.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 183 (task 171, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 183 (task 171, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.1.delta.68bd6056-f3df-4306-912a-4683fe67e039.TID170.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.1.delta.dec1c2f7-c832-487b-a460-ccc93a7c42ac.TID172.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 1.0 (TID 170). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 186.0 in stage 1.0 (TID 174, localhost, executor driver, partition 186, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 1.0 (TID 170) in 215 ms on localhost (executor driver) (170/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 186.0 in stage 1.0 (TID 174)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 184 (task 172, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 184 (task 172, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.1.delta.aa14d48d-ae87-4888-918e-c693b478bed7.TID173.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.1.delta.cf687ae9-ba9f-4401-a831-85b2b39d7dbb.TID171.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 1.0 (TID 171). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 187.0 in stage 1.0 (TID 175, localhost, executor driver, partition 187, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 1.0 (TID 171) in 226 ms on localhost (executor driver) (171/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 187.0 in stage 1.0 (TID 175)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41c5626e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,186,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.1.delta.5793c7f9-d935-4813-b247-68ce9f8e85aa.TID172.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 1.0 (TID 172). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 188.0 in stage 1.0 (TID 176, localhost, executor driver, partition 188, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 1.0 (TID 172) in 217 ms on localhost (executor driver) (172/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 188.0 in stage 1.0 (TID 176)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@796ece64
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,187,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26d63757
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,188,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@86d1345
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,186,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@693e19f8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,188,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62007fcb
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,187,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.1.delta.aa14d48d-ae87-4888-918e-c693b478bed7.TID173.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 185 (task 173, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 185 (task 173, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.1.delta.d820ceac-f86f-4c13-b55b-1708aee35247.TID175.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.1.delta.f89869b9-f186-4672-b711-067aadb8bd7d.TID174.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.1.delta.2f4ff23c-bfd9-46f7-b6c5-77c67d068ddd.TID176.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.1.delta.64d71ad8-dd5e-4e60-937f-a9069c824511.TID173.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 1.0 (TID 173). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 189.0 in stage 1.0 (TID 177, localhost, executor driver, partition 189, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 1.0 (TID 173) in 383 ms on localhost (executor driver) (173/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 189.0 in stage 1.0 (TID 177)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7450d38e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,189,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@158932c3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,189,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.1.delta.2f4ff23c-bfd9-46f7-b6c5-77c67d068ddd.TID176.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 188 (task 176, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 188 (task 176, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.1.delta.f89869b9-f186-4672-b711-067aadb8bd7d.TID174.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 186 (task 174, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 186 (task 174, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.1.delta.f9dc052c-3031-46b7-b185-139c2041ca1c.TID177.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.1.delta.d820ceac-f86f-4c13-b55b-1708aee35247.TID175.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 187 (task 175, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 187 (task 175, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.1.delta.5fcf2ebf-952c-4413-adb4-f1c34eab362a.TID176.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.1.delta.c22ea3d6-94e2-4b89-b23b-c04dc24e583f.TID174.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 1.0 (TID 176). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 191.0 in stage 1.0 (TID 178, localhost, executor driver, partition 191, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 191.0 in stage 1.0 (TID 178)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 1.0 (TID 176) in 399 ms on localhost (executor driver) (174/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.1.delta.7e247d34-49c2-4ad1-a98a-49caa52ae315.TID175.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 1.0 (TID 174). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 193.0 in stage 1.0 (TID 179, localhost, executor driver, partition 193, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 1.0 (TID 174) in 469 ms on localhost (executor driver) (175/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 193.0 in stage 1.0 (TID 179)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 1.0 (TID 175). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 194.0 in stage 1.0 (TID 180, localhost, executor driver, partition 194, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 1.0 (TID 175) in 462 ms on localhost (executor driver) (176/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 194.0 in stage 1.0 (TID 180)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2755b26e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,191,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.1.delta.f9dc052c-3031-46b7-b185-139c2041ca1c.TID177.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 189 (task 177, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 189 (task 177, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44794a8a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,194,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bef22fa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,193,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d0a71c0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,194,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@503400e0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,191,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6544e671
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,193,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.1.delta.4c10659c-ed1c-4f2f-8c2a-4c6e9b6b73ff.TID177.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 1.0 (TID 177). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 195.0 in stage 1.0 (TID 181, localhost, executor driver, partition 195, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 1.0 (TID 177) in 241 ms on localhost (executor driver) (177/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 195.0 in stage 1.0 (TID 181)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.1.delta.9cc9b13f-fe94-444a-8546-32c7d00c1e53.TID179.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7daaea99
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,195,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71983c15
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,195,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.1.delta.58e0912c-46c2-4d90-91b6-6e80bde5ee24.TID180.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.1.delta.2aebebcb-040f-4c41-9dee-855693b0953f.TID178.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.1.delta.685863c9-da89-40e4-b141-57761b86c277.TID181.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.1.delta.9cc9b13f-fe94-444a-8546-32c7d00c1e53.TID179.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.1.delta.2aebebcb-040f-4c41-9dee-855693b0953f.TID178.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 193 (task 179, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 193 (task 179, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.1.delta.58e0912c-46c2-4d90-91b6-6e80bde5ee24.TID180.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 191 (task 178, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 191 (task 178, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 194 (task 180, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 194 (task 180, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.1.delta.6fb916f3-d314-49b0-b39a-c8582ca57093.TID179.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.1.delta.e71a69d8-3ae6-48da-91e8-03cd3915f3c3.TID178.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.1.delta.065ed9c9-ff38-4f41-b6e4-a8785fc78835.TID180.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 1.0 (TID 179). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 1.0 (TID 178). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 196.0 in stage 1.0 (TID 182, localhost, executor driver, partition 196, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 197.0 in stage 1.0 (TID 183, localhost, executor driver, partition 197, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 196.0 in stage 1.0 (TID 182)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 1.0 (TID 179) in 261 ms on localhost (executor driver) (178/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 197.0 in stage 1.0 (TID 183)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 1.0 (TID 180). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 1.0 (TID 178) in 263 ms on localhost (executor driver) (179/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 198.0 in stage 1.0 (TID 184, localhost, executor driver, partition 198, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 1.0 (TID 180) in 257 ms on localhost (executor driver) (180/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 198.0 in stage 1.0 (TID 184)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.1.delta.685863c9-da89-40e4-b141-57761b86c277.TID181.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 195 (task 181, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 195 (task 181, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43decc2d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,196,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2592459
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,197,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.1.delta.b69af1b7-6328-4360-a750-5c600294a60a.TID181.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 1.0 (TID 181). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 199.0 in stage 1.0 (TID 185, localhost, executor driver, partition 199, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 1.0 (TID 181) in 207 ms on localhost (executor driver) (181/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 199.0 in stage 1.0 (TID 185)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@89fc058
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,198,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22417f78
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,198,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b93604d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,199,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1928851b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,197,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f2b1e8a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,196,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2645f86
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,199,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.1.delta.4808ed94-c375-4011-8149-0a5251db03f1.TID184.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.1.delta.bce19aeb-7d46-4203-8505-fb25cd8cc735.TID183.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.1.delta.2539ee6f-380d-41df-a3e7-c7d0c6e6d07f.TID182.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,916][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.1.delta.cfe50de5-9c93-48df-a287-5412e394a370.TID185.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.1.delta.4808ed94-c375-4011-8149-0a5251db03f1.TID184.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 198 (task 184, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 198 (task 184, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.1.delta.bce19aeb-7d46-4203-8505-fb25cd8cc735.TID183.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.1.delta.2539ee6f-380d-41df-a3e7-c7d0c6e6d07f.TID182.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 196 (task 182, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 197 (task 183, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 196 (task 182, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 197 (task 183, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.1.delta.cfe50de5-9c93-48df-a287-5412e394a370.TID185.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 199 (task 185, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:55,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 199 (task 185, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.1.delta.f50a88d0-6832-46bd-a67e-46c74c340f89.TID184.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.1.delta.86be6bbe-cf9a-4baf-aecc-cd8758cd1345.TID182.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.1.delta.df9457d7-6b86-445e-abd1-d33735756651.TID183.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 1.0 (TID 184). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 1.0 (TID 182). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 1.0 (TID 186, localhost, executor driver, partition 0, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 1.0 (TID 183). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 19.0 in stage 1.0 (TID 187, localhost, executor driver, partition 19, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 1.0 (TID 186)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 30.0 in stage 1.0 (TID 188, localhost, executor driver, partition 30, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 19.0 in stage 1.0 (TID 187)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 1.0 (TID 184) in 240 ms on localhost (executor driver) (182/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 30.0 in stage 1.0 (TID 188)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 1.0 (TID 182) in 244 ms on localhost (executor driver) (183/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 1.0 (TID 183) in 244 ms on localhost (executor driver) (184/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.1.delta.428f9edb-b913-47b9-b932-e23668e613b4.TID185.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 1.0 (TID 185). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 46.0 in stage 1.0 (TID 189, localhost, executor driver, partition 46, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 1.0 (TID 185) in 209 ms on localhost (executor driver) (185/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 46.0 in stage 1.0 (TID 189)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33beea0b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7beee581
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@228bb2aa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@160cf1e8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77fd5299
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c6ed11e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e65b1d1
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d5290c3
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 13.454098 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.1.delta.34de17f6-af15-49ae-a926-334e1c4c02a5.TID188.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.1.delta.bad21f04-ee68-40c0-a692-1593ee7fd3fa.TID189.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.1.delta.7333ee3c-9694-4c51-9e5f-f01d7cdb6afd.TID187.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.1.delta.f5768868-1a78-4d43-a72f-f8fab9cde621.TID186.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.1.delta.bad21f04-ee68-40c0-a692-1593ee7fd3fa.TID189.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.1.delta.34de17f6-af15-49ae-a926-334e1c4c02a5.TID188.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 24.439368 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 30 (task 188, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 46 (task 189, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 30 (task 188, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 46 (task 189, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.1.delta.7333ee3c-9694-4c51-9e5f-f01d7cdb6afd.TID187.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 19 (task 187, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 19 (task 187, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.1.delta.f5768868-1a78-4d43-a72f-f8fab9cde621.TID186.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 0 (task 186, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 0 (task 186, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.1.delta.11535920-5769-4ee3-8432-05e084900226.TID188.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 1.0 (TID 188). 5208 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 56.0 in stage 1.0 (TID 190, localhost, executor driver, partition 56, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 56.0 in stage 1.0 (TID 190)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 1.0 (TID 188) in 462 ms on localhost (executor driver) (186/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.1.delta.dbdb5c47-a200-4be6-920b-ea9ce988a548.TID187.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 1.0 (TID 187). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 66.0 in stage 1.0 (TID 191, localhost, executor driver, partition 66, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 1.0 (TID 187) in 468 ms on localhost (executor driver) (187/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 66.0 in stage 1.0 (TID 191)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.1.delta.5a24ec92-1fe6-40ba-b26f-9376b42dc115.TID189.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 1.0 (TID 189). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 67.0 in stage 1.0 (TID 192, localhost, executor driver, partition 67, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 1.0 (TID 189) in 476 ms on localhost (executor driver) (188/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 67.0 in stage 1.0 (TID 192)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76a73296
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.1.delta.4efa2291-4141-45aa-a14e-d0d2e0e24d46.TID186.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 186). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 72.0 in stage 1.0 (TID 193, localhost, executor driver, partition 72, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 186) in 501 ms on localhost (executor driver) (189/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 72.0 in stage 1.0 (TID 193)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66fdac0f
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@266e0d94
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@201f322b
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40ff6345
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b1f5136
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2afd81e8
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3da8be2d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.1.delta.c19d434b-e137-41b5-b8b4-bbd738c84388.TID191.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.1.delta.5384c9f8-245a-4c45-8a0e-a6a225bc6a3a.TID192.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.1.delta.cd029797-3e4e-4b49-9b66-a44cc6a07701.TID193.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.1.delta.9bfb9c85-92ed-49e2-95c3-190a05eca156.TID190.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.1.delta.c19d434b-e137-41b5-b8b4-bbd738c84388.TID191.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.1.delta.9bfb9c85-92ed-49e2-95c3-190a05eca156.TID190.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 66 (task 191, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 66 (task 191, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 56 (task 190, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 56 (task 190, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.1.delta.cd029797-3e4e-4b49-9b66-a44cc6a07701.TID193.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 72 (task 193, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 72 (task 193, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.1.delta.5384c9f8-245a-4c45-8a0e-a6a225bc6a3a.TID192.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 67 (task 192, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:56,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 67 (task 192, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.1.delta.c4a41a91-4c62-4d23-b3db-87f3d42c92b3.TID192.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.1.delta.1261a487-6376-4eef-b1df-389160b57201.TID193.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 1.0 (TID 192). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 108.0 in stage 1.0 (TID 194, localhost, executor driver, partition 108, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 108.0 in stage 1.0 (TID 194)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 1.0 (TID 192) in 546 ms on localhost (executor driver) (190/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.1.delta.706111aa-f104-4d0a-a3bb-e0c4cd4e2a50.TID191.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 1.0 (TID 193). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 116.0 in stage 1.0 (TID 195, localhost, executor driver, partition 116, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 116.0 in stage 1.0 (TID 195)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 1.0 (TID 193) in 531 ms on localhost (executor driver) (191/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 1.0 (TID 191). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.1.delta.1edd9a4a-0d14-4c42-a8b8-d44735def9bb.TID190.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 118.0 in stage 1.0 (TID 196, localhost, executor driver, partition 118, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 1.0 (TID 191) in 569 ms on localhost (executor driver) (192/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 118.0 in stage 1.0 (TID 196)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 1.0 (TID 190). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 129.0 in stage 1.0 (TID 197, localhost, executor driver, partition 129, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 1.0 (TID 190) in 580 ms on localhost (executor driver) (193/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 129.0 in stage 1.0 (TID 197)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e42699c
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e9a5e67
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f961b9e
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@734ec9c1
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ac2acaa
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.1.delta.fc3188c0-8512-4fb6-8ea3-65f0318ae241.TID194.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@333633a0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a816bb0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37abd9fe
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.1.delta.dd2c08a9-4a8d-49cc-8a7a-26d304a6c600.TID197.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.1.delta.0a5ee119-6912-4edd-9a77-fd7ec19fc67f.TID195.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.1.delta.0fcfe4a9-7378-4a73-89b9-5618482552f7.TID196.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.1.delta.fc3188c0-8512-4fb6-8ea3-65f0318ae241.TID194.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 108 (task 194, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 108 (task 194, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.1.delta.dd2c08a9-4a8d-49cc-8a7a-26d304a6c600.TID197.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 129 (task 197, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 129 (task 197, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.1.delta.4391e3be-db0e-42a5-ba49-b460679365dd.TID194.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 1.0 (TID 194). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 159.0 in stage 1.0 (TID 198, localhost, executor driver, partition 159, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 1.0 (TID 194) in 299 ms on localhost (executor driver) (194/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 159.0 in stage 1.0 (TID 198)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.1.delta.258caf48-1c07-4785-8643-00b532cade76.TID197.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 1.0 (TID 197). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 190.0 in stage 1.0 (TID 199, localhost, executor driver, partition 190, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 1.0 (TID 197) in 308 ms on localhost (executor driver) (195/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 190.0 in stage 1.0 (TID 199)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5334a6c1
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,159,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a679f7a
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.1.delta.0a5ee119-6912-4edd-9a77-fd7ec19fc67f.TID195.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,159,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 116 (task 195, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 116 (task 195, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.1.delta.0fcfe4a9-7378-4a73-89b9-5618482552f7.TID196.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 118 (task 196, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 118 (task 196, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c28917d
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,190,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dd4f740
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,190,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.1.delta.80f0eaa7-2ba2-458c-9eb0-b60ba2f8c03b.TID198.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.1.delta.a5ee7b38-3205-4484-aa69-a4a52b9e7e48.TID196.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.1.delta.b0a7ea5d-a948-4a2a-8dda-6efa5c2a53e0.TID195.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 1.0 (TID 196). 5208 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 192.0 in stage 1.0 (TID 200, localhost, executor driver, partition 192, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 1.0 (TID 196) in 382 ms on localhost (executor driver) (196/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 192.0 in stage 1.0 (TID 200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 1.0 (TID 195). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 1.0 (TID 195) in 389 ms on localhost (executor driver) (197/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.1.delta.38533d0d-ab49-48f2-b031-ba49df1e02e2.TID199.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@769df693
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,192,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f3498e5
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,192,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.1.delta.5a99fc9f-7c2d-45c0-82df-dc65cae57bae.TID200.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.1.delta.80f0eaa7-2ba2-458c-9eb0-b60ba2f8c03b.TID198.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 159 (task 198, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 159 (task 198, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.1.delta.38533d0d-ab49-48f2-b031-ba49df1e02e2.TID199.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 190 (task 199, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 190 (task 199, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.1.delta.0ab14f0f-91bb-46b2-9120-90d11f28df77.TID198.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 1.0 (TID 198). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 1.0 (TID 198) in 243 ms on localhost (executor driver) (198/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.1.delta.68fef8fb-08d9-4976-ac77-0e72213c3283.TID199.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 1.0 (TID 199). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 1.0 (TID 199) in 231 ms on localhost (executor driver) (199/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.1.delta.5a99fc9f-7c2d-45c0-82df-dc65cae57bae.TID200.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/1.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 192 (task 200, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 192 (task 200, attempt 0stage 1.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/1.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.1.delta.6d5a6ff8-afc2-4056-9425-40e6a43904ce.TID200.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192]
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 1.0 (TID 200). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 1.0 (TID 200) in 200 ms on localhost (executor driver) (200/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 1.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 1 (start at StreamingFile.scala:61) finished in 16,120 s
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 0 finished: start at StreamingFile.scala:61, took 16,803860 s
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@164ac59c is committing.
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 9.900004 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 11.847619 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@164ac59c committed.
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 1 finished: start at StreamingFile.scala:61, took 0,000042 s
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/0 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/.0.eabb1335-cc0a-4591-8f8a-cd8ff10c3274.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/.0.eabb1335-cc0a-4591-8f8a-cd8ff10c3274.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/0
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:38.002Z",
  "batchId" : 0,
  "numInputRows" : 100,
  "inputRowsPerSecond" : 50.050050050050054,
  "processedRowsPerSecond" : 5.019828321871392,
  "durationMs" : {
    "addBatch" : 18907,
    "getBatch" : 67,
    "getOffset" : 388,
    "queryPlanning" : 314,
    "triggerExecution" : 19921,
    "walCommit" : 81
  },
  "stateOperators" : [ {
    "numRowsTotal" : 15,
    "numRowsUpdated" : 15,
    "memoryUsedBytes" : 45599,
    "customMetrics" : {
      "loadedMapCacheHitCount" : 0,
      "loadedMapCacheMissCount" : 0,
      "stateOnCurrentVersionSizeBytes" : 16799
    }
  } ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : null,
    "endOffset" : {
      "logOffset" : 0
    },
    "numInputRows" : 100,
    "inputRowsPerSecond" : 50.050050050050054,
    "processedRowsPerSecond" : 5.019828321871392
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[31m[WARN ][0;39m [35m[2019-05-02 11:05:57,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logWarning][0;39m | Current batch is falling behind. The trigger interval is 2000 milliseconds, but spent 19946 milliseconds
[34m[INFO ][0;39m [35m[2019-05-02 11:05:57,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:05:57.951Z",
  "batchId" : 1,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 6,
    "triggerExecution" : 10
  },
  "stateOperators" : [ {
    "numRowsTotal" : 15,
    "numRowsUpdated" : 0,
    "memoryUsedBytes" : 45599,
    "customMetrics" : {
      "loadedMapCacheHitCount" : 0,
      "loadedMapCacheMissCount" : 0,
      "stateOnCurrentVersionSizeBytes" : 16799
    }
  } ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : {
      "logOffset" : 0
    },
    "endOffset" : {
      "logOffset" : 0
    },
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:06:08,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:06:08.003Z",
  "batchId" : 1,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 3,
    "triggerExecution" : 4
  },
  "stateOperators" : [ {
    "numRowsTotal" : 15,
    "numRowsUpdated" : 0,
    "memoryUsedBytes" : 45599,
    "customMetrics" : {
      "loadedMapCacheHitCount" : 0,
      "loadedMapCacheMissCount" : 0,
      "stateOnCurrentVersionSizeBytes" : 16799
    }
  } ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : {
      "logOffset" : 0
    },
    "endOffset" : {
      "logOffset" : 0
    },
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/1 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.1.947102ec-1c80-4296-9d0f-85556b1e4f2a.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.1.947102ec-1c80-4296-9d0f-85556b1e4f2a.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Log offset set to 1 with 1 new files
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,392][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/1 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.1.59adba98-f12c-489e-90db-81a57660ff3b.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.1.59adba98-f12c-489e-90db-81a57660ff3b.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed offsets for batch 1. Metadata OffsetSeqMetadata(0,1556805978325,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Processing 1 files from 1:1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<carrier: string, marital_status: string>
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_5 stored as values in memory (estimated size 221.7 KB, free 911.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_5_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 5 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_6 stored as values in memory (estimated size 220.7 KB, free 911.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_6_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:18,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 6 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_7 stored as values in memory (estimated size 220.7 KB, free 910.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.7 KB, free 910.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,204][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_7_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,204][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 7 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,213][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@19fe512e. The input RDD has 200 partitions.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering RDD 13 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 2 (start at StreamingFile.scala:61) with 200 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 3 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List(ShuffleMapStage 2)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List(ShuffleMapStage 2)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_8 stored as values in memory (estimated size 28.1 KB, free 910.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.6 KB, free 910.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_8_piece0 in memory on mac-180:55122 (size: 13.6 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 8 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 2.0 with 1 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 2.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 8357 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 2.0 (TID 201)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/stream_in/user-record.2.csv, range: 0-6869, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 2.0 (TID 201). 2395 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 2.0 (TID 201) in 79 ms on localhost (executor driver) (1/1)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 2.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ShuffleMapStage 2 (start at StreamingFile.scala:61) finished in 0,085 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | looking for newly runnable stages
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | running: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | waiting: Set(ResultStage 3)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | failed: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 3 (MapPartitionsRDD[19] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_9 stored as values in memory (estimated size 55.6 KB, free 910.7 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.5 KB, free 910.7 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_9_piece0 in memory on mac-180:55122 (size: 23.5 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 9 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 200 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 3.0 with 200 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 3.0 (TID 203, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 3.0 (TID 204, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 3.0 (TID 205, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 3.0 (TID 205)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 3.0 (TID 204)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 3.0 (TID 203)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 3.0 (TID 202)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d64a4c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@614750b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28b0cdbd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46262472
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@631d76ab
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6622b7e2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@564a34ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b7efe82
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.2.delta.75b319ab-8fd0-4289-b491-a5c2763593ae.TID204.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.2.delta.e82ef810-d3a9-4405-9505-ebbf9fc929de.TID205.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.2.delta.072f80f7-0342-4e9c-8f10-ad0ad655718d.TID203.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.2.delta.9bc71134-d613-49a7-bb1f-03da435b1e9c.TID202.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.2.delta.072f80f7-0342-4e9c-8f10-ad0ad655718d.TID203.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,555][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 1 (task 203, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 1 (task 203, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.2.delta.e82ef810-d3a9-4405-9505-ebbf9fc929de.TID205.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 3 (task 205, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 3 (task 205, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.2.delta.75b319ab-8fd0-4289-b491-a5c2763593ae.TID204.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 2 (task 204, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 2 (task 204, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.2.delta.9bc71134-d613-49a7-bb1f-03da435b1e9c.TID202.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 0 (task 202, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 0 (task 202, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.2.delta.31b707aa-6288-4bcd-84f3-483c281107bb.TID203.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 3.0 (TID 203). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 4.0 in stage 3.0 (TID 206, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.2.delta.1fe7af4f-20d9-4e31-8c1b-4a8e1b600edc.TID205.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 3.0 (TID 203) in 263 ms on localhost (executor driver) (1/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 4.0 in stage 3.0 (TID 206)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 3.0 (TID 205). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 5.0 in stage 3.0 (TID 207, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 3.0 (TID 205) in 267 ms on localhost (executor driver) (2/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 5.0 in stage 3.0 (TID 207)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b5850f6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73a1b5fa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437d3401
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5492df93
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.2.delta.44c58a1f-16fd-489e-b695-d063e874cd93.TID204.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 3.0 (TID 204). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 6.0 in stage 3.0 (TID 208, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 3.0 (TID 204) in 295 ms on localhost (executor driver) (3/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 6.0 in stage 3.0 (TID 208)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.2.delta.5dd51b98-c42f-4b64-9502-3e55a0414aa6.TID202.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ae6f213
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c2ca528
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 3.0 (TID 202). 5208 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 7.0 in stage 3.0 (TID 209, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 3.0 (TID 202) in 317 ms on localhost (executor driver) (4/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 7.0 in stage 3.0 (TID 209)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72163a5d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bb54f77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.2.delta.ce46eea8-78f6-49f5-ba59-03a0bb6f16f4.TID206.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.2.delta.f4161915-36d0-4942-b0c2-56d163d6b8ef.TID207.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.2.delta.b9199d06-09b1-4244-9ea7-a8ea43c96270.TID208.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.2.delta.55b67356-9736-48cb-b597-f297e48c7e4c.TID209.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.2.delta.ce46eea8-78f6-49f5-ba59-03a0bb6f16f4.TID206.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.2.delta.f4161915-36d0-4942-b0c2-56d163d6b8ef.TID207.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 4 (task 206, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 4 (task 206, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 5 (task 207, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 5 (task 207, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.2.delta.b9199d06-09b1-4244-9ea7-a8ea43c96270.TID208.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 6 (task 208, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 6 (task 208, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.2.delta.55b67356-9736-48cb-b597-f297e48c7e4c.TID209.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 7 (task 209, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 7 (task 209, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.2.delta.dcf07de2-fa70-462d-ba0b-a2f4cbf7f995.TID206.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.2.delta.14402a22-3e95-4a22-a22c-7986f4a06abf.TID207.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 3.0 (TID 207). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 3.0 (TID 206). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 8.0 in stage 3.0 (TID 210, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 9.0 in stage 3.0 (TID 211, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 8.0 in stage 3.0 (TID 210)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 3.0 (TID 207) in 265 ms on localhost (executor driver) (5/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 9.0 in stage 3.0 (TID 211)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 3.0 (TID 206) in 269 ms on localhost (executor driver) (6/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cb5ccd2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@214787f8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35bf169b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1af9b600
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.2.delta.9d505ebf-df5e-4eb3-9e51-5cdf2b981dfc.TID208.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.2.delta.e0041020-e8be-4c46-aba0-5e15e9b0df12.TID209.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 97
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 123
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 124
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 92
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 111
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 106
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 128
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 94
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 105
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 122
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 96
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 118
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 110
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 102
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 113
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 100
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 116
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 3.0 (TID 208). 5065 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed broadcast_8_piece0 on mac-180:55122 in memory (size: 13.6 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 10.0 in stage 3.0 (TID 212, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 3.0 (TID 208) in 309 ms on localhost (executor driver) (7/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 10.0 in stage 3.0 (TID 212)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 115
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 126
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 103
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 99
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 119
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 117
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 112
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 127
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 121
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 108
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 120
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 95
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 104
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 101
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 107
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 109
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 114
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 91
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 3.0 (TID 209). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 93
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 125
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 98
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 11.0 in stage 3.0 (TID 213, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 3.0 (TID 209) in 294 ms on localhost (executor driver) (8/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 11.0 in stage 3.0 (TID 213)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@652b6e84
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53783a6c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7caf6680
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11452ad1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.2.delta.f136b972-ec70-4bdb-a072-90b332f64c36.TID210.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:19,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.2.delta.c2e9af95-38ce-4f6f-9807-9bdbddbc3549.TID211.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.2.delta.4f62ed3e-2b45-473a-add0-5fd500ccb753.TID213.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.2.delta.92a54753-d831-4c62-a713-798f8eb1a3f3.TID212.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.2.delta.f136b972-ec70-4bdb-a072-90b332f64c36.TID210.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 8 (task 210, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 8 (task 210, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.2.delta.c2e9af95-38ce-4f6f-9807-9bdbddbc3549.TID211.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 9 (task 211, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 9 (task 211, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.2.delta.92a54753-d831-4c62-a713-798f8eb1a3f3.TID212.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 10 (task 212, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 10 (task 212, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.2.delta.4f62ed3e-2b45-473a-add0-5fd500ccb753.TID213.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 11 (task 213, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 11 (task 213, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.2.delta.c857307c-bd78-4428-9810-0afcecbd7c2b.TID210.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 3.0 (TID 210). 5065 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 12.0 in stage 3.0 (TID 214, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 3.0 (TID 210) in 274 ms on localhost (executor driver) (9/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 12.0 in stage 3.0 (TID 214)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e28a8bf
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62c06b06
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.2.delta.ce1433db-6849-465e-a20a-3b36e9855f62.TID211.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 3.0 (TID 211). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 13.0 in stage 3.0 (TID 215, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 3.0 (TID 211) in 289 ms on localhost (executor driver) (10/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 13.0 in stage 3.0 (TID 215)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.2.delta.8384f527-a13a-4810-aedb-fbe4b3221892.TID212.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 3.0 (TID 212). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@105fd9d1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 14.0 in stage 3.0 (TID 216, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 3.0 (TID 212) in 223 ms on localhost (executor driver) (11/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 14.0 in stage 3.0 (TID 216)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c97cd68
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@82701ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17c6e39f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.2.delta.343e052a-dc29-485f-8104-ed11c3735b56.TID213.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 3.0 (TID 213). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 15.0 in stage 3.0 (TID 217, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 3.0 (TID 213) in 237 ms on localhost (executor driver) (12/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 15.0 in stage 3.0 (TID 217)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@535dded2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74752a60
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.2.delta.6b0a564e-a233-4335-8bff-0701291954ae.TID214.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.2.delta.8fdd01b9-7c0d-4e2c-a9df-bebb95c0fe2b.TID215.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.2.delta.9f0c77e7-bb0c-40c0-bb80-d896189699b6.TID216.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.2.delta.32a6785f-6a21-4b18-b1f5-7d7230b1eb49.TID217.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.2.delta.6b0a564e-a233-4335-8bff-0701291954ae.TID214.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 12 (task 214, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 12 (task 214, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.2.delta.9f0c77e7-bb0c-40c0-bb80-d896189699b6.TID216.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 14 (task 216, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 14 (task 216, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.2.delta.8fdd01b9-7c0d-4e2c-a9df-bebb95c0fe2b.TID215.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,404][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 13 (task 215, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,404][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 13 (task 215, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.2.delta.32a6785f-6a21-4b18-b1f5-7d7230b1eb49.TID217.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 15 (task 217, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 15 (task 217, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.2.delta.3b6bb712-1e63-473c-b9f4-e783bbc53c0c.TID214.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 3.0 (TID 214). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 16.0 in stage 3.0 (TID 218, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 3.0 (TID 214) in 296 ms on localhost (executor driver) (13/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 16.0 in stage 3.0 (TID 218)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75caaf13
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@643f53ac
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.2.delta.ffeec706-e8a8-40ef-b4e4-fd26aa6c2278.TID216.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 3.0 (TID 216). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 17.0 in stage 3.0 (TID 219, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 3.0 (TID 216) in 289 ms on localhost (executor driver) (14/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 17.0 in stage 3.0 (TID 219)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75740a62
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5491f234
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.2.delta.cfb5225a-e5b3-4bd1-aa79-fbf35803106f.TID215.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 3.0 (TID 215). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 18.0 in stage 3.0 (TID 220, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 3.0 (TID 215) in 313 ms on localhost (executor driver) (15/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 18.0 in stage 3.0 (TID 220)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@272da69f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55028e1f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.2.delta.80556f5b-536b-45e3-9371-8b2c6486cf16.TID217.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 3.0 (TID 217). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 19.0 in stage 3.0 (TID 221, localhost, executor driver, partition 19, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 19.0 in stage 3.0 (TID 221)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 3.0 (TID 217) in 328 ms on localhost (executor driver) (16/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37b3fd91
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b8828e9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.2.delta.14562a19-0296-443f-b23c-31cefd1d4b74.TID218.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.2.delta.31a6bdbf-331f-4798-b4ea-5ba448c33d2d.TID220.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.2.delta.2a4dc5aa-5e0f-4d1c-b4a5-c9bb6d70b469.TID219.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.2.delta.a01be1d0-eb2e-4bd0-9fa3-ce4a19bd583f.TID221.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.2.delta.14562a19-0296-443f-b23c-31cefd1d4b74.TID218.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 16 (task 218, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 16 (task 218, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.2.delta.2a4dc5aa-5e0f-4d1c-b4a5-c9bb6d70b469.TID219.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.2.delta.31a6bdbf-331f-4798-b4ea-5ba448c33d2d.TID220.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 18 (task 220, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 18 (task 220, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 17 (task 219, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 17 (task 219, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.2.delta.a01be1d0-eb2e-4bd0-9fa3-ce4a19bd583f.TID221.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.2.delta.cf8d3b18-05e8-4a65-99ea-0cec19e4b31e.TID218.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 19 (task 221, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 19 (task 221, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 3.0 (TID 218). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 20.0 in stage 3.0 (TID 222, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 3.0 (TID 218) in 377 ms on localhost (executor driver) (17/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 20.0 in stage 3.0 (TID 222)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f649ac
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16ffc915
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.2.delta.35e6ada7-12ea-4499-a4d6-961bb7bfc0fc.TID220.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 3.0 (TID 220). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 21.0 in stage 3.0 (TID 223, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 3.0 (TID 220) in 372 ms on localhost (executor driver) (18/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 21.0 in stage 3.0 (TID 223)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@759fcae4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d670cdd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.2.delta.dd157d36-bd56-42a8-b7e5-b3cd8bf98b9b.TID219.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 3.0 (TID 219). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 22.0 in stage 3.0 (TID 224, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 3.0 (TID 219) in 407 ms on localhost (executor driver) (19/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 22.0 in stage 3.0 (TID 224)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@153a71ef
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78341956
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.2.delta.bd5c40e2-25b9-4249-8db6-1c87b03f4a83.TID221.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 3.0 (TID 221). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 23.0 in stage 3.0 (TID 225, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 23.0 in stage 3.0 (TID 225)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 3.0 (TID 221) in 372 ms on localhost (executor driver) (20/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c2be559
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f11173b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.2.delta.2011aa3b-67d7-44ff-b594-ce955df51290.TID222.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,917][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.2.delta.36255b22-c026-40dd-9ea0-ba7b67e655e2.TID223.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.2.delta.9dc9a136-3382-4d3b-b339-2e7f140b0bf6.TID224.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.2.delta.b798320a-d3b4-4cae-a45a-f62d31a6eff5.TID225.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.2.delta.2011aa3b-67d7-44ff-b594-ce955df51290.TID222.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 20 (task 222, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 20 (task 222, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.2.delta.36255b22-c026-40dd-9ea0-ba7b67e655e2.TID223.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:20,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 21 (task 223, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 21 (task 223, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.2.delta.9dc9a136-3382-4d3b-b339-2e7f140b0bf6.TID224.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 22 (task 224, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 22 (task 224, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.2.delta.e987376d-f287-4187-8734-ac4e65e547f6.TID222.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 3.0 (TID 222). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 24.0 in stage 3.0 (TID 226, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 3.0 (TID 222) in 206 ms on localhost (executor driver) (21/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 24.0 in stage 3.0 (TID 226)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72cd6fbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@575d057f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.2.delta.b798320a-d3b4-4cae-a45a-f62d31a6eff5.TID225.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 23 (task 225, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 23 (task 225, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.2.delta.91183efc-a5f1-4606-b6f5-e0401156ef74.TID223.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 3.0 (TID 223). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 25.0 in stage 3.0 (TID 227, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 3.0 (TID 223) in 200 ms on localhost (executor driver) (22/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 25.0 in stage 3.0 (TID 227)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a9058a4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2282c0d9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.2.delta.4966b6f5-d2ad-4e0f-9c65-c7caebcb0849.TID225.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.2.delta.06548ca1-2053-4b9c-8063-7350c14fd76f.TID224.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 3.0 (TID 225). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 26.0 in stage 3.0 (TID 228, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 3.0 (TID 225) in 196 ms on localhost (executor driver) (23/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 26.0 in stage 3.0 (TID 228)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 3.0 (TID 224). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 27.0 in stage 3.0 (TID 229, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 3.0 (TID 224) in 221 ms on localhost (executor driver) (24/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 27.0 in stage 3.0 (TID 229)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23f3e350
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44197dbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cfd5606
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e16ce0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.2.delta.5e308ceb-a34f-442c-a2fc-093a86fd5c4d.TID226.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.2.delta.bd52e704-13c9-4c32-9ecc-4d5193332127.TID227.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.2.delta.cdc0ccce-7753-4626-8d6c-67ba5fe4ed59.TID228.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.2.delta.e9cbe2d6-5b18-4d19-873f-95b360c28aec.TID229.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.2.delta.5e308ceb-a34f-442c-a2fc-093a86fd5c4d.TID226.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 24 (task 226, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 24 (task 226, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.2.delta.bd52e704-13c9-4c32-9ecc-4d5193332127.TID227.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 25 (task 227, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 25 (task 227, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.2.delta.cdc0ccce-7753-4626-8d6c-67ba5fe4ed59.TID228.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.2.delta.e9cbe2d6-5b18-4d19-873f-95b360c28aec.TID229.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 26 (task 228, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 26 (task 228, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 27 (task 229, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 27 (task 229, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.2.delta.7558753b-147f-477b-b2a0-f7683800b0ac.TID227.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.2.delta.aa4582ad-6632-48b4-b2e8-3df642872534.TID226.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 3.0 (TID 227). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 28.0 in stage 3.0 (TID 230, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 3.0 (TID 227) in 208 ms on localhost (executor driver) (25/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 28.0 in stage 3.0 (TID 230)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34862f76
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@413dda2f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 3.0 (TID 226). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 29.0 in stage 3.0 (TID 231, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 3.0 (TID 226) in 248 ms on localhost (executor driver) (26/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 29.0 in stage 3.0 (TID 231)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a32078
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36cd6d7c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.2.delta.deb1f1bb-b112-4526-a9c9-ca2bcae54986.TID228.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.2.delta.f0d007da-d736-43d7-bfa7-685b5c848101.TID229.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 3.0 (TID 228). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 30.0 in stage 3.0 (TID 232, localhost, executor driver, partition 30, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 3.0 (TID 228) in 342 ms on localhost (executor driver) (27/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 30.0 in stage 3.0 (TID 232)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 3.0 (TID 229). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 31.0 in stage 3.0 (TID 233, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 3.0 (TID 229) in 345 ms on localhost (executor driver) (28/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 31.0 in stage 3.0 (TID 233)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6743fbbc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d67e704
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@283e6a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3977b0fb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.2.delta.c2be89fc-5855-4af1-b4eb-a87b0d1dc6dd.TID230.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,528][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.2.delta.a82cc876-5757-433b-9ee4-61f470212bd8.TID231.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.2.delta.fdb24ad6-6264-47de-b0dd-a2f98562fea8.TID232.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.2.delta.e0a7c230-9b0e-4b0c-810d-b2cc09cee361.TID233.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.2.delta.c2be89fc-5855-4af1-b4eb-a87b0d1dc6dd.TID230.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 28 (task 230, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 28 (task 230, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.2.delta.a82cc876-5757-433b-9ee4-61f470212bd8.TID231.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 29 (task 231, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 29 (task 231, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.2.delta.e0a7c230-9b0e-4b0c-810d-b2cc09cee361.TID233.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.2.delta.fdb24ad6-6264-47de-b0dd-a2f98562fea8.TID232.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 31 (task 233, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 31 (task 233, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 30 (task 232, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 30 (task 232, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.2.delta.181b09ca-b851-439a-9f74-1d4abc0e6988.TID230.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 3.0 (TID 230). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 32.0 in stage 3.0 (TID 234, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 3.0 (TID 230) in 412 ms on localhost (executor driver) (29/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 32.0 in stage 3.0 (TID 234)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c8789e7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41be5782
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.2.delta.9d1d106b-b660-41d9-ba69-01f78321a2ab.TID231.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 3.0 (TID 231). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 33.0 in stage 3.0 (TID 235, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 3.0 (TID 231) in 407 ms on localhost (executor driver) (30/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 33.0 in stage 3.0 (TID 235)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30e27bf8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3128cc76
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.2.delta.aa76dc60-f1de-405c-9f57-05cf10fd76e9.TID233.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 3.0 (TID 233). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 34.0 in stage 3.0 (TID 236, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 3.0 (TID 233) in 273 ms on localhost (executor driver) (31/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 34.0 in stage 3.0 (TID 236)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@189ef350
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.2.delta.08675a19-1faa-41fb-9ae5-cc9a52e1077d.TID232.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7928537d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 3.0 (TID 232). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 35.0 in stage 3.0 (TID 237, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 3.0 (TID 232) in 288 ms on localhost (executor driver) (32/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 35.0 in stage 3.0 (TID 237)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58affef9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d5906ec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.2.delta.11c98d56-d7eb-4271-9355-072779dac47c.TID234.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.2.delta.2aff1e9c-a6b6-4869-93ec-6fb07fa229fa.TID235.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.2.delta.727a754a-a875-49ca-a229-8ede2c6ba3d9.TID236.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.2.delta.69cff1c1-9935-42a3-81d8-acd9a546b86c.TID237.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.2.delta.11c98d56-d7eb-4271-9355-072779dac47c.TID234.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 32 (task 234, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 32 (task 234, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.2.delta.2aff1e9c-a6b6-4869-93ec-6fb07fa229fa.TID235.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 33 (task 235, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 33 (task 235, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.2.delta.727a754a-a875-49ca-a229-8ede2c6ba3d9.TID236.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 34 (task 236, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 34 (task 236, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.2.delta.69cff1c1-9935-42a3-81d8-acd9a546b86c.TID237.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 35 (task 237, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 35 (task 237, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.2.delta.b7869a18-5c2f-434c-a0b1-2f49b01d8df0.TID234.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 3.0 (TID 234). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 36.0 in stage 3.0 (TID 238, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 3.0 (TID 234) in 198 ms on localhost (executor driver) (33/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 36.0 in stage 3.0 (TID 238)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4489ad5c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@609b80ad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.2.delta.4f3b4719-152c-4f05-84ea-589826d330ee.TID235.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 3.0 (TID 235). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 37.0 in stage 3.0 (TID 239, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 3.0 (TID 235) in 200 ms on localhost (executor driver) (34/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 37.0 in stage 3.0 (TID 239)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@457c54c4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.2.delta.04098469-259d-4208-8289-4cec0e791822.TID236.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@532e4c3e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 3.0 (TID 236). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 38.0 in stage 3.0 (TID 240, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 3.0 (TID 236) in 201 ms on localhost (executor driver) (35/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 38.0 in stage 3.0 (TID 240)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58e757b3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b49e843
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.2.delta.ab44788f-5b37-416a-8a25-f38ea0265eb4.TID237.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,917][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 3.0 (TID 237). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 39.0 in stage 3.0 (TID 241, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 3.0 (TID 237) in 211 ms on localhost (executor driver) (36/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 39.0 in stage 3.0 (TID 241)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@554668e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7209d473
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.2.delta.f306feb9-956f-431e-9216-cc77f32dc686.TID238.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.2.delta.3c9ea03a-3151-4979-9f4b-821c11da6ebc.TID239.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.2.delta.4d25a1fc-591d-46ea-bd7a-6e0c29ad5cd4.TID240.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:21,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.2.delta.1ea73081-945d-4c57-a0b6-ad4e83dc6533.TID241.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.2.delta.f306feb9-956f-431e-9216-cc77f32dc686.TID238.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.2.delta.3c9ea03a-3151-4979-9f4b-821c11da6ebc.TID239.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 36 (task 238, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 36 (task 238, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 37 (task 239, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 37 (task 239, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.2.delta.1ea73081-945d-4c57-a0b6-ad4e83dc6533.TID241.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 39 (task 241, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 39 (task 241, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.2.delta.4d25a1fc-591d-46ea-bd7a-6e0c29ad5cd4.TID240.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 38 (task 240, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 38 (task 240, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.2.delta.42363f5a-8cae-400b-9e20-60d5c728f5ed.TID239.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.2.delta.6e8b8c67-0ee2-4b08-b9e5-40d60e73100d.TID238.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 3.0 (TID 239). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 40.0 in stage 3.0 (TID 242, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 3.0 (TID 239) in 224 ms on localhost (executor driver) (37/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 3.0 (TID 238). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 40.0 in stage 3.0 (TID 242)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 41.0 in stage 3.0 (TID 243, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 3.0 (TID 238) in 241 ms on localhost (executor driver) (38/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 41.0 in stage 3.0 (TID 243)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2540523c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fae489
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68018b79
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@563d5133
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.2.delta.61f8ccd9-17fb-4ec6-8fe9-b2a7b809636a.TID241.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 3.0 (TID 241). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 42.0 in stage 3.0 (TID 244, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 3.0 (TID 241) in 202 ms on localhost (executor driver) (39/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 42.0 in stage 3.0 (TID 244)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ac110bc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ada61a3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.2.delta.b272fc3c-2ab7-4b66-9489-241d4821f069.TID240.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 3.0 (TID 240). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 43.0 in stage 3.0 (TID 245, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 43.0 in stage 3.0 (TID 245)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 3.0 (TID 240) in 242 ms on localhost (executor driver) (40/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bb0f7a4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d782de3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.2.delta.49935de8-a9e7-4c4a-a157-a8df00bb25f1.TID243.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.2.delta.81ff88b4-e185-4cf0-948a-ade0d5b780d8.TID244.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.2.delta.923b9623-7e96-43da-936c-d0837e3d94a1.TID242.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.2.delta.6e56aa9e-0d9a-47b0-ac3f-e4cd211947ea.TID245.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.2.delta.49935de8-a9e7-4c4a-a157-a8df00bb25f1.TID243.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 41 (task 243, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 41 (task 243, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.2.delta.923b9623-7e96-43da-936c-d0837e3d94a1.TID242.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 40 (task 242, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 40 (task 242, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.2.delta.81ff88b4-e185-4cf0-948a-ade0d5b780d8.TID244.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 42 (task 244, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 42 (task 244, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.2.delta.6e56aa9e-0d9a-47b0-ac3f-e4cd211947ea.TID245.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 43 (task 245, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 43 (task 245, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.2.delta.d7820b20-91dc-4224-9223-36a5cbdb3332.TID243.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 3.0 (TID 243). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 44.0 in stage 3.0 (TID 246, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 3.0 (TID 243) in 184 ms on localhost (executor driver) (41/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 44.0 in stage 3.0 (TID 246)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ad3fa1a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f1b0cbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.2.delta.a0d91dc7-ed8d-4d6a-9c47-fc05f040836b.TID242.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 3.0 (TID 242). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 45.0 in stage 3.0 (TID 247, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 3.0 (TID 242) in 194 ms on localhost (executor driver) (42/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 45.0 in stage 3.0 (TID 247)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fb12b64
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18086f93
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.2.delta.6421b241-51df-4971-8ac7-3a07bffca230.TID244.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.2.delta.e529688d-361d-4836-9894-c73b773284a4.TID245.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 3.0 (TID 244). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 46.0 in stage 3.0 (TID 248, localhost, executor driver, partition 46, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 3.0 (TID 244) in 207 ms on localhost (executor driver) (43/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 46.0 in stage 3.0 (TID 248)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 3.0 (TID 245). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 47.0 in stage 3.0 (TID 249, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 3.0 (TID 245) in 188 ms on localhost (executor driver) (44/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 47.0 in stage 3.0 (TID 249)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a56b6ae
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4432044d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,338][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30c22d09
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,338][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,338][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@380ab73a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.2.delta.c0f7442b-403d-4e09-876a-6599fdff7da6.TID246.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.2.delta.c79022e6-c580-450b-a3da-a51224b00968.TID247.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.2.delta.949957f5-e330-4a35-b7eb-79627ea0fcba.TID248.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.2.delta.1449b044-5767-4874-961d-89a74dfabf0d.TID249.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.2.delta.c0f7442b-403d-4e09-876a-6599fdff7da6.TID246.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 44 (task 246, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 44 (task 246, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.2.delta.c79022e6-c580-450b-a3da-a51224b00968.TID247.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 45 (task 247, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 45 (task 247, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.2.delta.1449b044-5767-4874-961d-89a74dfabf0d.TID249.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 47 (task 249, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 47 (task 249, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.2.delta.949957f5-e330-4a35-b7eb-79627ea0fcba.TID248.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.2.delta.8d68b281-7142-4e0b-a5f2-151f3b5c209f.TID246.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 46 (task 248, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 46 (task 248, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 3.0 (TID 246). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 48.0 in stage 3.0 (TID 250, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 3.0 (TID 246) in 331 ms on localhost (executor driver) (45/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 48.0 in stage 3.0 (TID 250)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.2.delta.58269fe9-b513-4706-af3f-fecc62efd8d1.TID247.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 3.0 (TID 247). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42ef3ae6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 49.0 in stage 3.0 (TID 251, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 3.0 (TID 247) in 326 ms on localhost (executor driver) (46/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58869634
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 49.0 in stage 3.0 (TID 251)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59a0e410
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13ffd75d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.2.delta.360f2eca-8931-4de9-9436-8c909b53e209.TID249.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 3.0 (TID 249). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 50.0 in stage 3.0 (TID 252, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 3.0 (TID 249) in 330 ms on localhost (executor driver) (47/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 50.0 in stage 3.0 (TID 252)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47370194
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376d9974
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.2.delta.e7603a05-2710-4051-b5f2-67b14ad53b12.TID251.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.2.delta.70cc7432-b0ff-4f1c-b440-24fd37804fed.TID248.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 3.0 (TID 248). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 51.0 in stage 3.0 (TID 253, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 3.0 (TID 248) in 408 ms on localhost (executor driver) (48/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 51.0 in stage 3.0 (TID 253)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c40593d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b0085f9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.2.delta.15ee9da1-2e0a-4a17-b05d-965f9ccb6d3d.TID252.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.2.delta.0ea0c25f-f54c-4928-9592-0b158c30a0e5.TID250.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.2.delta.f7308137-9c5e-4b2f-a654-c4a44004a9ae.TID253.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.2.delta.e7603a05-2710-4051-b5f2-67b14ad53b12.TID251.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 49 (task 251, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 49 (task 251, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.2.delta.15ee9da1-2e0a-4a17-b05d-965f9ccb6d3d.TID252.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.2.delta.0ea0c25f-f54c-4928-9592-0b158c30a0e5.TID250.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 50 (task 252, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 50 (task 252, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 48 (task 250, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 48 (task 250, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.2.delta.7d8d869b-7fcc-4b89-9a45-cbedf8b7c6b9.TID251.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 3.0 (TID 251). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 52.0 in stage 3.0 (TID 254, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 3.0 (TID 251) in 354 ms on localhost (executor driver) (49/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 52.0 in stage 3.0 (TID 254)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b146a97
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@387bc62e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:22,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.2.delta.f7308137-9c5e-4b2f-a654-c4a44004a9ae.TID253.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 51 (task 253, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 51 (task 253, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.2.delta.09576593-11a2-40a2-abf4-cebb251ee875.TID252.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 3.0 (TID 252). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 53.0 in stage 3.0 (TID 255, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 3.0 (TID 252) in 395 ms on localhost (executor driver) (50/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 53.0 in stage 3.0 (TID 255)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.2.delta.5c6463c9-29cc-4ffb-ae2e-69059c65ebfa.TID254.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6244b359
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55e02dfe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.2.delta.179f50bf-bac8-450e-bf84-986688446907.TID250.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 3.0 (TID 250). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 54.0 in stage 3.0 (TID 256, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 3.0 (TID 250) in 450 ms on localhost (executor driver) (51/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 54.0 in stage 3.0 (TID 256)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@451b2426
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6adb72c3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.2.delta.c4aa7b8f-4917-4b66-93c9-52c95b98bfb3.TID253.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 3.0 (TID 253). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 55.0 in stage 3.0 (TID 257, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 3.0 (TID 253) in 387 ms on localhost (executor driver) (52/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 55.0 in stage 3.0 (TID 257)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5326ecb1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@324a643
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.2.delta.74b5393f-81fc-448f-bda9-0818b9a5aebb.TID256.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,150][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.2.delta.f2e15953-5ee7-41bb-9cb0-7f5bc31059e9.TID255.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.2.delta.5c6463c9-29cc-4ffb-ae2e-69059c65ebfa.TID254.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 52 (task 254, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 52 (task 254, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.2.delta.bd3dbb50-4314-42f4-bd34-73c47483cad8.TID257.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.2.delta.613cb7dd-ad6b-43f4-8759-6db5fbb0f816.TID254.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,263][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.2.delta.74b5393f-81fc-448f-bda9-0818b9a5aebb.TID256.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,263][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,263][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 3.0 (TID 254). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 56.0 in stage 3.0 (TID 258, localhost, executor driver, partition 56, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 54 (task 256, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 3.0 (TID 254) in 291 ms on localhost (executor driver) (53/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 56.0 in stage 3.0 (TID 258)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 54 (task 256, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@706f375f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d95252e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.2.delta.f2e15953-5ee7-41bb-9cb0-7f5bc31059e9.TID255.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 53 (task 255, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 53 (task 255, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.2.delta.ba7097a8-2cd6-4737-b880-3914660e0426.TID256.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.2.delta.bd3dbb50-4314-42f4-bd34-73c47483cad8.TID257.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 3.0 (TID 256). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 55 (task 257, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 57.0 in stage 3.0 (TID 259, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 55 (task 257, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 3.0 (TID 256) in 265 ms on localhost (executor driver) (54/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 57.0 in stage 3.0 (TID 259)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@449ff404
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6066b726
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.2.delta.018de682-8680-4304-ad6a-7bf36d6a5b18.TID255.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 3.0 (TID 255). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 58.0 in stage 3.0 (TID 260, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 3.0 (TID 255) in 294 ms on localhost (executor driver) (55/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 58.0 in stage 3.0 (TID 260)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ac9c1de
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40511f3c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.2.delta.eb7a6c3e-8373-4260-ae6a-80d827ac23b5.TID258.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.2.delta.b7f5fd83-7bbf-4df4-93f8-544532cb64df.TID259.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.2.delta.a28bd06a-a26e-4a4b-85fc-a7bd9fe2ed34.TID257.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 3.0 (TID 257). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 59.0 in stage 3.0 (TID 261, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 3.0 (TID 257) in 341 ms on localhost (executor driver) (56/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 59.0 in stage 3.0 (TID 261)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4416a82
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7192c371
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,494][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.2.delta.d3a690bc-d7eb-4262-899d-e96c1c2f7aaa.TID260.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.2.delta.f1cb8ce2-fdca-474d-8e84-3e554e6d2532.TID261.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.2.delta.eb7a6c3e-8373-4260-ae6a-80d827ac23b5.TID258.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 56 (task 258, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 56 (task 258, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.2.delta.b7f5fd83-7bbf-4df4-93f8-544532cb64df.TID259.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 57 (task 259, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 57 (task 259, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.2.delta.d3a690bc-d7eb-4262-899d-e96c1c2f7aaa.TID260.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 58 (task 260, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 58 (task 260, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.2.delta.736a132b-f997-4043-b074-b0ec092adb89.TID259.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.2.delta.c78f51cb-b780-4486-b93a-401397ec954b.TID258.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 3.0 (TID 259). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 3.0 (TID 258). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 60.0 in stage 3.0 (TID 262, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 61.0 in stage 3.0 (TID 263, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 60.0 in stage 3.0 (TID 262)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 3.0 (TID 259) in 355 ms on localhost (executor driver) (57/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 61.0 in stage 3.0 (TID 263)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 3.0 (TID 258) in 419 ms on localhost (executor driver) (58/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@252f56de
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ff21eae
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43781b99
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27c2403e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.2.delta.f1cb8ce2-fdca-474d-8e84-3e554e6d2532.TID261.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.2.delta.0f61ec8c-6b26-432a-ac3c-d5a8dfdccab5.TID260.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 59 (task 261, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 59 (task 261, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 3.0 (TID 260). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 62.0 in stage 3.0 (TID 264, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 3.0 (TID 260) in 376 ms on localhost (executor driver) (59/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 62.0 in stage 3.0 (TID 264)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bb96eaa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b25bd92
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.2.delta.24ee6894-10bf-45d9-ab2f-373ba423ebe1.TID263.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.2.delta.19f7fecc-e5ba-409a-b367-0e9cc3746fc0.TID262.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.2.delta.e4b1c5ef-7bb1-4966-8aa1-954d9f2e9efc.TID261.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 3.0 (TID 261). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 63.0 in stage 3.0 (TID 265, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 3.0 (TID 261) in 343 ms on localhost (executor driver) (60/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 63.0 in stage 3.0 (TID 265)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc40ad9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@122f15f2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.2.delta.173911f7-98a9-432d-a11b-cc5f9221151e.TID264.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.2.delta.ae3fa3c9-b625-4b65-9765-b952195fc16e.TID265.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.2.delta.24ee6894-10bf-45d9-ab2f-373ba423ebe1.TID263.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 61 (task 263, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 61 (task 263, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.2.delta.19f7fecc-e5ba-409a-b367-0e9cc3746fc0.TID262.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 60 (task 262, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 60 (task 262, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.2.delta.173911f7-98a9-432d-a11b-cc5f9221151e.TID264.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 62 (task 264, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 62 (task 264, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.2.delta.00907c97-9b4e-4c30-aaa7-f28746e4441f.TID263.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 3.0 (TID 263). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 64.0 in stage 3.0 (TID 266, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 3.0 (TID 263) in 282 ms on localhost (executor driver) (61/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 64.0 in stage 3.0 (TID 266)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c6010c9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bf802f8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.2.delta.d0583aa8-08a3-4f0d-956a-2254fb453391.TID262.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 3.0 (TID 262). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 65.0 in stage 3.0 (TID 267, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 3.0 (TID 262) in 297 ms on localhost (executor driver) (62/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 65.0 in stage 3.0 (TID 267)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14a1a164
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fb654ca
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:23,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.2.delta.d1af74ce-5425-432e-80f2-6b1df2a0ec15.TID264.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 3.0 (TID 264). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 66.0 in stage 3.0 (TID 268, localhost, executor driver, partition 66, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 3.0 (TID 264) in 410 ms on localhost (executor driver) (63/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 66.0 in stage 3.0 (TID 268)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.2.delta.ae3fa3c9-b625-4b65-9765-b952195fc16e.TID265.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@546a3c63
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 63 (task 265, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 63 (task 265, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63b0a7ab
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.2.delta.1296ad94-78d0-4445-a5f8-74fe86b805f7.TID266.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.2.delta.ec29b131-21df-4503-905d-de8115b0c1ec.TID267.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.2.delta.661a9300-4384-40da-9ec0-44501e0fe6f8.TID265.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 3.0 (TID 265). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 67.0 in stage 3.0 (TID 269, localhost, executor driver, partition 67, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 3.0 (TID 265) in 409 ms on localhost (executor driver) (64/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 67.0 in stage 3.0 (TID 269)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@470c88a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@715b9ada
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.2.delta.40aedacb-0a1e-4110-a2b2-fefcbfc6ba25.TID268.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.2.delta.1296ad94-78d0-4445-a5f8-74fe86b805f7.TID266.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 64 (task 266, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 64 (task 266, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.2.delta.7363b312-5b4f-4243-a1cf-dbac89d1d10f.TID269.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.2.delta.ec29b131-21df-4503-905d-de8115b0c1ec.TID267.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 65 (task 267, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 65 (task 267, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.2.delta.40aedacb-0a1e-4110-a2b2-fefcbfc6ba25.TID268.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 66 (task 268, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 66 (task 268, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.2.delta.b68480f5-680c-4965-bc12-29eeb1c47db2.TID266.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 3.0 (TID 266). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 68.0 in stage 3.0 (TID 270, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 3.0 (TID 266) in 468 ms on localhost (executor driver) (65/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 68.0 in stage 3.0 (TID 270)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30fa6753
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@193c2140
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.2.delta.20bec9c0-b6e1-450b-ae0d-f91c0ac57d8a.TID267.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 3.0 (TID 267). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 69.0 in stage 3.0 (TID 271, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 3.0 (TID 267) in 475 ms on localhost (executor driver) (66/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 69.0 in stage 3.0 (TID 271)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39f17a2d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62b82cd8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.2.delta.d5f60dfa-b3a8-46a7-ba06-c21b08fdd5a3.TID268.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 3.0 (TID 268). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 70.0 in stage 3.0 (TID 272, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 3.0 (TID 268) in 350 ms on localhost (executor driver) (67/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 70.0 in stage 3.0 (TID 272)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dc40207
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19fe2cec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.2.delta.7363b312-5b4f-4243-a1cf-dbac89d1d10f.TID269.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,490][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 67 (task 269, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,491][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 67 (task 269, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.2.delta.883e183f-982a-4d7a-895f-ba57a725fe72.TID270.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.2.delta.4c55305d-27c6-4e08-9afc-6af510b019b4.TID271.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.2.delta.36d72a56-f4a5-405d-b7a8-70d495d3e80f.TID269.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.2.delta.2ba6932d-7cf2-4c49-9e09-ca057126b2c2.TID272.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 3.0 (TID 269). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 71.0 in stage 3.0 (TID 273, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 3.0 (TID 269) in 374 ms on localhost (executor driver) (68/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 71.0 in stage 3.0 (TID 273)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1465ddac
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e116a05
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.2.delta.883e183f-982a-4d7a-895f-ba57a725fe72.TID270.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 68 (task 270, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 68 (task 270, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.2.delta.dbf94eb5-b16b-4a32-89fb-951f590aa4aa.TID273.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.2.delta.4c55305d-27c6-4e08-9afc-6af510b019b4.TID271.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 69 (task 271, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 69 (task 271, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.2.delta.2ba6932d-7cf2-4c49-9e09-ca057126b2c2.TID272.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 70 (task 272, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 70 (task 272, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.2.delta.f8a0c067-1c97-4ebf-a437-30213cea9aa5.TID270.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 3.0 (TID 270). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 72.0 in stage 3.0 (TID 274, localhost, executor driver, partition 72, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 3.0 (TID 270) in 264 ms on localhost (executor driver) (69/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 72.0 in stage 3.0 (TID 274)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a19af14
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@144ad0ee
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.2.delta.702ab62c-67a4-42b2-9a2e-3c1dec957be5.TID271.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 3.0 (TID 271). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 73.0 in stage 3.0 (TID 275, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 3.0 (TID 271) in 264 ms on localhost (executor driver) (70/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 73.0 in stage 3.0 (TID 275)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@666593a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@666b438c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.2.delta.affb74cc-e954-4387-bdff-3bb7cad80c13.TID272.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 3.0 (TID 272). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 74.0 in stage 3.0 (TID 276, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 3.0 (TID 272) in 262 ms on localhost (executor driver) (71/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 74.0 in stage 3.0 (TID 276)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b3bbc4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65daefe0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.2.delta.dbf94eb5-b16b-4a32-89fb-951f590aa4aa.TID273.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 71 (task 273, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 71 (task 273, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.2.delta.87ed12b5-23eb-4b06-ba81-01cf5f804749.TID274.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.2.delta.ff6ba132-44b6-4f9b-908d-7addde18acfb.TID275.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.2.delta.c180839f-d11b-428c-8a9c-f2a99bd96db0.TID276.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.2.delta.545921c7-5f06-4e96-8f6a-39a56534a331.TID273.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 3.0 (TID 273). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 75.0 in stage 3.0 (TID 277, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 3.0 (TID 273) in 230 ms on localhost (executor driver) (72/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 75.0 in stage 3.0 (TID 277)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48505dd4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fe0d00b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.2.delta.616aa8ef-fcc0-4fdf-a8bc-7befd3ce26f1.TID277.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.2.delta.87ed12b5-23eb-4b06-ba81-01cf5f804749.TID274.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.2.delta.ff6ba132-44b6-4f9b-908d-7addde18acfb.TID275.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 72 (task 274, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 73 (task 275, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 72 (task 274, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:24,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 73 (task 275, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.2.delta.c180839f-d11b-428c-8a9c-f2a99bd96db0.TID276.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 74 (task 276, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 74 (task 276, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.2.delta.52b75bed-e4b1-4cd4-880c-bf8e616275df.TID274.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.2.delta.adc79446-bc27-4c89-b3f8-6641248c5c01.TID275.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 3.0 (TID 274). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 76.0 in stage 3.0 (TID 278, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 3.0 (TID 274) in 349 ms on localhost (executor driver) (73/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 76.0 in stage 3.0 (TID 278)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 3.0 (TID 275). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 77.0 in stage 3.0 (TID 279, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 3.0 (TID 275) in 329 ms on localhost (executor driver) (74/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 77.0 in stage 3.0 (TID 279)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca41208
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45dc33b5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53bcb299
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d0d784a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.2.delta.2c38fda5-0f8e-447e-8b4a-6c3f9437f197.TID276.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 3.0 (TID 276). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 78.0 in stage 3.0 (TID 280, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 3.0 (TID 276) in 332 ms on localhost (executor driver) (75/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 78.0 in stage 3.0 (TID 280)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23c37a09
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1462fa94
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.2.delta.616aa8ef-fcc0-4fdf-a8bc-7befd3ce26f1.TID277.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 75 (task 277, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 75 (task 277, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.2.delta.d7f657ef-91b8-4f44-a1bc-c04c92d1d999.TID278.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.2.delta.2255c10d-5255-4653-8660-d2e338321458.TID279.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.2.delta.f5b9de1a-6ef9-4a0e-88d7-045c840ecebc.TID277.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 3.0 (TID 277). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 79.0 in stage 3.0 (TID 281, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 3.0 (TID 277) in 359 ms on localhost (executor driver) (76/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 79.0 in stage 3.0 (TID 281)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4be3cf8c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd674ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.2.delta.98f1de89-9db2-4273-867a-c6301291ae82.TID280.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.2.delta.965c725a-8d43-44c8-8ee9-916d0f1f724e.TID281.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.2.delta.2255c10d-5255-4653-8660-d2e338321458.TID279.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.2.delta.d7f657ef-91b8-4f44-a1bc-c04c92d1d999.TID278.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 77 (task 279, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 77 (task 279, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 76 (task 278, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 76 (task 278, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.2.delta.98f1de89-9db2-4273-867a-c6301291ae82.TID280.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 78 (task 280, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 78 (task 280, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.2.delta.e93e96d6-c803-4524-9222-001ea6f9316e.TID278.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.2.delta.d4aeb589-a4ef-4f4b-9b12-621255a14770.TID279.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 3.0 (TID 278). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 3.0 (TID 279). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 80.0 in stage 3.0 (TID 282, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 81.0 in stage 3.0 (TID 283, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 80.0 in stage 3.0 (TID 282)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 3.0 (TID 279) in 507 ms on localhost (executor driver) (77/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 81.0 in stage 3.0 (TID 283)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 3.0 (TID 278) in 509 ms on localhost (executor driver) (78/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64b618fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,555][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,555][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@642839a3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,555][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e7071f9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@650607e0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.2.delta.965c725a-8d43-44c8-8ee9-916d0f1f724e.TID281.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,580][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.2.delta.7d65433d-27fd-4186-bd3a-c3ac0e52f2e4.TID280.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,580][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 3.0 (TID 280). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 79 (task 281, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 79 (task 281, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 82.0 in stage 3.0 (TID 284, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 3.0 (TID 280) in 510 ms on localhost (executor driver) (79/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 82.0 in stage 3.0 (TID 284)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@378c48a7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d87cf3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.2.delta.3baef45c-8a9e-43a7-bb0e-485c47dbb448.TID282.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.2.delta.606a2bca-48d6-4dc6-bde5-a1ebcf61bd0d.TID283.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.2.delta.e588f499-4738-4b4f-a5be-99bef8a6385c.TID281.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 3.0 (TID 281). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 83.0 in stage 3.0 (TID 285, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 3.0 (TID 281) in 468 ms on localhost (executor driver) (80/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 83.0 in stage 3.0 (TID 285)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20bc1f9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62585356
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.2.delta.3549ae0c-3c51-438e-8d5b-38ce90d0767e.TID284.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.2.delta.56210107-137b-4e07-8b5e-4bc3cdcf7fb6.TID285.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.2.delta.3baef45c-8a9e-43a7-bb0e-485c47dbb448.TID282.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 80 (task 282, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 80 (task 282, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.2.delta.606a2bca-48d6-4dc6-bde5-a1ebcf61bd0d.TID283.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 81 (task 283, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 81 (task 283, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.2.delta.3549ae0c-3c51-438e-8d5b-38ce90d0767e.TID284.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 82 (task 284, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 82 (task 284, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.2.delta.724f4cc1-62bf-44f3-992c-919a7d2dcb10.TID282.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 3.0 (TID 282). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 84.0 in stage 3.0 (TID 286, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 3.0 (TID 282) in 285 ms on localhost (executor driver) (81/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 84.0 in stage 3.0 (TID 286)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44e52ef3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7027bcf5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.2.delta.fcc9fdff-323a-4fa1-bd89-d870b2aa0e29.TID283.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 3.0 (TID 283). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 85.0 in stage 3.0 (TID 287, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 3.0 (TID 283) in 298 ms on localhost (executor driver) (82/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 85.0 in stage 3.0 (TID 287)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.2.delta.f7de64fe-7237-4eb9-81aa-6030d451ae92.TID284.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 3.0 (TID 284). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35b72b18
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 86.0 in stage 3.0 (TID 288, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 3.0 (TID 284) in 269 ms on localhost (executor driver) (83/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 86.0 in stage 3.0 (TID 288)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52a0733c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab2df25
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,857][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,857][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b223002
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.2.delta.56210107-137b-4e07-8b5e-4bc3cdcf7fb6.TID285.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 83 (task 285, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 83 (task 285, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.2.delta.bba15d1f-19b8-4db3-a946-ff8ff556700f.TID286.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.2.delta.fd92f680-8cf3-447d-99cf-fbc9e2a076fa.TID287.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.2.delta.e51f4dd7-8433-441c-9e4b-d49688b01b01.TID288.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.2.delta.e73e5309-b434-49d1-ba1f-f8b802e091bc.TID285.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 3.0 (TID 285). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 87.0 in stage 3.0 (TID 289, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 3.0 (TID 285) in 285 ms on localhost (executor driver) (84/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 87.0 in stage 3.0 (TID 289)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56c26820
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56797bcb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:25,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.2.delta.14320aa4-61c7-4c1d-8961-7c08c394b0c8.TID289.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.2.delta.bba15d1f-19b8-4db3-a946-ff8ff556700f.TID286.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 84 (task 286, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 84 (task 286, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.2.delta.fd92f680-8cf3-447d-99cf-fbc9e2a076fa.TID287.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.2.delta.e51f4dd7-8433-441c-9e4b-d49688b01b01.TID288.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 85 (task 287, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 86 (task 288, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 85 (task 287, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,030][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 86 (task 288, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.2.delta.0890eb4b-3417-4e13-ad35-b658a1b273eb.TID286.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 3.0 (TID 286). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 88.0 in stage 3.0 (TID 290, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 3.0 (TID 286) in 237 ms on localhost (executor driver) (85/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 88.0 in stage 3.0 (TID 290)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d807cf5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b771d10
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.2.delta.28e5c375-7d6a-49f0-8bfa-e3c9aebd1385.TID287.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.2.delta.4b6efe55-7ee9-4717-803c-3eec1d82567c.TID288.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 3.0 (TID 287). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 89.0 in stage 3.0 (TID 291, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 3.0 (TID 287) in 235 ms on localhost (executor driver) (86/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 89.0 in stage 3.0 (TID 291)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 3.0 (TID 288). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 90.0 in stage 3.0 (TID 292, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 3.0 (TID 288) in 233 ms on localhost (executor driver) (87/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 90.0 in stage 3.0 (TID 292)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5114caff
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ffb9593
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a935d59
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75fbf6a2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.2.delta.14320aa4-61c7-4c1d-8961-7c08c394b0c8.TID289.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 87 (task 289, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 87 (task 289, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.2.delta.ab2fc560-c97a-48d3-9395-f79626ff2ac5.TID290.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.2.delta.c5462771-6f29-4b97-8d5f-d255fab26b6f.TID291.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.2.delta.82c39669-e41e-4b11-b4af-3d410fe20e7a.TID289.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 3.0 (TID 289). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 91.0 in stage 3.0 (TID 293, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.2.delta.ba2945c1-02ee-4f25-b98a-f93aadded5e1.TID292.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 3.0 (TID 289) in 223 ms on localhost (executor driver) (88/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 91.0 in stage 3.0 (TID 293)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21bc7de6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,150][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7112545b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,150][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.2.delta.68bb1414-4ed6-488f-904c-3dd50d9133e8.TID293.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.2.delta.ab2fc560-c97a-48d3-9395-f79626ff2ac5.TID290.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 88 (task 290, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 88 (task 290, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.2.delta.c5462771-6f29-4b97-8d5f-d255fab26b6f.TID291.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.2.delta.ba2945c1-02ee-4f25-b98a-f93aadded5e1.TID292.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 89 (task 291, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 89 (task 291, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 90 (task 292, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 90 (task 292, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,263][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.2.delta.118228eb-4554-416d-9718-3807e28c6b47.TID290.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 3.0 (TID 290). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 92.0 in stage 3.0 (TID 294, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 3.0 (TID 290) in 197 ms on localhost (executor driver) (89/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 92.0 in stage 3.0 (TID 294)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a4f5949
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c217dc6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.2.delta.2534e3c4-b8b1-40b2-b05e-15f4a16a1659.TID291.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.2.delta.9e722bac-44ff-443d-bdef-e4bb48df6b5f.TID292.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 3.0 (TID 291). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 93.0 in stage 3.0 (TID 295, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 3.0 (TID 292). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 3.0 (TID 291) in 201 ms on localhost (executor driver) (90/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 93.0 in stage 3.0 (TID 295)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 94.0 in stage 3.0 (TID 296, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 3.0 (TID 292) in 200 ms on localhost (executor driver) (91/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 94.0 in stage 3.0 (TID 296)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7545262c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f0e8cb4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b727304
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4061e1d3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.2.delta.68bb1414-4ed6-488f-904c-3dd50d9133e8.TID293.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 91 (task 293, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 91 (task 293, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.2.delta.22c9cb6d-62ff-4440-a572-01d3c0cfdcfd.TID294.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.2.delta.7c6dfba2-ad16-4e5f-b501-13c2391fc8ad.TID296.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.2.delta.8a15e325-32a5-4057-893d-eb71b0378b40.TID295.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.2.delta.c690c2f0-8c11-4062-a660-2a5934afcb5d.TID293.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 3.0 (TID 293). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 95.0 in stage 3.0 (TID 297, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 3.0 (TID 293) in 209 ms on localhost (executor driver) (92/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 95.0 in stage 3.0 (TID 297)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58e60e46
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64c54acd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.2.delta.53d7c160-0fc8-4962-8ce9-20fc9c27c39f.TID297.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.2.delta.7c6dfba2-ad16-4e5f-b501-13c2391fc8ad.TID296.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.2.delta.22c9cb6d-62ff-4440-a572-01d3c0cfdcfd.TID294.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 94 (task 296, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 92 (task 294, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 94 (task 296, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 92 (task 294, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.2.delta.8a15e325-32a5-4057-893d-eb71b0378b40.TID295.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 93 (task 295, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 93 (task 295, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.2.delta.48ba1d25-0470-41cd-8df0-426c852df99e.TID296.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.2.delta.bd74e885-0b67-4268-97c1-dbb056271828.TID294.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 3.0 (TID 296). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 96.0 in stage 3.0 (TID 298, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 3.0 (TID 296) in 177 ms on localhost (executor driver) (93/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 96.0 in stage 3.0 (TID 298)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 3.0 (TID 294). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 97.0 in stage 3.0 (TID 299, localhost, executor driver, partition 97, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 3.0 (TID 294) in 196 ms on localhost (executor driver) (94/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 97.0 in stage 3.0 (TID 299)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cea5d12
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@332ded9e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64ed6aad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c73d81d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.2.delta.53d7c160-0fc8-4962-8ce9-20fc9c27c39f.TID297.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.2.delta.82fdc9d6-6772-418b-8528-d57cb2efd247.TID295.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 95 (task 297, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 95 (task 297, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 3.0 (TID 295). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 98.0 in stage 3.0 (TID 300, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 3.0 (TID 295) in 200 ms on localhost (executor driver) (95/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 98.0 in stage 3.0 (TID 300)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47c2d81
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4119061d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,534][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.2.delta.99e09846-c12c-42e1-95b8-3bc2812babdf.TID298.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.2.delta.e71d8218-bfcd-4b07-8782-56363a275cc6.TID297.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.2.delta.2b4cb547-13b9-4fff-8f34-84035fb5b005.TID299.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 3.0 (TID 297). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 99.0 in stage 3.0 (TID 301, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 3.0 (TID 297) in 185 ms on localhost (executor driver) (96/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 99.0 in stage 3.0 (TID 301)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@114ec60
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@781eaebe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.2.delta.635c7b06-8692-4c9f-8673-e7aadc2d6976.TID300.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.2.delta.c178e991-92f4-4dac-9ca7-b5e2cd1d1c59.TID301.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.2.delta.2b4cb547-13b9-4fff-8f34-84035fb5b005.TID299.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.2.delta.99e09846-c12c-42e1-95b8-3bc2812babdf.TID298.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 97 (task 299, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 97 (task 299, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 96 (task 298, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 96 (task 298, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.2.delta.635c7b06-8692-4c9f-8673-e7aadc2d6976.TID300.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 98 (task 300, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 98 (task 300, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.2.delta.c178e991-92f4-4dac-9ca7-b5e2cd1d1c59.TID301.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 99 (task 301, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 99 (task 301, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.2.delta.2413172e-d7e3-4b59-94aa-7b449322c71b.TID299.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 3.0 (TID 299). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 100.0 in stage 3.0 (TID 302, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 3.0 (TID 299) in 270 ms on localhost (executor driver) (97/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 100.0 in stage 3.0 (TID 302)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.2.delta.fb63038a-278a-4acf-a0c2-c8652495ea5f.TID300.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.2.delta.db1b7cc6-b7ee-449f-9df0-867a481d19aa.TID298.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b028faa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 3.0 (TID 300). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 3.0 (TID 298). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 101.0 in stage 3.0 (TID 303, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 102.0 in stage 3.0 (TID 304, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 101.0 in stage 3.0 (TID 303)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 3.0 (TID 300) in 255 ms on localhost (executor driver) (98/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27f283a4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 102.0 in stage 3.0 (TID 304)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 3.0 (TID 298) in 277 ms on localhost (executor driver) (99/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29423ca9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7acfa61b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aeadf6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d3caae7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.2.delta.b0f04d76-a61e-4816-b8ae-7e2a9b708347.TID301.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 3.0 (TID 301). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 103.0 in stage 3.0 (TID 305, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 3.0 (TID 301) in 234 ms on localhost (executor driver) (100/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 103.0 in stage 3.0 (TID 305)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@84b1264
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f4910a0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,790][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.2.delta.e818a55d-0776-4f3c-97e2-06968658731f.TID302.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.2.delta.37e78964-61c0-483e-9f17-22b0030bba59.TID304.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.2.delta.491bb5da-b3f6-4a7e-99b6-54677f57b0fd.TID303.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.2.delta.14e43a44-d8ec-441a-91de-84182b789df9.TID305.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.2.delta.37e78964-61c0-483e-9f17-22b0030bba59.TID304.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.2.delta.491bb5da-b3f6-4a7e-99b6-54677f57b0fd.TID303.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 102 (task 304, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.2.delta.e818a55d-0776-4f3c-97e2-06968658731f.TID302.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 102 (task 304, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 101 (task 303, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 101 (task 303, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 100 (task 302, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 100 (task 302, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.2.delta.14e43a44-d8ec-441a-91de-84182b789df9.TID305.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 103 (task 305, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 103 (task 305, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.2.delta.45b92e02-e77e-45a0-bd94-2d0bdff406a1.TID304.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.2.delta.853ef5c3-b083-4905-bf28-ffe4ffa798ac.TID303.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.2.delta.a41bf383-5733-45d7-a80b-29f17271fc1d.TID302.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 3.0 (TID 304). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 3.0 (TID 302). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 3.0 (TID 303). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 104.0 in stage 3.0 (TID 306, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 105.0 in stage 3.0 (TID 307, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 104.0 in stage 3.0 (TID 306)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 106.0 in stage 3.0 (TID 308, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 105.0 in stage 3.0 (TID 307)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 3.0 (TID 304) in 250 ms on localhost (executor driver) (101/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 106.0 in stage 3.0 (TID 308)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 3.0 (TID 302) in 257 ms on localhost (executor driver) (102/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 3.0 (TID 303) in 252 ms on localhost (executor driver) (103/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b4b9c47
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32440fd2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a0dac8c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de92e23
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1642bfd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a19b64
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:26,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.2.delta.f84c919d-5418-4b69-9641-60ae81b196ad.TID305.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 3.0 (TID 305). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 107.0 in stage 3.0 (TID 309, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 3.0 (TID 305) in 245 ms on localhost (executor driver) (104/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 107.0 in stage 3.0 (TID 309)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c24e110
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f0a3697
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.2.delta.684cb7f0-d836-4ed2-b563-e32bd5212cb0.TID308.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.2.delta.32e7d4bb-6061-42cc-819d-38547cec13ad.TID307.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.2.delta.e74ac420-0faa-40a5-b84d-221ab90b34a7.TID306.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.2.delta.997ef1ff-00a4-4398-90de-7a5b9eb628f4.TID309.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.2.delta.684cb7f0-d836-4ed2-b563-e32bd5212cb0.TID308.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.2.delta.32e7d4bb-6061-42cc-819d-38547cec13ad.TID307.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 106 (task 308, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 106 (task 308, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 105 (task 307, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 105 (task 307, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.2.delta.e74ac420-0faa-40a5-b84d-221ab90b34a7.TID306.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 104 (task 306, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 104 (task 306, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.2.delta.5b43b3a8-8e40-43a5-a373-b4fe12c948c5.TID307.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.2.delta.997ef1ff-00a4-4398-90de-7a5b9eb628f4.TID309.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 3.0 (TID 307). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 108.0 in stage 3.0 (TID 310, localhost, executor driver, partition 108, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 3.0 (TID 307) in 155 ms on localhost (executor driver) (105/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 107 (task 309, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 108.0 in stage 3.0 (TID 310)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 107 (task 309, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.2.delta.d351c01a-c7e0-463a-b7e4-46217a2eab85.TID308.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 3.0 (TID 308). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 109.0 in stage 3.0 (TID 311, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25e6a5b2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 3.0 (TID 308) in 160 ms on localhost (executor driver) (106/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 109.0 in stage 3.0 (TID 311)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e95196c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30234243
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28cfd24b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.2.delta.dd9113e5-cfef-442a-a43d-2cf8d55bbaa4.TID306.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 3.0 (TID 306). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 110.0 in stage 3.0 (TID 312, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 3.0 (TID 306) in 176 ms on localhost (executor driver) (107/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 110.0 in stage 3.0 (TID 312)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@419d54bc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,164][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ae8e0f4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.2.delta.d4e1b96f-0d6c-4f51-b85a-dc0bf8f628ff.TID309.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 3.0 (TID 309). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 111.0 in stage 3.0 (TID 313, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 3.0 (TID 309) in 196 ms on localhost (executor driver) (108/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 111.0 in stage 3.0 (TID 313)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ef57aa2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c15820d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.2.delta.eed4ad6e-a757-48f1-aac0-38c7ff41056d.TID310.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.2.delta.c05bb52d-d9fc-4373-ae4d-0225846daa5b.TID311.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.2.delta.a48aad0d-83e8-47a4-a274-0f9ba0da5c1b.TID312.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.2.delta.ee917ffb-3609-4ecc-ba77-96dcdad2fe49.TID313.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.2.delta.eed4ad6e-a757-48f1-aac0-38c7ff41056d.TID310.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 108 (task 310, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 108 (task 310, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.2.delta.c05bb52d-d9fc-4373-ae4d-0225846daa5b.TID311.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 109 (task 311, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 109 (task 311, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.2.delta.a48aad0d-83e8-47a4-a274-0f9ba0da5c1b.TID312.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 110 (task 312, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 110 (task 312, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.2.delta.56c717da-3bd8-425a-b65c-798b6c8eeaf8.TID310.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 3.0 (TID 310). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 112.0 in stage 3.0 (TID 314, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 3.0 (TID 310) in 198 ms on localhost (executor driver) (109/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 112.0 in stage 3.0 (TID 314)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.2.delta.93d41a54-c048-4605-b8f7-e3138db58051.TID311.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 3.0 (TID 311). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ccd3a3d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 113.0 in stage 3.0 (TID 315, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 3.0 (TID 311) in 196 ms on localhost (executor driver) (110/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 113.0 in stage 3.0 (TID 315)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78105615
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.2.delta.ee917ffb-3609-4ecc-ba77-96dcdad2fe49.TID313.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dc73032
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a3bb9f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 111 (task 313, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 111 (task 313, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.2.delta.2d6c05e8-ec25-4e53-a039-faf318fe781a.TID312.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 3.0 (TID 312). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 114.0 in stage 3.0 (TID 316, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 3.0 (TID 312) in 200 ms on localhost (executor driver) (111/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 114.0 in stage 3.0 (TID 316)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e6682f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c04b105
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.2.delta.059a830c-eecd-4f76-8711-d236afd7c015.TID314.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.2.delta.c9a06cc6-7151-4947-af07-1dd37364b535.TID313.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 3.0 (TID 313). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 115.0 in stage 3.0 (TID 317, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 3.0 (TID 313) in 291 ms on localhost (executor driver) (112/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 115.0 in stage 3.0 (TID 317)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.2.delta.49a321ef-f396-4d6f-864e-1e935f2421d7.TID315.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52f09013
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6be83fad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.2.delta.6cd9d657-48d3-4b68-a279-86134651f480.TID316.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.2.delta.5bdd86b9-dfa8-4a5f-ac22-79f9562e418f.TID317.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.2.delta.059a830c-eecd-4f76-8711-d236afd7c015.TID314.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 112 (task 314, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 112 (task 314, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.2.delta.6cd9d657-48d3-4b68-a279-86134651f480.TID316.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.2.delta.49a321ef-f396-4d6f-864e-1e935f2421d7.TID315.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 114 (task 316, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 114 (task 316, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 113 (task 315, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 113 (task 315, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.2.delta.8f08ddb8-01f4-4335-819d-8f34febfe20c.TID314.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.2.delta.5bdd86b9-dfa8-4a5f-ac22-79f9562e418f.TID317.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 3.0 (TID 314). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 116.0 in stage 3.0 (TID 318, localhost, executor driver, partition 116, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 3.0 (TID 314) in 309 ms on localhost (executor driver) (113/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 116.0 in stage 3.0 (TID 318)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 115 (task 317, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 115 (task 317, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.2.delta.5e574c46-2ae7-49dd-8747-0b96d5cb457f.TID316.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7da000e0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 3.0 (TID 316). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 117.0 in stage 3.0 (TID 319, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6374bb65
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 3.0 (TID 316) in 294 ms on localhost (executor driver) (114/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 117.0 in stage 3.0 (TID 319)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.2.delta.decb9851-6a56-4049-a46a-5824e2d49acb.TID315.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6710be03
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 3.0 (TID 315). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 118.0 in stage 3.0 (TID 320, localhost, executor driver, partition 118, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 3.0 (TID 315) in 317 ms on localhost (executor driver) (115/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 118.0 in stage 3.0 (TID 320)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c26aff5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eed4010
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ecc9231
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.2.delta.f00b0301-3844-45ba-96cc-06335c0478ee.TID317.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 3.0 (TID 317). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 119.0 in stage 3.0 (TID 321, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 119.0 in stage 3.0 (TID 321)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 3.0 (TID 317) in 200 ms on localhost (executor driver) (116/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ef3a441
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@364effb4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.2.delta.49d7eba7-2fe6-4613-91d2-d68e75d2feaa.TID319.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.2.delta.615e8a12-c246-4d23-83c8-63c1e394a77f.TID318.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.2.delta.d72515d4-e7d0-4b3b-910a-0fbbe6c40f37.TID320.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.2.delta.7d8062f2-7f88-4047-afa8-29e86fc5d1fc.TID321.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.2.delta.49d7eba7-2fe6-4613-91d2-d68e75d2feaa.TID319.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.2.delta.615e8a12-c246-4d23-83c8-63c1e394a77f.TID318.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 117 (task 319, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 117 (task 319, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 116 (task 318, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 116 (task 318, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.2.delta.d72515d4-e7d0-4b3b-910a-0fbbe6c40f37.TID320.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 118 (task 320, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 118 (task 320, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.2.delta.7d8062f2-7f88-4047-afa8-29e86fc5d1fc.TID321.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 119 (task 321, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 119 (task 321, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.2.delta.26bfe0f9-cce3-44fa-bf97-50b42d275cc9.TID319.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 3.0 (TID 319). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.2.delta.6fdfe3a2-6509-4993-9ab9-a2c00e2e7c04.TID318.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 120.0 in stage 3.0 (TID 322, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 3.0 (TID 319) in 188 ms on localhost (executor driver) (117/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 120.0 in stage 3.0 (TID 322)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 3.0 (TID 318). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 121.0 in stage 3.0 (TID 323, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 3.0 (TID 318) in 197 ms on localhost (executor driver) (118/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 121.0 in stage 3.0 (TID 323)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77173201
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22993f0d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fd3becb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65b11735
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.2.delta.f10fb828-3ac1-4337-99ff-57f69c2ab363.TID320.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,857][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 3.0 (TID 320). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 122.0 in stage 3.0 (TID 324, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 3.0 (TID 320) in 202 ms on localhost (executor driver) (119/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 122.0 in stage 3.0 (TID 324)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@159a3f05
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bc44c84
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.2.delta.13509dd6-40c1-44f8-8ef8-77e83b830f00.TID321.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 3.0 (TID 321). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,888][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 123.0 in stage 3.0 (TID 325, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 3.0 (TID 321) in 190 ms on localhost (executor driver) (120/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 123.0 in stage 3.0 (TID 325)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.2.delta.118fbd36-99d2-4020-976b-dbb0fb420c94.TID322.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27c8e39b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1da6bb3c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.2.delta.a03eebf7-11a0-4616-aab1-a2e4255a256b.TID323.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.2.delta.2e52d033-17e3-4b31-90ab-3fef74518a98.TID324.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.2.delta.ebeb30f0-2f4d-4d3e-88fd-ca909ca06db5.TID325.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.2.delta.118fbd36-99d2-4020-976b-dbb0fb420c94.TID322.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.2.delta.a03eebf7-11a0-4616-aab1-a2e4255a256b.TID323.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 121 (task 323, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 120 (task 322, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 121 (task 323, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 120 (task 322, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.2.delta.2e52d033-17e3-4b31-90ab-3fef74518a98.TID324.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 122 (task 324, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 122 (task 324, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.2.delta.3dd60c50-5164-44b4-98ef-513538b213fb.TID323.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.2.delta.4db73650-26a1-4515-873a-432cc358e002.TID322.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 3.0 (TID 323). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 3.0 (TID 322). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 124.0 in stage 3.0 (TID 326, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 125.0 in stage 3.0 (TID 327, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 124.0 in stage 3.0 (TID 326)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 3.0 (TID 323) in 153 ms on localhost (executor driver) (121/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 125.0 in stage 3.0 (TID 327)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 3.0 (TID 322) in 157 ms on localhost (executor driver) (122/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@448e3d23
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d7acc03
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cf9f776
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38fecf82
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:27,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.2.delta.ebeb30f0-2f4d-4d3e-88fd-ca909ca06db5.TID325.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 123 (task 325, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 123 (task 325, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.2.delta.1c7dd76d-7eba-437f-852e-b14e7a68fff6.TID324.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 3.0 (TID 324). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 126.0 in stage 3.0 (TID 328, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 3.0 (TID 324) in 169 ms on localhost (executor driver) (123/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 126.0 in stage 3.0 (TID 328)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7adeac36
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6605f6b4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.2.delta.411caf79-b01a-464f-80ed-e95642d96e68.TID325.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 3.0 (TID 325). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 127.0 in stage 3.0 (TID 329, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 3.0 (TID 325) in 179 ms on localhost (executor driver) (124/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 127.0 in stage 3.0 (TID 329)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f714fea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a01e4a3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.2.delta.c2fb18c9-57e0-48a3-b565-da72c7aa3ed0.TID326.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.2.delta.e07fc083-8e9b-4447-a9c3-35e3fdad3981.TID327.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.2.delta.66f6fc71-1fc5-4731-a512-d4674a5b0c61.TID328.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.2.delta.95f4505e-2c3e-4bc4-9bea-9856eab57344.TID329.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.2.delta.c2fb18c9-57e0-48a3-b565-da72c7aa3ed0.TID326.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 124 (task 326, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 124 (task 326, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.2.delta.e07fc083-8e9b-4447-a9c3-35e3fdad3981.TID327.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 125 (task 327, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 125 (task 327, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.2.delta.66f6fc71-1fc5-4731-a512-d4674a5b0c61.TID328.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 126 (task 328, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 126 (task 328, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.2.delta.bbb4015f-a87b-43e2-b7d6-dd874c3adfb5.TID326.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.2.delta.ad074588-a6fd-4c94-a128-4e8a4ac33cc4.TID327.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 3.0 (TID 326). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 128.0 in stage 3.0 (TID 330, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 3.0 (TID 326) in 232 ms on localhost (executor driver) (125/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 128.0 in stage 3.0 (TID 330)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e550b4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4780277d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 3.0 (TID 327). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 129.0 in stage 3.0 (TID 331, localhost, executor driver, partition 129, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 3.0 (TID 327) in 238 ms on localhost (executor driver) (126/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 129.0 in stage 3.0 (TID 331)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.2.delta.95f4505e-2c3e-4bc4-9bea-9856eab57344.TID329.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ffb24c1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 127 (task 329, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 127 (task 329, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dd38556
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.2.delta.e0256250-22d8-4931-8219-f171ffd9104a.TID328.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 3.0 (TID 328). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 130.0 in stage 3.0 (TID 332, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 3.0 (TID 328) in 224 ms on localhost (executor driver) (127/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 130.0 in stage 3.0 (TID 332)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43917c65
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ce90414
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.2.delta.efa65d2d-5a3e-44ad-818e-3ccdedeb9c17.TID330.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.2.delta.1de18f4b-c317-47e5-8b8b-015250bdfb91.TID329.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 3.0 (TID 329). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 131.0 in stage 3.0 (TID 333, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 3.0 (TID 329) in 212 ms on localhost (executor driver) (128/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 131.0 in stage 3.0 (TID 333)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aa311d0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74d87f90
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.2.delta.da7b5b2f-b8e4-4792-9616-bb941bf5fd1f.TID331.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.2.delta.26e99065-5492-4c16-abd1-8396381844c6.TID332.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.2.delta.e8263505-5f20-47de-b144-9f476bad9ead.TID333.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.2.delta.efa65d2d-5a3e-44ad-818e-3ccdedeb9c17.TID330.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 128 (task 330, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 128 (task 330, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.2.delta.da7b5b2f-b8e4-4792-9616-bb941bf5fd1f.TID331.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 129 (task 331, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 129 (task 331, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.2.delta.26e99065-5492-4c16-abd1-8396381844c6.TID332.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 130 (task 332, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 130 (task 332, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.2.delta.775560d5-aced-4401-a3d1-80c286a60c76.TID330.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 3.0 (TID 330). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 132.0 in stage 3.0 (TID 334, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 3.0 (TID 330) in 194 ms on localhost (executor driver) (129/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 132.0 in stage 3.0 (TID 334)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.2.delta.e8263505-5f20-47de-b144-9f476bad9ead.TID333.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 131 (task 333, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 131 (task 333, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b19c5c8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a0eec78
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.2.delta.f214bde1-57bf-43f9-9e3f-0d42742e0e0f.TID331.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 3.0 (TID 331). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 133.0 in stage 3.0 (TID 335, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 3.0 (TID 331) in 211 ms on localhost (executor driver) (130/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 133.0 in stage 3.0 (TID 335)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.2.delta.fdfaae12-b672-49aa-a155-4ca7c7d0e447.TID332.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31df3bd8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 3.0 (TID 332). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3705342d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 134.0 in stage 3.0 (TID 336, localhost, executor driver, partition 134, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 3.0 (TID 332) in 197 ms on localhost (executor driver) (131/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 134.0 in stage 3.0 (TID 336)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c071ec1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a73a374
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.2.delta.cd1f1806-4431-459a-b9ce-537ea1636420.TID333.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 3.0 (TID 333). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 135.0 in stage 3.0 (TID 337, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 3.0 (TID 333) in 191 ms on localhost (executor driver) (132/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 135.0 in stage 3.0 (TID 337)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.2.delta.89187ee4-1744-4e5f-9d79-ed73ed9dbe54.TID334.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73b9382f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1af64672
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.2.delta.85ae94ac-a998-4030-9c9e-ef7648af8945.TID335.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.2.delta.568e2365-0401-4d99-9176-3e1c3f30e188.TID336.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.2.delta.cd3a9c7b-d3c9-41e6-93a9-a8b475ec25d3.TID337.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.2.delta.89187ee4-1744-4e5f-9d79-ed73ed9dbe54.TID334.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 132 (task 334, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 132 (task 334, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.2.delta.85ae94ac-a998-4030-9c9e-ef7648af8945.TID335.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 133 (task 335, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 133 (task 335, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.2.delta.568e2365-0401-4d99-9176-3e1c3f30e188.TID336.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 134 (task 336, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 134 (task 336, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.2.delta.cd3a9c7b-d3c9-41e6-93a9-a8b475ec25d3.TID337.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 135 (task 337, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 135 (task 337, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.2.delta.4fd4985c-98b7-464e-b288-eaad31f516e7.TID334.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 3.0 (TID 334). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 136.0 in stage 3.0 (TID 338, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 3.0 (TID 334) in 195 ms on localhost (executor driver) (133/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 136.0 in stage 3.0 (TID 338)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52fdb00e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7708ecbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.2.delta.62cbe4ff-a610-414b-b507-89b6d055cdd5.TID335.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 3.0 (TID 335). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 137.0 in stage 3.0 (TID 339, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 3.0 (TID 335) in 192 ms on localhost (executor driver) (134/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 137.0 in stage 3.0 (TID 339)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ed9f201
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30b407ad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.2.delta.1601a43f-d203-450f-9bac-fb0239da7c8d.TID336.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 3.0 (TID 336). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 138.0 in stage 3.0 (TID 340, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 3.0 (TID 336) in 197 ms on localhost (executor driver) (135/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 138.0 in stage 3.0 (TID 340)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@387d2647
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d4e9761
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.2.delta.fe227bc5-f4a5-489f-9d87-e37dba9cc896.TID337.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 3.0 (TID 337). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 139.0 in stage 3.0 (TID 341, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 3.0 (TID 337) in 188 ms on localhost (executor driver) (136/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 139.0 in stage 3.0 (TID 341)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d1bf878
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ad27af
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.2.delta.3963afa0-4175-4b48-ab62-097762afc74e.TID338.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.2.delta.d9eba66b-fc4a-4e01-90e5-116925bfc57f.TID339.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.2.delta.a4127180-9df9-485e-8fe9-89fcd2da139e.TID340.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.2.delta.3827f5e0-f62a-4efe-b368-ed71e2078655.TID341.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.2.delta.3963afa0-4175-4b48-ab62-097762afc74e.TID338.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 136 (task 338, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 136 (task 338, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.2.delta.d9eba66b-fc4a-4e01-90e5-116925bfc57f.TID339.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 137 (task 339, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 137 (task 339, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.2.delta.c8f13d45-c486-4c43-9bc0-a300c7dbd4ad.TID338.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.2.delta.a4127180-9df9-485e-8fe9-89fcd2da139e.TID340.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 138 (task 340, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 138 (task 340, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 3.0 (TID 338). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 140.0 in stage 3.0 (TID 342, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 3.0 (TID 338) in 191 ms on localhost (executor driver) (137/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 140.0 in stage 3.0 (TID 342)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.2.delta.3827f5e0-f62a-4efe-b368-ed71e2078655.TID341.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a28f39
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dff49e7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 139 (task 341, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 139 (task 341, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.2.delta.93d5deb0-1040-4cd4-9885-6ad1b284f6d4.TID339.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 3.0 (TID 339). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 141.0 in stage 3.0 (TID 343, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 3.0 (TID 339) in 190 ms on localhost (executor driver) (138/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 141.0 in stage 3.0 (TID 343)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61c3709f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@137946fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.2.delta.9a7e4514-b4fe-4a90-95df-158880b8f81f.TID340.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 3.0 (TID 340). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 142.0 in stage 3.0 (TID 344, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 3.0 (TID 340) in 198 ms on localhost (executor driver) (139/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 142.0 in stage 3.0 (TID 344)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.2.delta.dd23c52d-c888-4942-8217-28828eebe8aa.TID341.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 3.0 (TID 341). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@313c5feb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 143.0 in stage 3.0 (TID 345, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 3.0 (TID 341) in 194 ms on localhost (executor driver) (140/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 143.0 in stage 3.0 (TID 345)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.2.delta.5afba5e6-53a3-4d68-8a0b-235461b43b3c.TID342.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67f60a13
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aa5f27b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bf19532
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.2.delta.dc704d81-4d56-44c0-a599-01e1db515f9e.TID343.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.2.delta.e79924b1-2a9c-42f7-9063-d90bcc88deee.TID344.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,916][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.2.delta.c1724b33-a15a-4dbe-bc8a-a7b967dba622.TID345.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.2.delta.5afba5e6-53a3-4d68-8a0b-235461b43b3c.TID342.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 140 (task 342, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 140 (task 342, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.2.delta.dc704d81-4d56-44c0-a599-01e1db515f9e.TID343.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 141 (task 343, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:28,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 141 (task 343, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.2.delta.e79924b1-2a9c-42f7-9063-d90bcc88deee.TID344.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.2.delta.6d77cc5f-bae6-45e3-81e4-5bede561ca8f.TID342.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 142 (task 344, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 3.0 (TID 342). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 142 (task 344, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 144.0 in stage 3.0 (TID 346, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 3.0 (TID 342) in 211 ms on localhost (executor driver) (141/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 144.0 in stage 3.0 (TID 346)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.2.delta.c1724b33-a15a-4dbe-bc8a-a7b967dba622.TID345.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fb24529
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 143 (task 345, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 143 (task 345, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4db3e67d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.2.delta.3344751d-3cbd-4e7e-89e8-ce243b789dcb.TID343.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 3.0 (TID 343). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 145.0 in stage 3.0 (TID 347, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 3.0 (TID 343) in 237 ms on localhost (executor driver) (142/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 145.0 in stage 3.0 (TID 347)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c330f8b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3195dd34
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.2.delta.c4bf89b9-a453-4855-a691-96e3cf901fb2.TID345.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.2.delta.9aa14ee5-ced6-4731-9d43-a36b687e6c51.TID344.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.2.delta.3c185622-afcb-4852-8e45-a0d568e741f4.TID346.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 3.0 (TID 345). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 3.0 (TID 344). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 146.0 in stage 3.0 (TID 348, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 147.0 in stage 3.0 (TID 349, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 146.0 in stage 3.0 (TID 348)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 3.0 (TID 345) in 238 ms on localhost (executor driver) (143/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 3.0 (TID 344) in 244 ms on localhost (executor driver) (144/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 147.0 in stage 3.0 (TID 349)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec3edb6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1798b6a8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26e3801c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fbde2e5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.2.delta.3a3d7a68-8294-425e-89f5-d2b520aa076d.TID347.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.2.delta.6a785635-56b1-41c7-8c22-1cd27a217748.TID348.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.2.delta.bc7d52ed-8b0c-41ab-9f91-1b69f5359b4d.TID349.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.2.delta.3c185622-afcb-4852-8e45-a0d568e741f4.TID346.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 144 (task 346, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 144 (task 346, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.2.delta.3a3d7a68-8294-425e-89f5-d2b520aa076d.TID347.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 145 (task 347, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 145 (task 347, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.2.delta.c4fa5704-66bc-42ce-922c-e6e00a2cfbb6.TID346.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 3.0 (TID 346). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 148.0 in stage 3.0 (TID 350, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 3.0 (TID 346) in 213 ms on localhost (executor driver) (145/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 148.0 in stage 3.0 (TID 350)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4229d409
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e8e2029
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.2.delta.6a785635-56b1-41c7-8c22-1cd27a217748.TID348.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.2.delta.bc7d52ed-8b0c-41ab-9f91-1b69f5359b4d.TID349.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 146 (task 348, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 146 (task 348, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 147 (task 349, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 147 (task 349, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.2.delta.13c0695f-44a7-4484-85f7-abbd88e297b1.TID347.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 3.0 (TID 347). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 149.0 in stage 3.0 (TID 351, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 3.0 (TID 347) in 194 ms on localhost (executor driver) (146/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 149.0 in stage 3.0 (TID 351)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d76ae7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@132fba34
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.2.delta.cac27ce2-97c6-4bef-8a7b-45eadf7608fc.TID350.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.2.delta.2feb873d-82ca-4ab3-8d19-41313e9e61e6.TID348.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.2.delta.c4f3cb1d-64e9-4ee9-9bb4-b37fe4300cbf.TID349.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 3.0 (TID 348). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 3.0 (TID 349). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 150.0 in stage 3.0 (TID 352, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 3.0 (TID 348) in 210 ms on localhost (executor driver) (147/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 150.0 in stage 3.0 (TID 352)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 151.0 in stage 3.0 (TID 353, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 3.0 (TID 349) in 213 ms on localhost (executor driver) (148/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,299][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 151.0 in stage 3.0 (TID 353)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dd2f113
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d0248dc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b973524
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74726208
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.2.delta.7ee39731-3219-4ef4-8962-91506f3df9f4.TID351.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.2.delta.0451f616-f4ca-4988-a136-16896d67be98.TID352.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.2.delta.0c2b778a-7c2c-4ce7-97e8-313a469c9e18.TID353.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.2.delta.cac27ce2-97c6-4bef-8a7b-45eadf7608fc.TID350.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 148 (task 350, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 148 (task 350, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.2.delta.7ee39731-3219-4ef4-8962-91506f3df9f4.TID351.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 149 (task 351, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 149 (task 351, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.2.delta.6a6218f3-d38c-453c-ad1b-72eb2991b2af.TID350.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 3.0 (TID 350). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 152.0 in stage 3.0 (TID 354, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 3.0 (TID 350) in 222 ms on localhost (executor driver) (149/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 152.0 in stage 3.0 (TID 354)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.2.delta.0451f616-f4ca-4988-a136-16896d67be98.TID352.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76626c56
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41f5f34b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 150 (task 352, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 150 (task 352, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.2.delta.0c2b778a-7c2c-4ce7-97e8-313a469c9e18.TID353.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 151 (task 353, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 151 (task 353, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.2.delta.59482825-226b-41b9-84f7-c57e295e59f3.TID351.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,466][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 3.0 (TID 351). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 153.0 in stage 3.0 (TID 355, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 3.0 (TID 351) in 214 ms on localhost (executor driver) (150/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 153.0 in stage 3.0 (TID 355)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@573c063f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70935c83
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.2.delta.655d91a9-e87a-4b0c-97c4-4f4ad900dc27.TID352.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,497][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 3.0 (TID 352). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 154.0 in stage 3.0 (TID 356, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 3.0 (TID 352) in 205 ms on localhost (executor driver) (151/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 154.0 in stage 3.0 (TID 356)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.2.delta.1422793a-e0c2-46ff-99d7-311882408ba0.TID353.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 3.0 (TID 353). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 155.0 in stage 3.0 (TID 357, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 3.0 (TID 353) in 205 ms on localhost (executor driver) (152/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 155.0 in stage 3.0 (TID 357)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e1a8b6e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,504][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.2.delta.4689f703-9061-4186-8d42-39477af942c7.TID354.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,504][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36155bbb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,504][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,504][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@605016cc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a4b216f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.2.delta.bd8e564a-ff7f-42c1-97bb-f50da2f7bee8.TID355.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.2.delta.ad8808d1-8db1-41ac-8844-0a7fa0eafac9.TID356.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.2.delta.80a24dd0-df99-47f3-8e0c-a7dd82d2d0ae.TID357.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.2.delta.4689f703-9061-4186-8d42-39477af942c7.TID354.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 152 (task 354, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 152 (task 354, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.2.delta.bd8e564a-ff7f-42c1-97bb-f50da2f7bee8.TID355.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 153 (task 355, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 153 (task 355, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.2.delta.1abd1d44-9614-4119-9251-cff505232d60.TID354.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.2.delta.ad8808d1-8db1-41ac-8844-0a7fa0eafac9.TID356.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 3.0 (TID 354). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 156.0 in stage 3.0 (TID 358, localhost, executor driver, partition 156, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 154 (task 356, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 3.0 (TID 354) in 200 ms on localhost (executor driver) (153/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 156.0 in stage 3.0 (TID 358)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 154 (task 356, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70bca7a9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,156,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a7a62f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,156,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.2.delta.80a24dd0-df99-47f3-8e0c-a7dd82d2d0ae.TID357.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 155 (task 357, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 155 (task 357, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.2.delta.22cc1cf6-a212-4dc4-a2f8-132ac07349d4.TID355.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 3.0 (TID 355). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 157.0 in stage 3.0 (TID 359, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 3.0 (TID 355) in 203 ms on localhost (executor driver) (154/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 157.0 in stage 3.0 (TID 359)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551574d2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,157,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@654a150d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,157,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.2.delta.6310d0a1-d6c0-464b-bdb9-aa92dea8a3b2.TID356.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.2.delta.bdbc609d-ae41-4341-91f8-9e9763a0b33f.TID358.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 3.0 (TID 356). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 158.0 in stage 3.0 (TID 360, localhost, executor driver, partition 158, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 3.0 (TID 356) in 194 ms on localhost (executor driver) (155/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 158.0 in stage 3.0 (TID 360)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.2.delta.ee3f5898-9647-4020-a947-e074913177fe.TID357.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@adef342
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,158,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76f6d4d4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,158,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 3.0 (TID 357). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 159.0 in stage 3.0 (TID 361, localhost, executor driver, partition 159, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 3.0 (TID 357) in 197 ms on localhost (executor driver) (156/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 159.0 in stage 3.0 (TID 361)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6099912
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,159,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52f0da14
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,159,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.2.delta.e85b543f-d3a7-45a1-aa9b-4f1cf8d5174a.TID359.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.2.delta.8c123a6f-2c1e-4757-8bb0-9450d7ff8129.TID360.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.2.delta.38785d12-3b92-4365-ae38-6ce3720b1587.TID361.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.2.delta.bdbc609d-ae41-4341-91f8-9e9763a0b33f.TID358.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 156 (task 358, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 156 (task 358, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.2.delta.e85b543f-d3a7-45a1-aa9b-4f1cf8d5174a.TID359.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 157 (task 359, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 157 (task 359, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156/.2.delta.a5973578-878d-4fa4-b139-152a2eeafddb.TID358.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/156]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 3.0 (TID 358). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 160.0 in stage 3.0 (TID 362, localhost, executor driver, partition 160, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 3.0 (TID 358) in 150 ms on localhost (executor driver) (157/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 160.0 in stage 3.0 (TID 362)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.2.delta.8c123a6f-2c1e-4757-8bb0-9450d7ff8129.TID360.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8b7f36
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 158 (task 360, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,160,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 158 (task 360, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35facd7a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,160,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.2.delta.38785d12-3b92-4365-ae38-6ce3720b1587.TID361.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 159 (task 361, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 159 (task 361, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157/.2.delta.78785fe4-efad-4de3-880d-c364abf3525b.TID359.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/157]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 3.0 (TID 359). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 161.0 in stage 3.0 (TID 363, localhost, executor driver, partition 161, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 3.0 (TID 359) in 157 ms on localhost (executor driver) (158/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 161.0 in stage 3.0 (TID 363)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79ffc40b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,161,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27842d2c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,161,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158/.2.delta.72f97153-0e38-4a30-b1b8-ff2d1dea3843.TID360.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.2.delta.05fb2514-45a2-44e1-a4b0-269d77c51e90.TID362.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/158]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 3.0 (TID 360). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 162.0 in stage 3.0 (TID 364, localhost, executor driver, partition 162, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 3.0 (TID 360) in 156 ms on localhost (executor driver) (159/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 162.0 in stage 3.0 (TID 364)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fdfb3fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,162,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e01846f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,162,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159/.2.delta.e1acd323-d15d-4546-9ccc-af4280a7dd8d.TID361.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/159]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 3.0 (TID 361). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 163.0 in stage 3.0 (TID 365, localhost, executor driver, partition 163, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 3.0 (TID 361) in 167 ms on localhost (executor driver) (160/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 163.0 in stage 3.0 (TID 365)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4925a7f5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,163,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17dd65c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,163,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,870][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.2.delta.99c92ba3-9cb5-4557-8441-86b54228cf14.TID363.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.2.delta.b309c296-3062-4b18-b19d-b1151026d8f9.TID364.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.2.delta.05fb2514-45a2-44e1-a4b0-269d77c51e90.TID362.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 160 (task 362, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 160 (task 362, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,908][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.2.delta.50e3583d-5b9f-40cd-ada5-48978519aa97.TID365.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.2.delta.99c92ba3-9cb5-4557-8441-86b54228cf14.TID363.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160/.2.delta.3051d8ca-f2c2-4e55-a944-44bb88f64bf7.TID362.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 161 (task 363, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 161 (task 363, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/160]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 3.0 (TID 362). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 164.0 in stage 3.0 (TID 366, localhost, executor driver, partition 164, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 3.0 (TID 362) in 146 ms on localhost (executor driver) (161/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 164.0 in stage 3.0 (TID 366)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@694e6a94
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,164,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fac4ec5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,164,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.2.delta.b309c296-3062-4b18-b19d-b1151026d8f9.TID364.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 162 (task 364, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 162 (task 364, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.2.delta.50e3583d-5b9f-40cd-ada5-48978519aa97.TID365.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 163 (task 365, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 163 (task 365, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:29,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161/.2.delta.3ab4a565-afb8-4638-b8e8-42847fb06986.TID363.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/161]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 3.0 (TID 363). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 165.0 in stage 3.0 (TID 367, localhost, executor driver, partition 165, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 3.0 (TID 363) in 178 ms on localhost (executor driver) (162/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 165.0 in stage 3.0 (TID 367)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@407ca334
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,165,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44793c11
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,165,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.2.delta.457fceca-27b3-4d29-b626-ff7eaddc41e6.TID366.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162/.2.delta.70953f9c-a604-4439-bd5a-21cf8a0e4869.TID364.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/162]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 3.0 (TID 364). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 166.0 in stage 3.0 (TID 368, localhost, executor driver, partition 166, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 3.0 (TID 364) in 231 ms on localhost (executor driver) (163/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 166.0 in stage 3.0 (TID 368)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163/.2.delta.22f2d69f-86f1-4a76-a69a-1b454b8739a3.TID365.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9c6100
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,166,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/163]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29b7b9ec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,166,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 3.0 (TID 365). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 167.0 in stage 3.0 (TID 369, localhost, executor driver, partition 167, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 3.0 (TID 365) in 224 ms on localhost (executor driver) (164/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 167.0 in stage 3.0 (TID 369)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612746fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,167,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fb99567
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,167,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.2.delta.ec45123a-e9c3-4581-b266-fc1a11a10a2c.TID367.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.2.delta.accfbdd1-695e-4e7c-bb4f-fee2fccff31a.TID368.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.2.delta.457fceca-27b3-4d29-b626-ff7eaddc41e6.TID366.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 164 (task 366, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 164 (task 366, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.2.delta.cb5db931-1eb9-4fbc-b956-73ff3a95cd73.TID369.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.2.delta.ec45123a-e9c3-4581-b266-fc1a11a10a2c.TID367.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 165 (task 367, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 165 (task 367, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164/.2.delta.e49a62ba-7760-4e16-9907-6981c87fc27f.TID366.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/164]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 3.0 (TID 366). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 168.0 in stage 3.0 (TID 370, localhost, executor driver, partition 168, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 3.0 (TID 366) in 228 ms on localhost (executor driver) (165/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 168.0 in stage 3.0 (TID 370)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e91410
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,168,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5be77d23
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,168,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165/.2.delta.1321af4c-2d75-4bcc-805e-7b44f2af0363.TID367.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.2.delta.accfbdd1-695e-4e7c-bb4f-fee2fccff31a.TID368.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/165]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 166 (task 368, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 166 (task 368, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 3.0 (TID 367). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 169.0 in stage 3.0 (TID 371, localhost, executor driver, partition 169, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 3.0 (TID 367) in 204 ms on localhost (executor driver) (166/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 169.0 in stage 3.0 (TID 371)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.2.delta.28cf3c7d-3811-4b02-ae0f-424615134c2e.TID370.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.2.delta.cb5db931-1eb9-4fbc-b956-73ff3a95cd73.TID369.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,212][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5721bc70
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,212][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,212][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,169,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,213][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b40295e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 167 (task 369, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,169,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 167 (task 369, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166/.2.delta.2f4378bd-5667-4045-9153-aa4a4b35e3a6.TID368.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/166]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 3.0 (TID 368). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 170.0 in stage 3.0 (TID 372, localhost, executor driver, partition 170, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 3.0 (TID 368) in 168 ms on localhost (executor driver) (167/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 170.0 in stage 3.0 (TID 372)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@277baf46
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,170,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167/.2.delta.d47e1a7f-e4ea-4b91-928e-f2b649ae57a6.TID369.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d4e05fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,170,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/167]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 3.0 (TID 369). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 171.0 in stage 3.0 (TID 373, localhost, executor driver, partition 171, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 3.0 (TID 369) in 163 ms on localhost (executor driver) (168/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 171.0 in stage 3.0 (TID 373)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.2.delta.e877c40e-b448-4977-91dc-a412aa8d174a.TID371.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e3e8821
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,171,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3267b1c2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,171,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.2.delta.28cf3c7d-3811-4b02-ae0f-424615134c2e.TID370.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 168 (task 370, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 168 (task 370, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.2.delta.6160bd82-5ef7-466e-982e-30e36c4afa8a.TID373.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.2.delta.68c7fb3d-31f2-4f98-b7c6-602c0df4771d.TID372.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168/.2.delta.5c356fa3-5797-4fa8-9bb0-9a978844bc9e.TID370.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/168]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 3.0 (TID 370). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 172.0 in stage 3.0 (TID 374, localhost, executor driver, partition 172, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 172.0 in stage 3.0 (TID 374)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 3.0 (TID 370) in 161 ms on localhost (executor driver) (169/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d6c961e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,172,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ab2af8b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,172,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.2.delta.e877c40e-b448-4977-91dc-a412aa8d174a.TID371.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 169 (task 371, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 169 (task 371, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.2.delta.6160bd82-5ef7-466e-982e-30e36c4afa8a.TID373.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.2.delta.68c7fb3d-31f2-4f98-b7c6-602c0df4771d.TID372.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 171 (task 373, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 170 (task 372, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 171 (task 373, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 170 (task 372, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.2.delta.228e9ab0-ac90-4e16-ba1c-0fe4200a98e7.TID374.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169/.2.delta.65f8eb98-e829-48d8-9348-2285ce9f4ab1.TID371.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/169]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 3.0 (TID 371). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 173.0 in stage 3.0 (TID 375, localhost, executor driver, partition 173, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 3.0 (TID 371) in 178 ms on localhost (executor driver) (170/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,386][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 173.0 in stage 3.0 (TID 375)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25d84b58
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,173,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@126ddf49
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,173,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171/.2.delta.a4281aec-f524-4be1-bcef-1ac05ab44df8.TID373.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/171]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170/.2.delta.118bfe47-ce47-4368-9ab2-ca67934eed80.TID372.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 3.0 (TID 373). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 174.0 in stage 3.0 (TID 376, localhost, executor driver, partition 174, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 3.0 (TID 373) in 173 ms on localhost (executor driver) (171/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 174.0 in stage 3.0 (TID 376)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/170]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 3.0 (TID 372). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 175.0 in stage 3.0 (TID 377, localhost, executor driver, partition 175, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 3.0 (TID 372) in 184 ms on localhost (executor driver) (172/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 175.0 in stage 3.0 (TID 377)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@159c106a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,174,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32be26f1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,174,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fdb6f7d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,175,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1209452a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,175,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.2.delta.28b5159d-023a-4248-bb0c-1112da9e1cb3.TID375.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.2.delta.228e9ab0-ac90-4e16-ba1c-0fe4200a98e7.TID374.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 172 (task 374, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,476][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 172 (task 374, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.2.delta.32527d44-d32c-4613-8048-82ed2f5a7463.TID376.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.2.delta.a91b3739-c273-4017-9b22-f7b0cd46659c.TID377.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172/.2.delta.035b39c9-8627-4fee-a307-11f182092625.TID374.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/172]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 3.0 (TID 374). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,527][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 176.0 in stage 3.0 (TID 378, localhost, executor driver, partition 176, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,527][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 3.0 (TID 374) in 200 ms on localhost (executor driver) (173/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,527][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 176.0 in stage 3.0 (TID 378)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41b50951
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,176,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d13577
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,176,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.2.delta.28b5159d-023a-4248-bb0c-1112da9e1cb3.TID375.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 173 (task 375, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 173 (task 375, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.2.delta.32527d44-d32c-4613-8048-82ed2f5a7463.TID376.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 174 (task 376, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 174 (task 376, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.2.delta.396a3143-2bc3-434f-a468-e160d01b4914.TID378.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.2.delta.a91b3739-c273-4017-9b22-f7b0cd46659c.TID377.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 175 (task 377, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 175 (task 377, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173/.2.delta.cd20ae5e-671a-45c2-a872-9a78df7a9924.TID375.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/173]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 3.0 (TID 375). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 177.0 in stage 3.0 (TID 379, localhost, executor driver, partition 177, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 3.0 (TID 375) in 217 ms on localhost (executor driver) (174/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 177.0 in stage 3.0 (TID 379)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7001de38
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,177,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@243ef73d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,177,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174/.2.delta.25a42b91-d81c-4291-bc3a-a8d2cf3d69a8.TID376.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/174]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 3.0 (TID 376). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 178.0 in stage 3.0 (TID 380, localhost, executor driver, partition 178, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 3.0 (TID 376) in 191 ms on localhost (executor driver) (175/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 178.0 in stage 3.0 (TID 380)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40511b2e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,178,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41c7d471
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,178,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175/.2.delta.837f19d2-0af3-4e5e-8683-55eb0a913259.TID377.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/175]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 3.0 (TID 377). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 179.0 in stage 3.0 (TID 381, localhost, executor driver, partition 179, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 3.0 (TID 377) in 204 ms on localhost (executor driver) (176/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 179.0 in stage 3.0 (TID 381)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7306ba93
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,179,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f1f4696
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,179,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.2.delta.d2b22469-c9bc-43a3-a411-2e9748b26acf.TID379.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.2.delta.04f5d7ae-7a40-43d7-b6a2-af55b7855c40.TID380.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.2.delta.396a3143-2bc3-434f-a468-e160d01b4914.TID378.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 176 (task 378, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 176 (task 378, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.2.delta.04ecad19-01e3-41cd-9f10-ebee2fda3cf6.TID381.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176/.2.delta.250472d6-f175-42ef-82aa-65a08950812f.TID378.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/176]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 3.0 (TID 378). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 180.0 in stage 3.0 (TID 382, localhost, executor driver, partition 180, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 3.0 (TID 378) in 172 ms on localhost (executor driver) (177/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 180.0 in stage 3.0 (TID 382)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ce8780b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,180,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c5c9e20
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,180,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.2.delta.d2b22469-c9bc-43a3-a411-2e9748b26acf.TID379.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 177 (task 379, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 177 (task 379, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.2.delta.04f5d7ae-7a40-43d7-b6a2-af55b7855c40.TID380.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 178 (task 380, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 178 (task 380, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.2.delta.9133b9c2-409a-48dc-9f0e-4ee9c79a5e92.TID382.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.2.delta.04ecad19-01e3-41cd-9f10-ebee2fda3cf6.TID381.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,741][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 179 (task 381, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 179 (task 381, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177/.2.delta.409925c1-0578-488c-b1e1-15efefb25154.TID379.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/177]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 3.0 (TID 379). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 181.0 in stage 3.0 (TID 383, localhost, executor driver, partition 181, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 3.0 (TID 379) in 154 ms on localhost (executor driver) (178/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 181.0 in stage 3.0 (TID 383)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e5d06d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,181,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,762][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,762][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e7da0fa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,181,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178/.2.delta.67e89d6f-55f6-4910-944f-761d02fd290c.TID380.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/178]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 3.0 (TID 380). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 182.0 in stage 3.0 (TID 384, localhost, executor driver, partition 182, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 3.0 (TID 380) in 158 ms on localhost (executor driver) (179/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 182.0 in stage 3.0 (TID 384)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cb3ddba
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,182,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ce5ba7c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,182,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179/.2.delta.e1345938-3251-4ca9-986a-16082aad6cc9.TID381.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.2.delta.66dd2826-2aaa-4ac4-8136-bfec5b89fae2.TID383.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/179]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 3.0 (TID 381). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 183.0 in stage 3.0 (TID 385, localhost, executor driver, partition 183, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 3.0 (TID 381) in 192 ms on localhost (executor driver) (180/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 183.0 in stage 3.0 (TID 385)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@527c8d59
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,183,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34bcee1d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,183,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.2.delta.8716191c-2d66-43d0-8d53-f149ade8bb21.TID384.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.2.delta.9133b9c2-409a-48dc-9f0e-4ee9c79a5e92.TID382.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 180 (task 382, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 180 (task 382, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.2.delta.1404a84b-4024-40c7-bcbb-b2f8f423c579.TID385.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180/.2.delta.a58eae5f-8039-4e07-a504-9c3d2a4e9254.TID382.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/180]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 3.0 (TID 382). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 184.0 in stage 3.0 (TID 386, localhost, executor driver, partition 184, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 3.0 (TID 382) in 197 ms on localhost (executor driver) (181/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 184.0 in stage 3.0 (TID 386)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f945a51
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,184,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f0c32f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,184,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.2.delta.66dd2826-2aaa-4ac4-8136-bfec5b89fae2.TID383.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 181 (task 383, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 181 (task 383, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.2.delta.8716191c-2d66-43d0-8d53-f149ade8bb21.TID384.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 182 (task 384, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 182 (task 384, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.2.delta.a348bd86-1724-4c77-9829-be9c51a897b4.TID386.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.2.delta.1404a84b-4024-40c7-bcbb-b2f8f423c579.TID385.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 183 (task 385, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 183 (task 385, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181/.2.delta.1251470d-9d64-468c-9de3-5a54b0539edc.TID383.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/181]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 3.0 (TID 383). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 185.0 in stage 3.0 (TID 387, localhost, executor driver, partition 185, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 185.0 in stage 3.0 (TID 387)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 3.0 (TID 383) in 222 ms on localhost (executor driver) (182/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a17131b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,185,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39294647
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,185,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182/.2.delta.1dce7e58-5dee-461f-9fb5-233f6f909790.TID384.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/182]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 3.0 (TID 384). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 186.0 in stage 3.0 (TID 388, localhost, executor driver, partition 186, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 3.0 (TID 384) in 217 ms on localhost (executor driver) (183/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 186.0 in stage 3.0 (TID 388)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52a17461
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,186,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11795f24
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,186,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:30,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183/.2.delta.6072eefe-49d6-4693-8cce-d11204ded19b.TID385.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/183]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 3.0 (TID 385). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 187.0 in stage 3.0 (TID 389, localhost, executor driver, partition 187, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 3.0 (TID 385) in 195 ms on localhost (executor driver) (184/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 187.0 in stage 3.0 (TID 389)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78dae78d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,187,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b9bd527
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,187,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.2.delta.f65c89bf-9fb4-4d12-ba08-8568ccea8fb0.TID387.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.2.delta.d98ccde5-aef8-4f22-b6f7-f1205a0c6433.TID388.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.2.delta.a348bd86-1724-4c77-9829-be9c51a897b4.TID386.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 184 (task 386, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 184 (task 386, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.2.delta.13aac37f-8fed-4f73-9944-129751f0dfbd.TID389.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184/.2.delta.850a8f6f-0669-433e-b9c6-bd053369efdf.TID386.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/184]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 3.0 (TID 386). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 188.0 in stage 3.0 (TID 390, localhost, executor driver, partition 188, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 188.0 in stage 3.0 (TID 390)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 3.0 (TID 386) in 206 ms on localhost (executor driver) (185/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e6fbf7e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,188,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b76c326
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,188,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.2.delta.f65c89bf-9fb4-4d12-ba08-8568ccea8fb0.TID387.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 185 (task 387, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 185 (task 387, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.2.delta.d98ccde5-aef8-4f22-b6f7-f1205a0c6433.TID388.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 186 (task 388, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 186 (task 388, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.2.delta.13aac37f-8fed-4f73-9944-129751f0dfbd.TID389.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 187 (task 389, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.2.delta.888450bb-0b4c-4d9c-a3de-046ea3f9663c.TID390.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 187 (task 389, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185/.2.delta.349b64f3-4b12-44e3-845e-8d1d24dd5802.TID387.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/185]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 3.0 (TID 387). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 189.0 in stage 3.0 (TID 391, localhost, executor driver, partition 189, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 3.0 (TID 387) in 198 ms on localhost (executor driver) (186/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 189.0 in stage 3.0 (TID 391)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2792248c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,189,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29870498
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,189,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186/.2.delta.2b046bc5-586a-4d96-9cfc-377640d84a9e.TID388.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/186]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 3.0 (TID 388). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 190.0 in stage 3.0 (TID 392, localhost, executor driver, partition 190, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 3.0 (TID 388) in 197 ms on localhost (executor driver) (187/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 190.0 in stage 3.0 (TID 392)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aad19fa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,190,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72c66d83
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,190,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187/.2.delta.11e52997-9000-4351-8bd3-b42ec258c3dd.TID389.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/187]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 3.0 (TID 389). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 191.0 in stage 3.0 (TID 393, localhost, executor driver, partition 191, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 3.0 (TID 389) in 188 ms on localhost (executor driver) (188/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 191.0 in stage 3.0 (TID 393)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ce0731
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,191,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bad5a52
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,191,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.2.delta.0e47244c-663b-4e8c-8a4a-28bb8030ebaa.TID391.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.2.delta.888450bb-0b4c-4d9c-a3de-046ea3f9663c.TID390.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 188 (task 390, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 188 (task 390, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.2.delta.6cd86265-3b16-4411-aabe-3fe00527ca09.TID392.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.2.delta.71c0054e-54fe-473c-8bf7-808e2ba0af53.TID393.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188/.2.delta.9fd12342-2b76-4104-9d73-3879823a46b9.TID390.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/188]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 3.0 (TID 390). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 192.0 in stage 3.0 (TID 394, localhost, executor driver, partition 192, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 3.0 (TID 390) in 192 ms on localhost (executor driver) (189/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 192.0 in stage 3.0 (TID 394)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@104d4392
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,192,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b385507
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,192,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.2.delta.0e47244c-663b-4e8c-8a4a-28bb8030ebaa.TID391.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 189 (task 391, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 189 (task 391, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.2.delta.6cd86265-3b16-4411-aabe-3fe00527ca09.TID392.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 190 (task 392, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 190 (task 392, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.2.delta.71c0054e-54fe-473c-8bf7-808e2ba0af53.TID393.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.2.delta.1c217a51-626e-406f-94bd-8f5d821ba006.TID394.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 191 (task 393, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 191 (task 393, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189/.2.delta.92ec7ba1-6d1c-418d-907f-e96c57c6eb3b.TID391.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190/.2.delta.3b7a93a4-ee13-4da5-8284-8dd0a74226f3.TID392.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/189]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/190]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 3.0 (TID 391). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191/.2.delta.e8577500-9241-4c98-b35f-b189c6c9521c.TID393.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 193.0 in stage 3.0 (TID 395, localhost, executor driver, partition 193, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 3.0 (TID 392). 5208 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 3.0 (TID 391) in 237 ms on localhost (executor driver) (190/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 193.0 in stage 3.0 (TID 395)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 194.0 in stage 3.0 (TID 396, localhost, executor driver, partition 194, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 3.0 (TID 392) in 228 ms on localhost (executor driver) (191/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/191]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 194.0 in stage 3.0 (TID 396)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 3.0 (TID 393). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 195.0 in stage 3.0 (TID 397, localhost, executor driver, partition 195, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 3.0 (TID 393) in 212 ms on localhost (executor driver) (192/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 195.0 in stage 3.0 (TID 397)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@95249a1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,193,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@221efe93
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,193,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8303a9d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,195,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@780bb49e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,195,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b76fcd9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,194,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4024f77d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,194,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.2.delta.1c217a51-626e-406f-94bd-8f5d821ba006.TID394.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 192 (task 394, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 192 (task 394, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.2.delta.43a52cc2-de25-4a0d-b8f2-235becc403f1.TID397.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.2.delta.3a9b1f5a-1925-4fcc-b150-92603e0b5ba8.TID395.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.2.delta.80592a05-94e0-4de1-9ba5-fb706cc130a1.TID396.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192/.2.delta.8d73913c-0c40-41bf-ace1-5daef78af250.TID394.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/192]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 3.0 (TID 394). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 196.0 in stage 3.0 (TID 398, localhost, executor driver, partition 196, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 3.0 (TID 394) in 218 ms on localhost (executor driver) (193/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 196.0 in stage 3.0 (TID 398)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32380803
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,196,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a080dd3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,196,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.2.delta.43a52cc2-de25-4a0d-b8f2-235becc403f1.TID397.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.2.delta.3a9b1f5a-1925-4fcc-b150-92603e0b5ba8.TID395.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 195 (task 397, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 193 (task 395, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 195 (task 397, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,536][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 193 (task 395, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.2.delta.80592a05-94e0-4de1-9ba5-fb706cc130a1.TID396.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 194 (task 396, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 194 (task 396, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.2.delta.75faf85f-7f33-47b3-aa63-eb6ddd8a1ac5.TID398.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195/.2.delta.40fffd48-77f0-4e9b-85d5-03f29ac2447c.TID397.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/195]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 3.0 (TID 397). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 197.0 in stage 3.0 (TID 399, localhost, executor driver, partition 197, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 197.0 in stage 3.0 (TID 399)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 3.0 (TID 397) in 175 ms on localhost (executor driver) (194/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193/.2.delta.88d6711e-59a7-40e5-9935-b320515e68ed.TID395.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/193]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 3.0 (TID 395). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 198.0 in stage 3.0 (TID 400, localhost, executor driver, partition 198, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 3.0 (TID 395) in 182 ms on localhost (executor driver) (195/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 198.0 in stage 3.0 (TID 400)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32f7503b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,197,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d42b664
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,197,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@331d9d31
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,198,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77010df8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,198,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194/.2.delta.d7c8477a-9ea6-4a6b-8cab-d547a58965ca.TID396.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/194]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 3.0 (TID 396). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 199.0 in stage 3.0 (TID 401, localhost, executor driver, partition 199, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 199.0 in stage 3.0 (TID 401)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 3.0 (TID 396) in 202 ms on localhost (executor driver) (196/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2376f995
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,199,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d359942
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,199,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.2.delta.3d856840-6090-438d-a362-3cc315eb84a5.TID399.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.2.delta.71edb6ec-e040-40c0-8d5b-133a463116bd.TID400.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.2.delta.75faf85f-7f33-47b3-aa63-eb6ddd8a1ac5.TID398.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 196 (task 398, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 196 (task 398, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.2.delta.9fbbe931-0a8d-422f-a541-7b7429c89a2b.TID401.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196/.2.delta.487fed9a-c9b8-4373-8a14-e0183711c9c0.TID398.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/196]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 3.0 (TID 398). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 3.0 (TID 398) in 194 ms on localhost (executor driver) (197/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.2.delta.3d856840-6090-438d-a362-3cc315eb84a5.TID399.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 197 (task 399, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.2.delta.71edb6ec-e040-40c0-8d5b-133a463116bd.TID400.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 197 (task 399, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 198 (task 400, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 198 (task 400, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.2.delta.9fbbe931-0a8d-422f-a541-7b7429c89a2b.TID401.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/2.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 199 (task 401, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 199 (task 401, attempt 0stage 3.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197/.2.delta.f032d5bc-ac1b-4ce1-97df-f467dc39fc6d.TID399.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198/.2.delta.15016105-037a-477e-9e4f-2d283de7467b.TID400.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/197]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/198]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 3.0 (TID 400). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 3.0 (TID 399). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,762][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 3.0 (TID 400) in 170 ms on localhost (executor driver) (198/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 3.0 (TID 399) in 175 ms on localhost (executor driver) (199/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/2.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199/.2.delta.dc6c9c35-050a-4e52-bde5-c1e484466106.TID401.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/199]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 3.0 (TID 401). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 3.0 (TID 401) in 158 ms on localhost (executor driver) (200/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 3.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 3 (start at StreamingFile.scala:61) finished in 12,442 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 2 finished: start at StreamingFile.scala:61, took 12,556149 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@19fe512e is committing.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@19fe512e committed.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 3 finished: start at StreamingFile.scala:61, took 0,000028 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/1 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/.1.7ebd1928-2aa4-46ea-8642-0aa7944f1ab0.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,860][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/.1.7ebd1928-2aa4-46ea-8642-0aa7944f1ab0.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/commits/1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Streaming query made progress: {
  "id" : "eeb06daf-41d7-4c11-830a-51392556e50b",
  "runId" : "dfd1489f-ab85-4006-996b-815ebec09125",
  "name" : null,
  "timestamp" : "2019-05-02T14:06:18.004Z",
  "batchId" : 1,
  "numInputRows" : 100,
  "inputRowsPerSecond" : 49.97501249375313,
  "processedRowsPerSecond" : 7.216569242981887,
  "durationMs" : {
    "addBatch" : 13209,
    "getBatch" : 10,
    "getOffset" : 321,
    "queryPlanning" : 58,
    "triggerExecution" : 13857,
    "walCommit" : 192
  },
  "stateOperators" : [ {
    "numRowsTotal" : 15,
    "numRowsUpdated" : 15,
    "memoryUsedBytes" : 80759,
    "customMetrics" : {
      "loadedMapCacheHitCount" : 400,
      "loadedMapCacheMissCount" : 0,
      "stateOnCurrentVersionSizeBytes" : 20399
    }
  } ],
  "sources" : [ {
    "description" : "FileStreamSource[file:/Users/eiti/git-repository/structured-streaming/dataset/stream_in/*]",
    "startOffset" : {
      "logOffset" : 0
    },
    "endOffset" : {
      "logOffset" : 1
    },
    "numInputRows" : 100,
    "inputRowsPerSecond" : 49.97501249375313,
    "processedRowsPerSecond" : 7.216569242981887
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@58ff9c6e"
  }
}
[31m[WARN ][0;39m [35m[2019-05-02 11:06:31,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logWarning][0;39m | Current batch is falling behind. The trigger interval is 2000 milliseconds, but spent 13858 milliseconds
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/2 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.2.bac0eb01-365d-4db3-b1c7-8c5483c981ed.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/.2.bac0eb01-365d-4db3-b1c7-8c5483c981ed.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/sources/0/2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Log offset set to 2 with 1 new files
[34m[INFO ][0;39m [35m[2019-05-02 11:06:31,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/2 using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.2.f239fe94-ad5d-45c5-919e-e3246a22a251.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/.2.f239fe94-ad5d-45c5-919e-e3246a22a251.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/offsets/2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed offsets for batch 2. Metadata OffsetSeqMetadata(0,1556805991921,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Processing 1 files from 2:2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<carrier: string, marital_status: string>
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_10 stored as values in memory (estimated size 221.7 KB, free 910.5 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.7 KB, free 910.5 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_10_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 10 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_11 stored as values in memory (estimated size 220.7 KB, free 910.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.7 KB, free 910.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_11_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 11 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_12 stored as values in memory (estimated size 220.7 KB, free 910.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KB, free 910.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_12_piece0 in memory on mac-180:55122 (size: 20.7 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 12 from start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@13cfade. The input RDD has 200 partitions.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: start at StreamingFile.scala:61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering RDD 24 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 4 (start at StreamingFile.scala:61) with 200 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 5 (start at StreamingFile.scala:61)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List(ShuffleMapStage 4)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List(ShuffleMapStage 4)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ShuffleMapStage 4 (MapPartitionsRDD[24] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_13 stored as values in memory (estimated size 28.1 KB, free 910.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.6 KB, free 910.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_13_piece0 in memory on mac-180:55122 (size: 13.6 KB, free: 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 13 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[24] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 4.0 with 1 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 4.0 (TID 402, localhost, executor driver, partition 0, PROCESS_LOCAL, 8357 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 4.0 (TID 402)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/stream_in/user-record.3.csv, range: 0-6907, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 4.0 (TID 402). 2352 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 4.0 (TID 402) in 140 ms on localhost (executor driver) (1/1)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 4.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ShuffleMapStage 4 (start at StreamingFile.scala:61) finished in 0,146 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | looking for newly runnable stages
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | running: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | waiting: Set(ResultStage 5)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | failed: Set()
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 5 (MapPartitionsRDD[30] at start at StreamingFile.scala:61), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_14 stored as values in memory (estimated size 55.6 KB, free 909.9 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.5 KB, free 909.9 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_14_piece0 in memory on mac-180:55122 (size: 23.5 KB, free: 912.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 14 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 200 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at start at StreamingFile.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 5.0 with 200 tasks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 5.0 (TID 403, localhost, executor driver, partition 0, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 5.0 (TID 404, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 5.0 (TID 405, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 5.0 (TID 406, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 5.0 (TID 406)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 5.0 (TID 404)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 5.0 (TID 405)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 5.0 (TID 403)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43b33950
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2130ca39
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,1,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd654a5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60eb23d8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f52504e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c7697c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,2,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@784475be
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,0,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50f3b33e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,3,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.3.delta.312a65de-6ee9-4449-b17b-39cfe3c04c48.TID405.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.3.delta.b39e626c-2d4f-4bc6-b744-3172b6fc8472.TID404.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.3.delta.578f0093-36ec-4825-aef8-4f3e9cfa7c0f.TID406.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.3.delta.bb4f3017-f040-4457-9477-2f97de05150e.TID403.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.3.delta.312a65de-6ee9-4449-b17b-39cfe3c04c48.TID405.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.3.delta.b39e626c-2d4f-4bc6-b744-3172b6fc8472.TID404.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.3.delta.578f0093-36ec-4825-aef8-4f3e9cfa7c0f.TID406.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 1 (task 404, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 2 (task 405, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 1 (task 404, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 3 (task 406, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 2 (task 405, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,852][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 3 (task 406, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.3.delta.bb4f3017-f040-4457-9477-2f97de05150e.TID403.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 0 (task 403, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 0 (task 403, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1/.3.delta.e7c5b58a-1fd6-4eb6-badb-b0d2f4c67754.TID404.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=1),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/1]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 5.0 (TID 404). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 4.0 in stage 5.0 (TID 407, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 5.0 (TID 404) in 284 ms on localhost (executor driver) (1/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 4.0 in stage 5.0 (TID 407)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2/.3.delta.8d923be1-a833-42c3-9efd-6bff15f007ac.TID405.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@670f5bc9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a10ea77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,4,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3/.3.delta.d05e87b0-dc12-4bc9-ba30-e87455811087.TID406.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=2),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/2]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 5.0 (TID 405). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=3),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/3]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 5.0 in stage 5.0 (TID 408, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 5.0 in stage 5.0 (TID 408)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 5.0 (TID 405) in 301 ms on localhost (executor driver) (2/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 5.0 (TID 406). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 6.0 in stage 5.0 (TID 409, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 5.0 (TID 406) in 302 ms on localhost (executor driver) (3/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 6.0 in stage 5.0 (TID 409)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60ceefbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ca48d4b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,5,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@112e0d7a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12c07f5a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,6,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0/.3.delta.cd80d389-4f28-4e75-a87c-24fc6587e803.TID403.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=0),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/0]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 5.0 (TID 403). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 7.0 in stage 5.0 (TID 410, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 5.0 (TID 403) in 346 ms on localhost (executor driver) (4/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:32,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 7.0 in stage 5.0 (TID 410)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63ce49fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@739a35f4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,7,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.3.delta.40d3b862-38bb-4156-afc9-dd24adb5389d.TID407.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.3.delta.1dcbc12e-380e-47f2-9981-676786143605.TID409.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.3.delta.346431fe-3afd-4de3-98c8-59d89fdcff12.TID408.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.3.delta.6959bd2e-df1b-4fb5-a8b0-bc8e607aa364.TID410.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.3.delta.1dcbc12e-380e-47f2-9981-676786143605.TID409.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.3.delta.346431fe-3afd-4de3-98c8-59d89fdcff12.TID408.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 5 (task 408, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 6 (task 409, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.3.delta.40d3b862-38bb-4156-afc9-dd24adb5389d.TID407.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 5 (task 408, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 6 (task 409, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 4 (task 407, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 4 (task 407, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.3.delta.6959bd2e-df1b-4fb5-a8b0-bc8e607aa364.TID410.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 7 (task 410, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 7 (task 410, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5/.3.delta.0eac1226-7a01-44a4-b958-720f46c593e8.TID408.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=5),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/5]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 5.0 (TID 408). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 8.0 in stage 5.0 (TID 411, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6/.3.delta.fd3f5255-a8e4-4aa2-a884-f5dca37645bb.TID409.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 5.0 (TID 408) in 319 ms on localhost (executor driver) (5/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 8.0 in stage 5.0 (TID 411)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4/.3.delta.0bbd4c02-4abf-44df-9471-e618a87d62bb.TID407.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=6),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/6]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,272][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 5.0 (TID 409). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 9.0 in stage 5.0 (TID 412, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 5.0 (TID 409) in 320 ms on localhost (executor driver) (6/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f1b1f18
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 9.0 in stage 5.0 (TID 412)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=4),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/4]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,274][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 5.0 (TID 407). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69430c63
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 10.0 in stage 5.0 (TID 413, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,8,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 5.0 (TID 407) in 341 ms on localhost (executor driver) (7/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 10.0 in stage 5.0 (TID 413)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25128ed4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@700fadcd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,9,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ef9b183
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4abc02b6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,283][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,10,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7/.3.delta.5adcdc9e-49c7-442a-8745-b7bfed72fbda.TID410.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=7),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/7]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 5.0 (TID 410). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 11.0 in stage 5.0 (TID 414, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 5.0 (TID 410) in 302 ms on localhost (executor driver) (8/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 11.0 in stage 5.0 (TID 414)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46cfc44f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21c29d45
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,11,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.3.delta.219af77a-a60c-4864-a182-63ff1a12579f.TID411.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.3.delta.3aa0a391-1de6-42b1-a9e5-41f7d9904b5e.TID412.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,338][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.3.delta.727025f3-c254-44cd-8461-48a14111813c.TID413.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.3.delta.59d8d18b-4e96-4e5c-90c7-c73982545f1e.TID414.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,402][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.3.delta.219af77a-a60c-4864-a182-63ff1a12579f.TID411.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,404][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.3.delta.727025f3-c254-44cd-8461-48a14111813c.TID413.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 8 (task 411, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 8 (task 411, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 10 (task 413, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 10 (task 413, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.3.delta.3aa0a391-1de6-42b1-a9e5-41f7d9904b5e.TID412.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.3.delta.59d8d18b-4e96-4e5c-90c7-c73982545f1e.TID414.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 9 (task 412, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 9 (task 412, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 11 (task 414, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 11 (task 414, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8/.3.delta.ba7b1751-210b-48fd-85ed-17cf947a8687.TID411.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=8),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/8]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 5.0 (TID 411). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 12.0 in stage 5.0 (TID 415, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 5.0 (TID 411) in 177 ms on localhost (executor driver) (9/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 12.0 in stage 5.0 (TID 415)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bc52b50
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ef44eaf
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,12,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10/.3.delta.3c15d636-702d-484a-9321-8db3087cc7f6.TID413.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=10),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/10]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 5.0 (TID 413). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 13.0 in stage 5.0 (TID 416, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 5.0 (TID 413) in 179 ms on localhost (executor driver) (10/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 13.0 in stage 5.0 (TID 416)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6340798a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@633d8160
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,13,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9/.3.delta.3550773a-3d3d-47a5-a2cb-6398c94206da.TID412.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11/.3.delta.9866af3f-1c11-4c1a-abbc-d37257b5104f.TID414.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=9),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/9]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=11),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/11]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 5.0 (TID 412). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 14.0 in stage 5.0 (TID 417, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 5.0 (TID 412) in 190 ms on localhost (executor driver) (11/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 14.0 in stage 5.0 (TID 417)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 5.0 (TID 414). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 15.0 in stage 5.0 (TID 418, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 5.0 (TID 414) in 169 ms on localhost (executor driver) (12/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 15.0 in stage 5.0 (TID 418)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f1bc253
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10a9de04
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,14,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e669f97
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bccfcfa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,15,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.3.delta.f5cdd0aa-4fc7-4dd9-b601-58a747a469c4.TID415.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.3.delta.b47789cb-ae67-4a9d-8b6c-03edef7404ca.TID416.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.3.delta.2c85f38e-a571-4a49-8b9d-5a33c44c917a.TID418.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.3.delta.bc8875fd-c47f-400b-a2f0-011d8f118499.TID417.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.3.delta.f5cdd0aa-4fc7-4dd9-b601-58a747a469c4.TID415.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 12 (task 415, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 12 (task 415, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.3.delta.b47789cb-ae67-4a9d-8b6c-03edef7404ca.TID416.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 13 (task 416, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.3.delta.2c85f38e-a571-4a49-8b9d-5a33c44c917a.TID418.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 13 (task 416, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 15 (task 418, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 15 (task 418, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.3.delta.bc8875fd-c47f-400b-a2f0-011d8f118499.TID417.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 14 (task 417, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 14 (task 417, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12/.3.delta.ec5ffab2-9055-4ac5-b234-bf75a2283243.TID415.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=12),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/12]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 5.0 (TID 415). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 16.0 in stage 5.0 (TID 419, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 5.0 (TID 415) in 235 ms on localhost (executor driver) (13/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 16.0 in stage 5.0 (TID 419)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a8f2e4f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12f0b67c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,16,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15/.3.delta.0e719a88-5b95-42b6-8843-7130994fe2cb.TID418.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13/.3.delta.4f08c701-e335-4519-b0f9-c0a3986ac08a.TID416.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=15),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/15]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=13),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/13]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 5.0 (TID 416). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 5.0 (TID 418). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 17.0 in stage 5.0 (TID 420, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 18.0 in stage 5.0 (TID 421, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 17.0 in stage 5.0 (TID 420)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 5.0 (TID 416) in 234 ms on localhost (executor driver) (14/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 18.0 in stage 5.0 (TID 421)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 5.0 (TID 418) in 225 ms on localhost (executor driver) (15/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370e8caa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b28649d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,18,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d71eeca
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7508c96
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,17,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,698][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14/.3.delta.bcfffd62-1cd8-4680-8cf8-313023583d66.TID417.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=14),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/14]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 5.0 (TID 417). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,705][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 19.0 in stage 5.0 (TID 422, localhost, executor driver, partition 19, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 5.0 (TID 417) in 243 ms on localhost (executor driver) (16/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 19.0 in stage 5.0 (TID 422)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc33978
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fb51df8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,19,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.3.delta.48343d36-05f2-4504-bf3d-bc2feda6d859.TID419.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.3.delta.06c8e128-8ded-426c-8e72-2df7231f614a.TID421.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.3.delta.ef9645a5-5b27-42f1-a5fd-ab213ceb20c2.TID420.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.3.delta.ba06d19d-b7f5-4a79-bee9-0ac1d995cae5.TID422.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.3.delta.48343d36-05f2-4504-bf3d-bc2feda6d859.TID419.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 16 (task 419, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 16 (task 419, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.3.delta.ef9645a5-5b27-42f1-a5fd-ab213ceb20c2.TID420.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 17 (task 420, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 17 (task 420, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.3.delta.06c8e128-8ded-426c-8e72-2df7231f614a.TID421.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 18 (task 421, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:33,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 18 (task 421, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.3.delta.ba06d19d-b7f5-4a79-bee9-0ac1d995cae5.TID422.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 19 (task 422, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 19 (task 422, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16/.3.delta.4dd50166-f0e3-4658-816e-5ea53ecde768.TID419.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=16),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/16]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 5.0 (TID 419). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 20.0 in stage 5.0 (TID 423, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 5.0 (TID 419) in 387 ms on localhost (executor driver) (17/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 20.0 in stage 5.0 (TID 423)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17/.3.delta.ccd88e2e-00f7-4372-90bf-670d1c7f7ec7.TID420.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35d8ecfc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=17),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/17]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@490ed7ed
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,20,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 5.0 (TID 420). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 21.0 in stage 5.0 (TID 424, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 5.0 (TID 420) in 386 ms on localhost (executor driver) (18/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 21.0 in stage 5.0 (TID 424)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aafeefc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@427acfa8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,21,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18/.3.delta.5d6748c9-5418-4578-91d7-766932f07a83.TID421.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=18),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/18]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 5.0 (TID 421). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 22.0 in stage 5.0 (TID 425, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 5.0 (TID 421) in 396 ms on localhost (executor driver) (19/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 22.0 in stage 5.0 (TID 425)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ffeaafd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748ff8e5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,22,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19/.3.delta.dbfde88f-9b81-4bb5-a874-fcd00cbc9737.TID422.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=19),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/19]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 5.0 (TID 422). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 23.0 in stage 5.0 (TID 426, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 5.0 (TID 422) in 403 ms on localhost (executor driver) (20/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 23.0 in stage 5.0 (TID 426)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@672dc074
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5032b08a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,23,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.3.delta.ab7dddff-2247-49b0-95f0-ddde53d09937.TID423.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.3.delta.3fa10767-7145-49d2-a995-c4275244145d.TID424.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.3.delta.c042bfc8-58e0-487c-a4f3-aa783c8b07ef.TID425.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.3.delta.dfaa0b35-5114-4100-8576-04305406e26f.TID426.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.3.delta.ab7dddff-2247-49b0-95f0-ddde53d09937.TID423.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 20 (task 423, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 20 (task 423, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.3.delta.3fa10767-7145-49d2-a995-c4275244145d.TID424.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.3.delta.c042bfc8-58e0-487c-a4f3-aa783c8b07ef.TID425.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 21 (task 424, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 21 (task 424, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 22 (task 425, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 22 (task 425, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.3.delta.dfaa0b35-5114-4100-8576-04305406e26f.TID426.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 23 (task 426, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 23 (task 426, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20/.3.delta.1d282da6-e8ab-4e7a-a1b8-e7576e5a43b1.TID423.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=20),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/20]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 5.0 (TID 423). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 24.0 in stage 5.0 (TID 427, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 5.0 (TID 423) in 347 ms on localhost (executor driver) (21/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 24.0 in stage 5.0 (TID 427)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21/.3.delta.2eab68c5-de27-4758-ac85-2aeca219b06f.TID424.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ebec072
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22/.3.delta.33b58665-38a7-46ee-9c3c-8295ab967210.TID425.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=21),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/21]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 5.0 (TID 424). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aa8f050
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=22),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/22]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 25.0 in stage 5.0 (TID 428, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,24,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 5.0 (TID 424) in 348 ms on localhost (executor driver) (22/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 25.0 in stage 5.0 (TID 428)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 5.0 (TID 425). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 26.0 in stage 5.0 (TID 429, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 5.0 (TID 425) in 338 ms on localhost (executor driver) (23/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 26.0 in stage 5.0 (TID 429)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12ab3e50
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49fda003
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,25,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@144cc5df
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41024691
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,26,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23/.3.delta.f5f5f5e2-b9fa-483a-a8e3-15c51531308f.TID426.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=23),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/23]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 5.0 (TID 426). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 27.0 in stage 5.0 (TID 430, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 5.0 (TID 426) in 329 ms on localhost (executor driver) (24/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 27.0 in stage 5.0 (TID 430)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,440][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54437643
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@324357f5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,27,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.3.delta.198c0c4a-681b-4333-addd-39de438985a5.TID427.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.3.delta.eca9c595-513a-4522-89aa-d794bc18925f.TID429.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.3.delta.6d75cf44-6b82-4ce4-890f-a520507f0403.TID428.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.3.delta.81738b07-c2a3-4581-88eb-460e87bd1036.TID430.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.3.delta.198c0c4a-681b-4333-addd-39de438985a5.TID427.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 24 (task 427, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 24 (task 427, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.3.delta.6d75cf44-6b82-4ce4-890f-a520507f0403.TID428.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.3.delta.81738b07-c2a3-4581-88eb-460e87bd1036.TID430.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.3.delta.eca9c595-513a-4522-89aa-d794bc18925f.TID429.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 25 (task 428, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 27 (task 430, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 25 (task 428, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 26 (task 429, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 27 (task 430, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 26 (task 429, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24/.3.delta.a0848701-342e-41fc-a152-d391d1657f73.TID427.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=24),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/24]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 5.0 (TID 427). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 28.0 in stage 5.0 (TID 431, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 5.0 (TID 427) in 242 ms on localhost (executor driver) (25/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 28.0 in stage 5.0 (TID 431)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18dab970
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f72ce0f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,28,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27/.3.delta.8e843437-cd4c-4865-a3fe-763a1a7c15f9.TID430.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25/.3.delta.a2be7f60-f806-4802-89aa-8ae6fd20d75e.TID428.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=27),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/27]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=25),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/25]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 5.0 (TID 430). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 5.0 (TID 428). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 29.0 in stage 5.0 (TID 432, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 29.0 in stage 5.0 (TID 432)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 30.0 in stage 5.0 (TID 433, localhost, executor driver, partition 30, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 5.0 (TID 430) in 234 ms on localhost (executor driver) (26/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 30.0 in stage 5.0 (TID 433)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 5.0 (TID 428) in 251 ms on localhost (executor driver) (27/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26/.3.delta.0469466b-134e-460a-b147-b1fc2c985736.TID429.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=26),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/26]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22c8c2ad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 5.0 (TID 429). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 31.0 in stage 5.0 (TID 434, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 5.0 (TID 429) in 253 ms on localhost (executor driver) (28/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 31.0 in stage 5.0 (TID 434)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@305c38ca
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2574ffd1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,29,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8fd86fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,30,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fdd93f8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78d6d87c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,31,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.3.delta.3681df86-e4a3-484c-9b1b-1fc1d8f3859d.TID431.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.3.delta.59487356-c846-4d73-89c1-843cd3fca536.TID432.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.3.delta.77069ac9-f27e-40e2-925d-d9769fe38127.TID434.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,739][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.3.delta.78fa8d41-21c3-4ed5-a014-d8a52309c29f.TID433.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.3.delta.59487356-c846-4d73-89c1-843cd3fca536.TID432.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.3.delta.77069ac9-f27e-40e2-925d-d9769fe38127.TID434.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 31 (task 434, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 29 (task 432, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 31 (task 434, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 29 (task 432, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.3.delta.3681df86-e4a3-484c-9b1b-1fc1d8f3859d.TID431.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 28 (task 431, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 28 (task 431, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.3.delta.78fa8d41-21c3-4ed5-a014-d8a52309c29f.TID433.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 30 (task 433, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:34,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 30 (task 433, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28/.3.delta.67eedcac-28c2-41a4-8b1d-6ec7ad25c876.TID431.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=28),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/28]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 5.0 (TID 431). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 32.0 in stage 5.0 (TID 435, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 5.0 (TID 431) in 405 ms on localhost (executor driver) (29/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 32.0 in stage 5.0 (TID 435)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63e2b3ef
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d06fa16
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,32,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31/.3.delta.83731e3e-f35b-4abf-83a7-6be7399d1d43.TID434.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=31),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/31]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29/.3.delta.3ee012ba-12b5-4bb5-977d-17fd99c83137.TID432.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 5.0 (TID 434). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 33.0 in stage 5.0 (TID 436, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 5.0 (TID 434) in 397 ms on localhost (executor driver) (30/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 33.0 in stage 5.0 (TID 436)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=29),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/29]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 5.0 (TID 432). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 34.0 in stage 5.0 (TID 437, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 5.0 (TID 432) in 404 ms on localhost (executor driver) (31/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 34.0 in stage 5.0 (TID 437)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15d2de2a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30/.3.delta.8ca8fc85-13c8-4b77-9189-0b34f9ab77fb.TID433.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@203ca9a2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,33,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e61f110
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=30),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/30]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bed49ee
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,34,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 5.0 (TID 433). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 35.0 in stage 5.0 (TID 438, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 5.0 (TID 433) in 413 ms on localhost (executor driver) (32/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 35.0 in stage 5.0 (TID 438)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@131bc325
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad8e37a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,35,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.3.delta.f9b7a835-7e7f-41c7-9698-d66b2085e638.TID435.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.3.delta.660c8831-ac9c-4068-91f0-cb63daaac678.TID436.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.3.delta.ae920657-46ec-4cce-9bca-b1d82ed051c1.TID437.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.3.delta.99892a35-1960-47e7-af45-2232307e409a.TID438.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.3.delta.660c8831-ac9c-4068-91f0-cb63daaac678.TID436.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.3.delta.f9b7a835-7e7f-41c7-9698-d66b2085e638.TID435.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 33 (task 436, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.3.delta.ae920657-46ec-4cce-9bca-b1d82ed051c1.TID437.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 32 (task 435, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 33 (task 436, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 32 (task 435, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 34 (task 437, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 34 (task 437, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.3.delta.99892a35-1960-47e7-af45-2232307e409a.TID438.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,263][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 35 (task 438, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 35 (task 438, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33/.3.delta.ad666e5f-fe37-4781-b892-b940dd1dd63a.TID436.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=33),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/33]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 5.0 (TID 436). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 36.0 in stage 5.0 (TID 439, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 5.0 (TID 436) in 218 ms on localhost (executor driver) (33/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 36.0 in stage 5.0 (TID 439)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34/.3.delta.22aa7e8d-1f56-4d60-bd84-2af1108557e2.TID437.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=34),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/34]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 5.0 (TID 437). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c22290e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 37.0 in stage 5.0 (TID 440, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 5.0 (TID 437) in 220 ms on localhost (executor driver) (34/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,293][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 37.0 in stage 5.0 (TID 440)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32/.3.delta.579441fe-c063-4f83-8f3a-4191fedb462a.TID435.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25f0e4c5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,36,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=32),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/32]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 5.0 (TID 435). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 38.0 in stage 5.0 (TID 441, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 5.0 (TID 435) in 240 ms on localhost (executor driver) (35/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 38.0 in stage 5.0 (TID 441)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@513b0486
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,299][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bde40ab
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,37,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e47e31c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@658ce14a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,38,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35/.3.delta.7fbd3035-e748-472e-b100-1790a5332a8e.TID438.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=35),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/35]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 5.0 (TID 438). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 39.0 in stage 5.0 (TID 442, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 5.0 (TID 438) in 233 ms on localhost (executor driver) (36/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 39.0 in stage 5.0 (TID 442)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58245031
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a5bbc51
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,39,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,322][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.3.delta.383d38be-8ce1-4808-ac6a-3ec4695960cd.TID439.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.3.delta.41602f52-a403-47ee-89f1-40fd993f80c2.TID440.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.3.delta.254a0e10-7de6-4e08-abf8-08dd0548a3a6.TID442.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,478][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.3.delta.3888b4d8-5650-4b87-83c8-d01317f8a271.TID441.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.3.delta.41602f52-a403-47ee-89f1-40fd993f80c2.TID440.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,633][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 37 (task 440, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 37 (task 440, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.3.delta.254a0e10-7de6-4e08-abf8-08dd0548a3a6.TID442.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.3.delta.3888b4d8-5650-4b87-83c8-d01317f8a271.TID441.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 38 (task 441, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 39 (task 442, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 38 (task 441, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 39 (task 442, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.3.delta.383d38be-8ce1-4808-ac6a-3ec4695960cd.TID439.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 36 (task 439, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 36 (task 439, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37/.3.delta.65d592ea-9a7f-4640-bef4-cded302d631a.TID440.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=37),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/37]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39/.3.delta.5bd4f808-058b-430f-b05c-b43e6012e8d1.TID442.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38/.3.delta.ede12421-e059-4846-93d4-6302f446282a.TID441.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 5.0 (TID 440). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 40.0 in stage 5.0 (TID 443, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=39),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/39]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 5.0 (TID 440) in 381 ms on localhost (executor driver) (37/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 40.0 in stage 5.0 (TID 443)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 5.0 (TID 442). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=38),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/38]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 41.0 in stage 5.0 (TID 444, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 5.0 (TID 442) in 361 ms on localhost (executor driver) (38/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 41.0 in stage 5.0 (TID 444)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 5.0 (TID 441). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 42.0 in stage 5.0 (TID 445, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 5.0 (TID 441) in 380 ms on localhost (executor driver) (39/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 42.0 in stage 5.0 (TID 445)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77f98d65
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a468053
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab0f47e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,40,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36/.3.delta.5446314a-8a6c-4c6c-9d9e-5ad68aa49297.TID439.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6519a25f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,41,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d99a4d9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=36),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/36]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 5.0 (TID 439). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 43.0 in stage 5.0 (TID 446, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 5.0 (TID 439) in 398 ms on localhost (executor driver) (40/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bb999b4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 43.0 in stage 5.0 (TID 446)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,42,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 9 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb6024a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17986e8c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,43,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 223
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 222
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 220
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed broadcast_13_piece0 on mac-180:55122 in memory (size: 13.6 KB, free: 912.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 221
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 219
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.3.delta.4a5d1030-9a04-4e26-8ec0-75cf68861376.TID445.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.3.delta.7abd5b96-798e-4c74-9e84-7e096d7bc469.TID443.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.3.delta.e1322423-704d-4b66-a656-9d18803446ad.TID444.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.3.delta.135cb80a-6539-416b-acac-22e29ebb125e.TID446.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.3.delta.e1322423-704d-4b66-a656-9d18803446ad.TID444.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.3.delta.4a5d1030-9a04-4e26-8ec0-75cf68861376.TID445.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 41 (task 444, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 42 (task 445, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 41 (task 444, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 42 (task 445, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.3.delta.7abd5b96-798e-4c74-9e84-7e096d7bc469.TID443.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 40 (task 443, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 40 (task 443, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.3.delta.135cb80a-6539-416b-acac-22e29ebb125e.TID446.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 43 (task 446, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 43 (task 446, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41/.3.delta.09e9625d-58ff-498b-8f95-cbefbdbfab61.TID444.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42/.3.delta.353566e2-35ec-48ae-b561-df4e82b38ea0.TID445.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=41),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/41]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 5.0 (TID 444). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40/.3.delta.a75e46a2-6e28-42be-8fc4-020dd48ea33b.TID443.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=42),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/42]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 44.0 in stage 5.0 (TID 447, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 5.0 (TID 444) in 323 ms on localhost (executor driver) (41/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 44.0 in stage 5.0 (TID 447)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:35,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 5.0 (TID 445). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 45.0 in stage 5.0 (TID 448, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=40),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/40]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 5.0 (TID 445) in 323 ms on localhost (executor driver) (42/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 5.0 (TID 443). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 46.0 in stage 5.0 (TID 449, localhost, executor driver, partition 46, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 45.0 in stage 5.0 (TID 448)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 5.0 (TID 443) in 328 ms on localhost (executor driver) (43/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 46.0 in stage 5.0 (TID 449)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bb288cd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@da52a5a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,44,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c3df34c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d0a2469
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,46,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a7127ab
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1706afc3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,45,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43/.3.delta.a5af8f25-daa2-44e8-a53f-d596976a56f0.TID446.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=43),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/43]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 5.0 (TID 446). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 47.0 in stage 5.0 (TID 450, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 5.0 (TID 446) in 342 ms on localhost (executor driver) (44/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 47.0 in stage 5.0 (TID 450)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bbf5787
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34915212
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,47,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.3.delta.de78c7ed-70e6-4647-b660-0ffff5f7e951.TID447.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.3.delta.d1ac2a87-1a0d-4357-9b30-9cca76abdf25.TID448.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.3.delta.595dedf5-4c01-455e-86a6-7294f6231dc8.TID449.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.3.delta.12e3e034-7da4-4d15-8e60-0ff54fe128ff.TID450.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.3.delta.de78c7ed-70e6-4647-b660-0ffff5f7e951.TID447.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 44 (task 447, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 44 (task 447, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.3.delta.d1ac2a87-1a0d-4357-9b30-9cca76abdf25.TID448.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.3.delta.12e3e034-7da4-4d15-8e60-0ff54fe128ff.TID450.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.3.delta.595dedf5-4c01-455e-86a6-7294f6231dc8.TID449.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 45 (task 448, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 45 (task 448, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 47 (task 450, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 47 (task 450, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 46 (task 449, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 46 (task 449, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44/.3.delta.431cddf2-da33-4981-99c6-b7b6ff455882.TID447.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=44),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/44]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 5.0 (TID 447). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 48.0 in stage 5.0 (TID 451, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 5.0 (TID 447) in 186 ms on localhost (executor driver) (45/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 48.0 in stage 5.0 (TID 451)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47/.3.delta.7e9a64b3-c2a1-4f22-83ca-9646a67fb600.TID450.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45/.3.delta.945b81f3-7e5a-4cdf-a943-25f92fb6890e.TID448.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c56a3d9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=45),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/45]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=47),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/47]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46/.3.delta.099582ee-0960-47df-8654-7479cc9eb9b9.TID449.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 5.0 (TID 448). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 5.0 (TID 450). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 49.0 in stage 5.0 (TID 452, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7341039f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=46),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/46]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 50.0 in stage 5.0 (TID 453, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 49.0 in stage 5.0 (TID 452)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,48,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 5.0 (TID 448) in 191 ms on localhost (executor driver) (46/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 50.0 in stage 5.0 (TID 453)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 5.0 (TID 449). 5208 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 5.0 (TID 450) in 164 ms on localhost (executor driver) (47/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 51.0 in stage 5.0 (TID 454, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 5.0 (TID 449) in 191 ms on localhost (executor driver) (48/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 51.0 in stage 5.0 (TID 454)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@245f982c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668007d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,49,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@851da7d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bc9ca38
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d5e86c4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,50,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd4d536
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,51,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.3.delta.3b188784-d5d9-4f92-a869-03d55e3d7212.TID451.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.3.delta.97431b57-9db7-4f4b-9ada-96bf3bdc2eb3.TID452.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.3.delta.349a462a-13d5-4541-98e7-a4536c1057d0.TID453.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.3.delta.8ae3bd76-259c-4526-af66-f1acdf3a0cb5.TID454.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,309][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.3.delta.97431b57-9db7-4f4b-9ada-96bf3bdc2eb3.TID452.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.3.delta.3b188784-d5d9-4f92-a869-03d55e3d7212.TID451.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 49 (task 452, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 48 (task 451, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.3.delta.8ae3bd76-259c-4526-af66-f1acdf3a0cb5.TID454.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 49 (task 452, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 48 (task 451, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 51 (task 454, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 51 (task 454, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.3.delta.349a462a-13d5-4541-98e7-a4536c1057d0.TID453.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 50 (task 453, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 50 (task 453, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48/.3.delta.86d904cd-da91-46f2-8888-e45a526c2c1f.TID451.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=48),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/48]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 5.0 (TID 451). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 52.0 in stage 5.0 (TID 455, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 5.0 (TID 451) in 165 ms on localhost (executor driver) (49/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 52.0 in stage 5.0 (TID 455)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49/.3.delta.caa0023f-c035-4f47-b8d2-63995b1757af.TID452.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=49),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/49]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3320c2b4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 5.0 (TID 452). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 53.0 in stage 5.0 (TID 456, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 5.0 (TID 452) in 164 ms on localhost (executor driver) (50/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54197ba9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 53.0 in stage 5.0 (TID 456)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,52,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f4b57c1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b529655
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,53,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51/.3.delta.70e82959-5d35-4c39-ace4-ba52030dcda1.TID454.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=51),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/51]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50/.3.delta.d759b002-42b1-401a-a09f-78e212831cf9.TID453.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 5.0 (TID 454). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 54.0 in stage 5.0 (TID 457, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 54.0 in stage 5.0 (TID 457)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 5.0 (TID 454) in 169 ms on localhost (executor driver) (51/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=50),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/50]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 5.0 (TID 453). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 55.0 in stage 5.0 (TID 458, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 5.0 (TID 453) in 175 ms on localhost (executor driver) (52/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 55.0 in stage 5.0 (TID 458)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1159e705
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52fdc63d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,54,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20b150b0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6234dbad
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,55,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.3.delta.864e1142-fbdb-4cb4-836e-599dc30a0307.TID455.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.3.delta.a36bbbfb-634d-4902-bdb0-bc867a1e3be8.TID456.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.3.delta.0646da5f-1681-4270-9368-dc8322b9b7f2.TID457.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.3.delta.2703ecd1-5d3d-4774-8cc5-c0cf3bcbe312.TID458.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.3.delta.864e1142-fbdb-4cb4-836e-599dc30a0307.TID455.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 52 (task 455, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 52 (task 455, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.3.delta.a36bbbfb-634d-4902-bdb0-bc867a1e3be8.TID456.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 53 (task 456, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 53 (task 456, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.3.delta.2703ecd1-5d3d-4774-8cc5-c0cf3bcbe312.TID458.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.3.delta.0646da5f-1681-4270-9368-dc8322b9b7f2.TID457.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 55 (task 458, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 55 (task 458, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 54 (task 457, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 54 (task 457, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53/.3.delta.c0659c40-23d3-412b-86eb-575e940382f5.TID456.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52/.3.delta.04c44aac-0ad5-402e-a8d9-d82c5aa4128d.TID455.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55/.3.delta.25c4f3a1-70e9-41f3-9308-03352dd56a94.TID458.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=52),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/52]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=53),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/53]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 5.0 (TID 455). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=55),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/55]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 5.0 (TID 456). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 56.0 in stage 5.0 (TID 459, localhost, executor driver, partition 56, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 5.0 (TID 458). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 57.0 in stage 5.0 (TID 460, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 56.0 in stage 5.0 (TID 459)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 58.0 in stage 5.0 (TID 461, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 57.0 in stage 5.0 (TID 460)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 5.0 (TID 455) in 331 ms on localhost (executor driver) (53/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 58.0 in stage 5.0 (TID 461)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 5.0 (TID 456) in 327 ms on localhost (executor driver) (54/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 5.0 (TID 458) in 315 ms on localhost (executor driver) (55/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54/.3.delta.52a6d5a3-1bb7-4303-84c2-1ea5701cef61.TID457.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4990c7b0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=54),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/54]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 5.0 (TID 457). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26ba4532
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 59.0 in stage 5.0 (TID 462, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 5.0 (TID 457) in 322 ms on localhost (executor driver) (56/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 59.0 in stage 5.0 (TID 462)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7829ed3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cae76e4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,58,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@906233d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,56,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d38b57b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,57,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dec057c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16b99afc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,59,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.3.delta.d8a2e609-32eb-4d41-98d5-6558eb858158.TID462.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.3.delta.585f10be-5c83-4fad-9303-bba19e8fe300.TID461.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.3.delta.395a0e40-cf20-407a-a032-31b52407e985.TID459.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.3.delta.16065c3c-8071-4a4f-b814-8ecfddd35f40.TID460.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.3.delta.16065c3c-8071-4a4f-b814-8ecfddd35f40.TID460.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 57 (task 460, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 57 (task 460, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.3.delta.585f10be-5c83-4fad-9303-bba19e8fe300.TID461.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 58 (task 461, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 58 (task 461, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,857][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.3.delta.d8a2e609-32eb-4d41-98d5-6558eb858158.TID462.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.3.delta.395a0e40-cf20-407a-a032-31b52407e985.TID459.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 59 (task 462, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 59 (task 462, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 56 (task 459, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 56 (task 459, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58/.3.delta.a60637c4-ad8b-405d-9a92-8a65d7495b9c.TID461.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=58),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/58]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,970][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57/.3.delta.710149e0-4061-4464-8d07-8953fde0077c.TID460.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 5.0 (TID 461). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 60.0 in stage 5.0 (TID 463, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 5.0 (TID 461) in 299 ms on localhost (executor driver) (57/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 60.0 in stage 5.0 (TID 463)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=57),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/57]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 5.0 (TID 460). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 61.0 in stage 5.0 (TID 464, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@483d0e86
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 5.0 (TID 460) in 307 ms on localhost (executor driver) (58/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 61.0 in stage 5.0 (TID 464)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59860e1e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,60,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,987][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4809ade2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3012c8c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,61,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:36,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59/.3.delta.f20ff90b-06e8-48d0-86c7-839e443405e8.TID462.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56/.3.delta.c7213e14-6594-4a57-8706-6a93a9e1c4e8.TID459.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=59),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/59]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 5.0 (TID 462). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 62.0 in stage 5.0 (TID 465, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 5.0 (TID 462) in 332 ms on localhost (executor driver) (59/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 62.0 in stage 5.0 (TID 465)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=56),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/56]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33fe71f1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 5.0 (TID 459). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1774e1d8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 63.0 in stage 5.0 (TID 466, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,62,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 5.0 (TID 459) in 344 ms on localhost (executor driver) (60/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 63.0 in stage 5.0 (TID 466)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a9e452a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9a8cbb3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,63,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.3.delta.b87aebc9-0cbf-474f-a89c-9c7f83d1570e.TID463.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.3.delta.15341d5d-6e9d-40bc-b154-23836f3d65ee.TID464.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.3.delta.63dbc15a-e8db-49e4-87a1-1fee21621534.TID465.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.3.delta.a7e39454-072e-4b63-a0ba-041f034fed31.TID466.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.3.delta.b87aebc9-0cbf-474f-a89c-9c7f83d1570e.TID463.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 60 (task 463, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 60 (task 463, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.3.delta.15341d5d-6e9d-40bc-b154-23836f3d65ee.TID464.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 61 (task 464, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 61 (task 464, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.3.delta.63dbc15a-e8db-49e4-87a1-1fee21621534.TID465.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 62 (task 465, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 62 (task 465, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.3.delta.a7e39454-072e-4b63-a0ba-041f034fed31.TID466.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 63 (task 466, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 63 (task 466, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60/.3.delta.a8862691-7bae-45ca-97e9-e014585dc403.TID463.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=60),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/60]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 5.0 (TID 463). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 64.0 in stage 5.0 (TID 467, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 5.0 (TID 463) in 265 ms on localhost (executor driver) (61/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 64.0 in stage 5.0 (TID 467)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61/.3.delta.9c4e72fc-7cf5-46e9-b2df-82aa81271b08.TID464.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=61),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/61]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50fd617d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 5.0 (TID 464). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 65.0 in stage 5.0 (TID 468, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 5.0 (TID 464) in 260 ms on localhost (executor driver) (62/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 65.0 in stage 5.0 (TID 468)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@108c297c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,64,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4df76a48
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dcececa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,65,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62/.3.delta.781c648d-6768-41b0-b488-986a62d1a90f.TID465.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63/.3.delta.b1edacd4-8de9-4649-81e0-4ac3d28af8c8.TID466.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=62),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/62]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 5.0 (TID 465). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=63),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/63]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 66.0 in stage 5.0 (TID 469, localhost, executor driver, partition 66, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 5.0 (TID 465) in 239 ms on localhost (executor driver) (63/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 66.0 in stage 5.0 (TID 469)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 5.0 (TID 466). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 67.0 in stage 5.0 (TID 470, localhost, executor driver, partition 67, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 5.0 (TID 466) in 235 ms on localhost (executor driver) (64/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 67.0 in stage 5.0 (TID 470)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a5445b2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@664ed23
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,66,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5378866f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c023cdd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,67,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,262][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.3.delta.6c807778-5c73-4290-8f5c-020beecbf48e.TID467.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.3.delta.30461571-401e-43c0-8912-0cb3596340b3.TID469.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.3.delta.dc4b09da-89fe-4aff-99da-9086a3b2b61e.TID468.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.3.delta.890929bd-4185-4716-8db5-8bdc147566a5.TID470.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.3.delta.6c807778-5c73-4290-8f5c-020beecbf48e.TID467.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,386][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 64 (task 467, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,386][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 64 (task 467, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.3.delta.dc4b09da-89fe-4aff-99da-9086a3b2b61e.TID468.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.3.delta.30461571-401e-43c0-8912-0cb3596340b3.TID469.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 65 (task 468, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 65 (task 468, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 66 (task 469, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 66 (task 469, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.3.delta.890929bd-4185-4716-8db5-8bdc147566a5.TID470.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 67 (task 470, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 67 (task 470, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65/.3.delta.dbbf8ead-b693-4d78-a646-43e1ef25f63d.TID468.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=65),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/65]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64/.3.delta.63273939-84d0-4e60-8251-1d8de779dce4.TID467.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 5.0 (TID 468). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 68.0 in stage 5.0 (TID 471, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=64),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/64]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 5.0 (TID 468) in 203 ms on localhost (executor driver) (65/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 68.0 in stage 5.0 (TID 471)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 5.0 (TID 467). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 69.0 in stage 5.0 (TID 472, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 5.0 (TID 467) in 210 ms on localhost (executor driver) (66/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 69.0 in stage 5.0 (TID 472)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@533d23c3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a933e9f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,68,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66/.3.delta.25100f2f-a562-4fb4-8344-366569f0ef21.TID469.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c2ddd55
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=66),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/66]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aff719
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,69,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 5.0 (TID 469). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 70.0 in stage 5.0 (TID 473, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 5.0 (TID 469) in 204 ms on localhost (executor driver) (67/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 70.0 in stage 5.0 (TID 473)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa8ad41
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67/.3.delta.c96bd8ee-e2c5-4c21-902a-1ded1cdcbcb4.TID470.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@522924db
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,70,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=67),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/67]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,462][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 5.0 (TID 470). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,463][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 71.0 in stage 5.0 (TID 474, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 5.0 (TID 470) in 211 ms on localhost (executor driver) (68/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 71.0 in stage 5.0 (TID 474)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a0f3f10
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7808f2ef
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,71,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.3.delta.cbd46cd7-34f8-409f-879a-e2a501afd282.TID471.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.3.delta.86fe9ea1-a34f-4ebd-90bb-e97ea9b692cb.TID473.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.3.delta.d7205356-1080-48a4-b468-e6c30db221a4.TID474.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.3.delta.98005772-503f-40ba-a9f3-b9a3b9711470.TID472.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.3.delta.cbd46cd7-34f8-409f-879a-e2a501afd282.TID471.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 68 (task 471, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 68 (task 471, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.3.delta.d7205356-1080-48a4-b468-e6c30db221a4.TID474.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.3.delta.98005772-503f-40ba-a9f3-b9a3b9711470.TID472.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 71 (task 474, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 69 (task 472, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 71 (task 474, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 69 (task 472, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.3.delta.86fe9ea1-a34f-4ebd-90bb-e97ea9b692cb.TID473.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 70 (task 473, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 70 (task 473, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68/.3.delta.3f6f0d9b-c50b-4d59-b381-b69222854866.TID471.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=68),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/68]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 5.0 (TID 471). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 72.0 in stage 5.0 (TID 475, localhost, executor driver, partition 72, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 5.0 (TID 471) in 211 ms on localhost (executor driver) (69/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 72.0 in stage 5.0 (TID 475)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23559e59
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f200c27
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,72,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69/.3.delta.fc0dd28b-14e4-4712-850c-5fc8b53df599.TID472.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,664][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71/.3.delta.d44a59a3-5486-4946-8811-23ee9826eee6.TID474.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=69),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/69]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=71),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/71]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 5.0 (TID 472). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 5.0 (TID 474). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 73.0 in stage 5.0 (TID 476, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 74.0 in stage 5.0 (TID 477, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 73.0 in stage 5.0 (TID 476)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 5.0 (TID 474) in 205 ms on localhost (executor driver) (70/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 5.0 (TID 472) in 221 ms on localhost (executor driver) (71/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 74.0 in stage 5.0 (TID 477)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e368210
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fcc66
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,73,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b9d102
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e1ac5b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,74,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70/.3.delta.cabdf447-ccd0-421e-833f-6216bc7a43d6.TID473.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=70),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/70]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 5.0 (TID 473). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 75.0 in stage 5.0 (TID 478, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 5.0 (TID 473) in 226 ms on localhost (executor driver) (72/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 75.0 in stage 5.0 (TID 478)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dcce1a9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@731fa4e0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,75,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.3.delta.8f656de1-8f23-4778-bb4c-707f961affa3.TID475.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.3.delta.c65ff371-7859-41d7-9d4a-8f4c57ef5f6f.TID476.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.3.delta.5223d7b9-4ff5-4373-bcac-4e392b2ad101.TID477.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.3.delta.1f3e9a56-631b-440d-bede-65d0fbd7f197.TID478.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.3.delta.c65ff371-7859-41d7-9d4a-8f4c57ef5f6f.TID476.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.3.delta.8f656de1-8f23-4778-bb4c-707f961affa3.TID475.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 73 (task 476, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 72 (task 475, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,774][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 73 (task 476, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 72 (task 475, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.3.delta.5223d7b9-4ff5-4373-bcac-4e392b2ad101.TID477.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,781][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 74 (task 477, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 74 (task 477, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.3.delta.1f3e9a56-631b-440d-bede-65d0fbd7f197.TID478.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,790][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 75 (task 478, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 75 (task 478, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73/.3.delta.dc6c69d6-916a-432e-8fd6-1f70b48daef9.TID476.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=73),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/73]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 5.0 (TID 476). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 76.0 in stage 5.0 (TID 479, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 5.0 (TID 476) in 146 ms on localhost (executor driver) (73/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 76.0 in stage 5.0 (TID 479)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@554c5f1c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75a14103
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,76,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72/.3.delta.38c1678f-867b-4e5f-a174-fa0f2e72b01f.TID475.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=72),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/72]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 5.0 (TID 475). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 77.0 in stage 5.0 (TID 480, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 5.0 (TID 475) in 174 ms on localhost (executor driver) (74/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 77.0 in stage 5.0 (TID 480)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57144a33
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ac9fd1e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74/.3.delta.49f18bfc-1b75-4a69-a698-0188841110d6.TID477.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,77,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=74),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/74]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 5.0 (TID 477). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 78.0 in stage 5.0 (TID 481, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 78.0 in stage 5.0 (TID 481)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 5.0 (TID 477) in 169 ms on localhost (executor driver) (75/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75/.3.delta.960431a1-9ec1-49c7-b69c-9d12d1ea75d6.TID478.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=75),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/75]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce1b689
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 5.0 (TID 478). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 79.0 in stage 5.0 (TID 482, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7058cbee
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 5.0 (TID 478) in 161 ms on localhost (executor driver) (76/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 79.0 in stage 5.0 (TID 482)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,78,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70294c98
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bd77290
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,79,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,865][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.3.delta.e064eeb8-de8c-43cc-8cc1-de2a6027daa3.TID479.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.3.delta.a11c6fd4-9207-458f-b3d8-f2d44a6144bc.TID480.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.3.delta.491067a2-19ed-4e34-a95d-fa35c1dfdf4c.TID482.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.3.delta.bbb8b16b-f846-4928-ba73-bf00c0b2c42a.TID481.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.3.delta.e064eeb8-de8c-43cc-8cc1-de2a6027daa3.TID479.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 76 (task 479, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 76 (task 479, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.3.delta.a11c6fd4-9207-458f-b3d8-f2d44a6144bc.TID480.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 77 (task 480, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 77 (task 480, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.3.delta.491067a2-19ed-4e34-a95d-fa35c1dfdf4c.TID482.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 79 (task 482, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 79 (task 482, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.3.delta.bbb8b16b-f846-4928-ba73-bf00c0b2c42a.TID481.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 78 (task 481, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 78 (task 481, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76/.3.delta.0fe8268b-3ad4-4ef4-8102-6545496e8f47.TID479.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=76),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/76]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 5.0 (TID 479). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 80.0 in stage 5.0 (TID 483, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 5.0 (TID 479) in 146 ms on localhost (executor driver) (77/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 80.0 in stage 5.0 (TID 483)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79ccfe74
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ae967fe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,80,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77/.3.delta.454e9b24-c775-4bad-aaf6-4a322171a658.TID480.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=77),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/77]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 5.0 (TID 480). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 81.0 in stage 5.0 (TID 484, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 5.0 (TID 480) in 140 ms on localhost (executor driver) (78/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 81.0 in stage 5.0 (TID 484)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ed054d0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5280b962
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79/.3.delta.dead75ea-fe0a-4662-8370-a306e102071e.TID482.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,81,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=79),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/79]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 5.0 (TID 482). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 82.0 in stage 5.0 (TID 485, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 5.0 (TID 482) in 135 ms on localhost (executor driver) (79/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 82.0 in stage 5.0 (TID 485)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46f0a438
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78/.3.delta.ca32629c-f047-433e-892a-f4ee967abf39.TID481.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34378421
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,82,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=78),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/78]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 5.0 (TID 481). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 83.0 in stage 5.0 (TID 486, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 5.0 (TID 481) in 146 ms on localhost (executor driver) (80/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 83.0 in stage 5.0 (TID 486)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ddaff80
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27d1d141
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,83,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:37,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.3.delta.f77aa90e-2704-4d9e-8dfd-ae3bacec6a34.TID483.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.3.delta.8f763b18-63d8-4f07-ae71-bfe7ba41b5f3.TID484.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.3.delta.8d5e932e-1eff-475b-9d06-929f9d45ff51.TID485.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.3.delta.ecaa00ed-adff-4106-84c3-fdc38ae61594.TID486.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.3.delta.f77aa90e-2704-4d9e-8dfd-ae3bacec6a34.TID483.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 80 (task 483, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 80 (task 483, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.3.delta.8f763b18-63d8-4f07-ae71-bfe7ba41b5f3.TID484.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 81 (task 484, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 81 (task 484, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.3.delta.8d5e932e-1eff-475b-9d06-929f9d45ff51.TID485.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 82 (task 485, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 82 (task 485, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.3.delta.ecaa00ed-adff-4106-84c3-fdc38ae61594.TID486.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 83 (task 486, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 83 (task 486, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80/.3.delta.b0a91b9b-10cd-40be-a62f-4ce064d3253b.TID483.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=80),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/80]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81/.3.delta.93c520f1-7e21-43ca-8f73-81e310fe1f69.TID484.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 5.0 (TID 483). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 84.0 in stage 5.0 (TID 487, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 5.0 (TID 483) in 167 ms on localhost (executor driver) (81/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 84.0 in stage 5.0 (TID 487)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=81),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/81]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 5.0 (TID 484). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1659d8fb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 85.0 in stage 5.0 (TID 488, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 5.0 (TID 484) in 163 ms on localhost (executor driver) (82/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 85.0 in stage 5.0 (TID 488)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11841299
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,84,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31e740dd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51b6633f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,85,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82/.3.delta.33ea9f40-5159-4890-b567-ffa40e260143.TID485.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=82),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/82]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 5.0 (TID 485). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83/.3.delta.24a2780c-9fc5-473c-aace-5fad251bea6f.TID486.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 86.0 in stage 5.0 (TID 489, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 5.0 (TID 485) in 185 ms on localhost (executor driver) (83/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 86.0 in stage 5.0 (TID 489)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77b28aaa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26b377b5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=83),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/83]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,86,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 5.0 (TID 486). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 87.0 in stage 5.0 (TID 490, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 5.0 (TID 486) in 189 ms on localhost (executor driver) (84/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 87.0 in stage 5.0 (TID 490)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75bb428f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ac170d1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,87,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.3.delta.2ad6e34d-2779-4ff3-8164-e01a290285c0.TID487.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.3.delta.2407e566-62ed-4c8b-8b9b-4b3a6100b622.TID488.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.3.delta.a678b774-a288-41d8-968a-9d63116276a8.TID489.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.3.delta.e14724dd-fd5f-4100-9fdf-a0a9fd8df793.TID490.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.3.delta.2ad6e34d-2779-4ff3-8164-e01a290285c0.TID487.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.3.delta.2407e566-62ed-4c8b-8b9b-4b3a6100b622.TID488.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 84 (task 487, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 84 (task 487, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 85 (task 488, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 85 (task 488, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.3.delta.e14724dd-fd5f-4100-9fdf-a0a9fd8df793.TID490.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 87 (task 490, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 87 (task 490, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.3.delta.a678b774-a288-41d8-968a-9d63116276a8.TID489.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,460][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 86 (task 489, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 86 (task 489, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84/.3.delta.168abc14-52d5-42c0-b44d-ff30bdcbc16f.TID487.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=84),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/84]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,493][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 5.0 (TID 487). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,494][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 88.0 in stage 5.0 (TID 491, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,494][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 5.0 (TID 487) in 369 ms on localhost (executor driver) (85/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 88.0 in stage 5.0 (TID 491)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c652b64
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85/.3.delta.fb112f92-f574-44bd-8cd5-ff6d54a72eb5.TID488.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2743da47
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,88,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=85),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/85]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 5.0 (TID 488). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 89.0 in stage 5.0 (TID 492, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 5.0 (TID 488) in 383 ms on localhost (executor driver) (86/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 89.0 in stage 5.0 (TID 492)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21b7230c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a23e109
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,89,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,542][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87/.3.delta.34277ece-261a-449e-a665-de6f04e200c0.TID490.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86/.3.delta.0855c971-e22a-4479-8243-08fa178adc8b.TID489.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=87),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/87]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 5.0 (TID 490). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 90.0 in stage 5.0 (TID 493, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 5.0 (TID 490) in 379 ms on localhost (executor driver) (87/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,550][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 90.0 in stage 5.0 (TID 493)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=86),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/86]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 5.0 (TID 489). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 91.0 in stage 5.0 (TID 494, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 5.0 (TID 489) in 394 ms on localhost (executor driver) (88/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 91.0 in stage 5.0 (TID 494)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@700de71b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cda01a1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,90,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3abf3b21
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37ebf3c3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,91,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.3.delta.f10ee296-418a-40a4-9938-5329afa05f5f.TID491.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.3.delta.401e63b1-8a47-4b15-b3c5-c021fb71c5c3.TID492.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.3.delta.9b363750-478e-424f-9f79-12b8b96b97a8.TID493.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.3.delta.78372fdc-c893-4d12-8180-3740d2fcb38d.TID494.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.3.delta.f10ee296-418a-40a4-9938-5329afa05f5f.TID491.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,771][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 88 (task 491, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 88 (task 491, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.3.delta.401e63b1-8a47-4b15-b3c5-c021fb71c5c3.TID492.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,817][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 89 (task 492, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 89 (task 492, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.3.delta.9b363750-478e-424f-9f79-12b8b96b97a8.TID493.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 90 (task 493, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 90 (task 493, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.3.delta.78372fdc-c893-4d12-8180-3740d2fcb38d.TID494.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 91 (task 494, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 91 (task 494, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88/.3.delta.0c552681-c44b-43db-aa12-3d132307357d.TID491.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=88),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/88]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 5.0 (TID 491). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 92.0 in stage 5.0 (TID 495, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 5.0 (TID 491) in 402 ms on localhost (executor driver) (89/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 92.0 in stage 5.0 (TID 495)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,901][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f6c18c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@681fade
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,92,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,927][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89/.3.delta.27c10fb7-058e-4371-8549-fa88d8c79d8a.TID492.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=89),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/89]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 5.0 (TID 492). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 93.0 in stage 5.0 (TID 496, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 5.0 (TID 492) in 420 ms on localhost (executor driver) (90/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 93.0 in stage 5.0 (TID 496)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@666837ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48df5c2b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,93,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90/.3.delta.63e8bad2-d60b-428a-a669-0f14a515a4cd.TID493.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=90),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/90]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 5.0 (TID 493). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 94.0 in stage 5.0 (TID 497, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 5.0 (TID 493) in 401 ms on localhost (executor driver) (91/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 94.0 in stage 5.0 (TID 497)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b350480
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91/.3.delta.a4bb048a-c004-44b7-bb90-4af815b9b78e.TID494.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@561652f5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=91),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/91]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,94,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 5.0 (TID 494). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 95.0 in stage 5.0 (TID 498, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 5.0 (TID 494) in 414 ms on localhost (executor driver) (92/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 95.0 in stage 5.0 (TID 498)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61593576
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57014cd1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,95,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:38,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.3.delta.56e8140f-bc97-4d1a-b2e3-720f2f2feed0.TID495.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.3.delta.7826d73e-b797-46f4-b411-2e45fe193ec7.TID496.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.3.delta.a0c64edb-c8d6-4f64-b86d-e52bfc177980.TID497.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.3.delta.9579214b-e298-4c70-8f67-a30d8a77c685.TID498.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.3.delta.56e8140f-bc97-4d1a-b2e3-720f2f2feed0.TID495.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 92 (task 495, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 92 (task 495, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.3.delta.a0c64edb-c8d6-4f64-b86d-e52bfc177980.TID497.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 94 (task 497, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 94 (task 497, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.3.delta.7826d73e-b797-46f4-b411-2e45fe193ec7.TID496.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 93 (task 496, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 93 (task 496, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.3.delta.9579214b-e298-4c70-8f67-a30d8a77c685.TID498.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 95 (task 498, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 95 (task 498, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92/.3.delta.c7ccf945-799e-4caf-b7d9-1bf2ca6b46e2.TID495.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=92),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/92]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 5.0 (TID 495). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 96.0 in stage 5.0 (TID 499, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 5.0 (TID 495) in 396 ms on localhost (executor driver) (93/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 96.0 in stage 5.0 (TID 499)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,294][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad9f099
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58fb5ae5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,96,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94/.3.delta.06859323-e6bd-4e05-8ccb-4fe73c5d70df.TID497.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=94),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/94]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 5.0 (TID 497). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 97.0 in stage 5.0 (TID 500, localhost, executor driver, partition 97, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 5.0 (TID 497) in 375 ms on localhost (executor driver) (94/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 97.0 in stage 5.0 (TID 500)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@364e151f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c06a642
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,97,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93/.3.delta.26797eb8-d306-4334-a81e-3a9e661b7366.TID496.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=93),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/93]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 5.0 (TID 496). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 98.0 in stage 5.0 (TID 501, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 5.0 (TID 496) in 413 ms on localhost (executor driver) (95/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 98.0 in stage 5.0 (TID 501)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e98726a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ef7eaa8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,98,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95/.3.delta.b8a6dc2d-92aa-464f-94e7-e1da9fe91dc2.TID498.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=95),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/95]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 5.0 (TID 498). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 99.0 in stage 5.0 (TID 502, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 5.0 (TID 498) in 387 ms on localhost (executor driver) (96/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 99.0 in stage 5.0 (TID 502)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29b14552
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@259c35aa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,99,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.3.delta.81b79ef8-afd3-488a-b524-3fc9aca2dda8.TID499.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.3.delta.c6142583-3ea0-4983-8dea-48e28dc8fb5c.TID500.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.3.delta.6e806a46-7d7a-4cfd-80d6-f0cccbf9f6ee.TID502.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.3.delta.b554ac4e-4fa1-4815-b0c3-f106d2a19cda.TID501.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.3.delta.81b79ef8-afd3-488a-b524-3fc9aca2dda8.TID499.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 96 (task 499, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 96 (task 499, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.3.delta.c6142583-3ea0-4983-8dea-48e28dc8fb5c.TID500.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,528][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 97 (task 500, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,528][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 97 (task 500, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.3.delta.b554ac4e-4fa1-4815-b0c3-f106d2a19cda.TID501.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.3.delta.6e806a46-7d7a-4cfd-80d6-f0cccbf9f6ee.TID502.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 98 (task 501, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 98 (task 501, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 99 (task 502, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 99 (task 502, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96/.3.delta.77da8fc0-dee8-47c7-b627-fd1cd66d0208.TID499.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=96),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/96]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 5.0 (TID 499). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 100.0 in stage 5.0 (TID 503, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 5.0 (TID 499) in 264 ms on localhost (executor driver) (97/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,555][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 100.0 in stage 5.0 (TID 503)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e073269
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1085b59
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,100,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97/.3.delta.d54ace9f-fd7b-46be-a329-14b2c685c096.TID500.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=97),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/97]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 5.0 (TID 500). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 101.0 in stage 5.0 (TID 504, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 5.0 (TID 500) in 247 ms on localhost (executor driver) (98/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 101.0 in stage 5.0 (TID 504)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21ef4e68
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,578][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c4dcd3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,101,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,580][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99/.3.delta.51eee8d8-5204-4991-af8c-29404bdc4b72.TID502.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98/.3.delta.821bd670-c3c7-4a61-9880-0e88eaf505aa.TID501.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=99),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/99]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=98),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/98]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 5.0 (TID 501). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 5.0 (TID 502). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 102.0 in stage 5.0 (TID 505, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 103.0 in stage 5.0 (TID 506, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 102.0 in stage 5.0 (TID 505)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 5.0 (TID 502) in 243 ms on localhost (executor driver) (99/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 103.0 in stage 5.0 (TID 506)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 5.0 (TID 501) in 252 ms on localhost (executor driver) (100/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7200ab9c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7322dcfd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@190850a0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,103,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@667ac939
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,102,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.3.delta.027c6e32-e08d-4a3c-a302-2d7511677751.TID503.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.3.delta.eb1576a2-0f13-4a8c-b643-9d8d3a76d380.TID504.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.3.delta.528e2d3a-7102-43b2-a34c-e80c148d68fb.TID506.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.3.delta.f74bfe34-3d5b-433e-aca9-a4affa10b413.TID505.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.3.delta.027c6e32-e08d-4a3c-a302-2d7511677751.TID503.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 100 (task 503, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 100 (task 503, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.3.delta.f74bfe34-3d5b-433e-aca9-a4affa10b413.TID505.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.3.delta.eb1576a2-0f13-4a8c-b643-9d8d3a76d380.TID504.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 102 (task 505, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 102 (task 505, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 101 (task 504, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 101 (task 504, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.3.delta.528e2d3a-7102-43b2-a34c-e80c148d68fb.TID506.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 103 (task 506, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 103 (task 506, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100/.3.delta.7c66f3c8-6e2a-49da-b768-7ec7f5acc4e9.TID503.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=100),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/100]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 5.0 (TID 503). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 104.0 in stage 5.0 (TID 507, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 5.0 (TID 503) in 227 ms on localhost (executor driver) (101/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 104.0 in stage 5.0 (TID 507)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4266814c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47435471
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,104,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102/.3.delta.aaba05be-f6b6-4c83-ae39-a0c9177544bd.TID505.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=102),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/102]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 5.0 (TID 505). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 105.0 in stage 5.0 (TID 508, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 5.0 (TID 505) in 217 ms on localhost (executor driver) (102/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 105.0 in stage 5.0 (TID 508)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101/.3.delta.25c123dd-be0f-4b4b-a34b-bd398d4605fc.TID504.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=101),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/101]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 5.0 (TID 504). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 106.0 in stage 5.0 (TID 509, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 5.0 (TID 504) in 242 ms on localhost (executor driver) (103/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 106.0 in stage 5.0 (TID 509)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb10226
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78413279
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,105,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad490bb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@732ebda
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,106,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103/.3.delta.5227e59b-048d-4d32-8e4d-608a27bbd504.TID506.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=103),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/103]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 5.0 (TID 506). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 107.0 in stage 5.0 (TID 510, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 5.0 (TID 506) in 234 ms on localhost (executor driver) (104/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 107.0 in stage 5.0 (TID 510)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3517feef
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3584ca0e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,107,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.3.delta.9381aeca-ab38-4428-9689-67db4b7d42be.TID507.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.3.delta.ce7282f4-8fbf-43e3-9ec3-4b4f30195ea4.TID509.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.3.delta.413eeec1-2b08-4238-9cf6-a24c797cf72b.TID508.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.3.delta.cad2b282-1c6e-400e-826c-37d2df9df65a.TID510.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.3.delta.9381aeca-ab38-4428-9689-67db4b7d42be.TID507.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 104 (task 507, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 104 (task 507, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.3.delta.ce7282f4-8fbf-43e3-9ec3-4b4f30195ea4.TID509.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 106 (task 509, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 106 (task 509, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.3.delta.413eeec1-2b08-4238-9cf6-a24c797cf72b.TID508.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 105 (task 508, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 105 (task 508, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104/.3.delta.a37852fe-8370-428e-8317-fa694eecd87a.TID507.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.3.delta.cad2b282-1c6e-400e-826c-37d2df9df65a.TID510.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=104),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/104]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 5.0 (TID 507). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 108.0 in stage 5.0 (TID 511, localhost, executor driver, partition 108, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 5.0 (TID 507) in 179 ms on localhost (executor driver) (105/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 107 (task 510, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 107 (task 510, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 108.0 in stage 5.0 (TID 511)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ac1c6b9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d0854bb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,108,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106/.3.delta.de0892c0-8239-4517-902f-56e4682fc44d.TID509.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105/.3.delta.8dd0f825-7d5e-4b18-9758-270e362bb1a1.TID508.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=106),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/106]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=105),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/105]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 5.0 (TID 509). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 109.0 in stage 5.0 (TID 512, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 5.0 (TID 508). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 5.0 (TID 509) in 170 ms on localhost (executor driver) (106/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 109.0 in stage 5.0 (TID 512)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 110.0 in stage 5.0 (TID 513, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 5.0 (TID 508) in 175 ms on localhost (executor driver) (107/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 110.0 in stage 5.0 (TID 513)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2414fb43
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27849d2a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a573f13
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,110,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f66f452
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,109,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:39,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107/.3.delta.083c7596-3cb4-4d25-a0ab-42083e33600f.TID510.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=107),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/107]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 5.0 (TID 510). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 111.0 in stage 5.0 (TID 514, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 5.0 (TID 510) in 185 ms on localhost (executor driver) (108/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 111.0 in stage 5.0 (TID 514)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b5cae7b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7624bd5d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,111,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.3.delta.921c3dc9-3853-4dda-b38c-614e000ccb16.TID511.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.3.delta.842a5339-825f-421c-a91e-757ce1250ca0.TID512.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.3.delta.ceb45e83-b058-40e9-8cd2-f0f501460bf3.TID513.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.3.delta.fdf2eade-fe30-4496-9b4c-fc56e78e5fbc.TID514.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.3.delta.921c3dc9-3853-4dda-b38c-614e000ccb16.TID511.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 108 (task 511, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 108 (task 511, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.3.delta.ceb45e83-b058-40e9-8cd2-f0f501460bf3.TID513.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.3.delta.842a5339-825f-421c-a91e-757ce1250ca0.TID512.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 110 (task 513, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 110 (task 513, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 109 (task 512, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 109 (task 512, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.3.delta.fdf2eade-fe30-4496-9b4c-fc56e78e5fbc.TID514.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 111 (task 514, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 111 (task 514, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108/.3.delta.b873aa0a-dc3e-4de7-afd3-bbf5d59cb733.TID511.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=108),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/108]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 5.0 (TID 511). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 112.0 in stage 5.0 (TID 515, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 112.0 in stage 5.0 (TID 515)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 5.0 (TID 511) in 187 ms on localhost (executor driver) (109/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77938819
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a1347c1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,112,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109/.3.delta.a1bb75cc-036e-4566-95f4-8555c64f00ba.TID512.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110/.3.delta.d765434d-b278-4a3a-b5de-8dbbe7ef09e6.TID513.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=109),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/109]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=110),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/110]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 5.0 (TID 512). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 5.0 (TID 513). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 113.0 in stage 5.0 (TID 516, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 114.0 in stage 5.0 (TID 517, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 113.0 in stage 5.0 (TID 516)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 5.0 (TID 513) in 191 ms on localhost (executor driver) (110/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 114.0 in stage 5.0 (TID 517)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 5.0 (TID 512) in 194 ms on localhost (executor driver) (111/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4827cd4a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6774f95c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,113,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10d57a10
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62b08525
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,114,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111/.3.delta.1e3ea9dd-ccb5-419e-8ab7-3b83242dc45b.TID514.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=111),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/111]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 5.0 (TID 514). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 115.0 in stage 5.0 (TID 518, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 5.0 (TID 514) in 184 ms on localhost (executor driver) (112/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 115.0 in stage 5.0 (TID 518)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa9e884
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41476d64
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,115,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.3.delta.cd90dd84-57a2-49df-8e3f-27b026ecfa43.TID515.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.3.delta.ea8310b9-63cf-4fc1-9d18-ad72cc149577.TID517.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.3.delta.e74e23b1-7d07-4d1e-aac2-be7d859f9aa9.TID516.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.3.delta.13404c71-c3c4-4c8e-8f17-ecd77be8822a.TID518.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.3.delta.cd90dd84-57a2-49df-8e3f-27b026ecfa43.TID515.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 112 (task 515, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 112 (task 515, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.3.delta.e74e23b1-7d07-4d1e-aac2-be7d859f9aa9.TID516.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 113 (task 516, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 113 (task 516, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.3.delta.ea8310b9-63cf-4fc1-9d18-ad72cc149577.TID517.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 114 (task 517, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 114 (task 517, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.3.delta.13404c71-c3c4-4c8e-8f17-ecd77be8822a.TID518.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 115 (task 518, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 115 (task 518, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112/.3.delta.10b1cd5b-d68c-43f4-822e-6d3d087ce093.TID515.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113/.3.delta.89f98cfb-e169-42af-ad09-2434e506e713.TID516.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=112),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/112]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=113),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/113]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 5.0 (TID 515). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 5.0 (TID 516). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 116.0 in stage 5.0 (TID 519, localhost, executor driver, partition 116, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 117.0 in stage 5.0 (TID 520, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 116.0 in stage 5.0 (TID 519)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 5.0 (TID 515) in 224 ms on localhost (executor driver) (113/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 117.0 in stage 5.0 (TID 520)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 5.0 (TID 516) in 192 ms on localhost (executor driver) (114/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f8edb03
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f655d67
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,117,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114/.3.delta.f2e38a85-aef7-4bb7-aaad-652455011b64.TID517.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4168ba3e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=114),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/114]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77e7a21e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,116,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 5.0 (TID 517). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 118.0 in stage 5.0 (TID 521, localhost, executor driver, partition 118, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 5.0 (TID 517) in 199 ms on localhost (executor driver) (115/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 118.0 in stage 5.0 (TID 521)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@acb8ad3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26d9119a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,118,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115/.3.delta.55e41d30-ba8f-499a-bd0c-87f28d8664c3.TID518.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=115),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/115]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 5.0 (TID 518). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 119.0 in stage 5.0 (TID 522, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 5.0 (TID 518) in 230 ms on localhost (executor driver) (116/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 119.0 in stage 5.0 (TID 522)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36b328a5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@249c6df2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,119,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.3.delta.1d00176e-f3ad-4c59-aa44-5f4939a5c40a.TID520.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.3.delta.fc250bef-804e-483b-8b27-756063eaf915.TID521.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.3.delta.32187b94-cd99-4d58-8628-858c82372f6e.TID519.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.3.delta.8ab6db23-3690-460e-b89a-be351a2aca11.TID522.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.3.delta.1d00176e-f3ad-4c59-aa44-5f4939a5c40a.TID520.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 117 (task 520, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 117 (task 520, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.3.delta.fc250bef-804e-483b-8b27-756063eaf915.TID521.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 118 (task 521, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,568][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 118 (task 521, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.3.delta.32187b94-cd99-4d58-8628-858c82372f6e.TID519.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,575][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 116 (task 519, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 116 (task 519, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.3.delta.8ab6db23-3690-460e-b89a-be351a2aca11.TID522.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 119 (task 522, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 119 (task 522, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117/.3.delta.c56bf174-a394-4ccb-9fdd-8f119b6b3598.TID520.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118/.3.delta.9ab64a31-445c-4633-b28f-f64ec173c70e.TID521.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=117),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/117]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 5.0 (TID 520). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 120.0 in stage 5.0 (TID 523, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=118),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/118]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 5.0 (TID 520) in 277 ms on localhost (executor driver) (117/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 120.0 in stage 5.0 (TID 523)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 5.0 (TID 521). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 121.0 in stage 5.0 (TID 524, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 5.0 (TID 521) in 271 ms on localhost (executor driver) (118/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 121.0 in stage 5.0 (TID 524)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4249b613
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e77bad9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,120,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5beb13f3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66c85c7b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,121,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116/.3.delta.a9d511af-ec9e-437f-92f6-ea0728aabea9.TID519.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=116),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/116]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 5.0 (TID 519). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 122.0 in stage 5.0 (TID 525, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 5.0 (TID 519) in 311 ms on localhost (executor driver) (119/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 122.0 in stage 5.0 (TID 525)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1310e41
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f772851
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,122,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119/.3.delta.08a3938d-cb5a-4edf-a99e-65888dc5fc27.TID522.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=119),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/119]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 5.0 (TID 522). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 123.0 in stage 5.0 (TID 526, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,689][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 5.0 (TID 522) in 264 ms on localhost (executor driver) (120/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 123.0 in stage 5.0 (TID 526)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46476b9c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10c227b8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,123,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.3.delta.ab9b1758-6716-4096-878a-9cf7aa44f0fa.TID524.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.3.delta.c4997b42-1a68-4bb5-a58d-1d94d9e8f10e.TID523.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.3.delta.8b1c4067-20c1-43f8-8be2-9fccd4c1754c.TID525.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.3.delta.bae995a7-dd11-40cb-99ce-4ef163a22290.TID526.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.3.delta.ab9b1758-6716-4096-878a-9cf7aa44f0fa.TID524.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 121 (task 524, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 121 (task 524, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.3.delta.c4997b42-1a68-4bb5-a58d-1d94d9e8f10e.TID523.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 120 (task 523, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 120 (task 523, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.3.delta.8b1c4067-20c1-43f8-8be2-9fccd4c1754c.TID525.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 122 (task 525, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 122 (task 525, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.3.delta.bae995a7-dd11-40cb-99ce-4ef163a22290.TID526.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 123 (task 526, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 123 (task 526, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121/.3.delta.e4a095d0-083b-4f39-93ae-3af95ae9aeee.TID524.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=121),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/121]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 5.0 (TID 524). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 124.0 in stage 5.0 (TID 527, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 5.0 (TID 524) in 224 ms on localhost (executor driver) (121/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 124.0 in stage 5.0 (TID 527)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120/.3.delta.6791d523-ae43-47c6-9852-2c908cec4a97.TID523.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=120),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/120]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 5.0 (TID 523). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@610761f0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 125.0 in stage 5.0 (TID 528, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 125.0 in stage 5.0 (TID 528)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 5.0 (TID 523) in 232 ms on localhost (executor driver) (122/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,874][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36d89490
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,124,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,876][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f96839e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@103ec3a2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,125,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,879][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123/.3.delta.824f1c95-af00-406b-85ad-82d8f1de9194.TID526.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122/.3.delta.c2f87118-01fb-4d50-be60-f33e93f1a02a.TID525.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=123),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/123]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 5.0 (TID 526). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 126.0 in stage 5.0 (TID 529, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 5.0 (TID 526) in 196 ms on localhost (executor driver) (123/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=122),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/122]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 126.0 in stage 5.0 (TID 529)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 5.0 (TID 525). 5022 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 127.0 in stage 5.0 (TID 530, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 5.0 (TID 525) in 211 ms on localhost (executor driver) (124/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 127.0 in stage 5.0 (TID 530)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12575645
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@675e15c1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39778724
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,126,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@379a01f1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,127,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.3.delta.72592b1c-8f3b-45fe-b676-9e9a10557c26.TID527.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.3.delta.5d714c36-8cf1-48b5-ac5d-ad737c2e504d.TID528.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.3.delta.0ffe29c0-e8f8-4957-aac4-ec3f0ebb6281.TID529.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.3.delta.5c736265-702a-464f-92b4-93af586b22bf.TID530.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.3.delta.5d714c36-8cf1-48b5-ac5d-ad737c2e504d.TID528.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 125 (task 528, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 125 (task 528, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.3.delta.72592b1c-8f3b-45fe-b676-9e9a10557c26.TID527.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 124 (task 527, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:40,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 124 (task 527, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.3.delta.0ffe29c0-e8f8-4957-aac4-ec3f0ebb6281.TID529.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 126 (task 529, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.3.delta.5c736265-702a-464f-92b4-93af586b22bf.TID530.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 126 (task 529, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 127 (task 530, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 127 (task 530, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125/.3.delta.7242f1a2-a4a9-4dc2-a74a-b74395d17f6d.TID528.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=125),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/125]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 5.0 (TID 528). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 128.0 in stage 5.0 (TID 531, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 5.0 (TID 528) in 159 ms on localhost (executor driver) (125/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 128.0 in stage 5.0 (TID 531)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dfb9b75
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@666af0e3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,128,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124/.3.delta.53d78365-fc8e-427d-943f-880159489ef6.TID527.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=124),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/124]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 5.0 (TID 527). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 129.0 in stage 5.0 (TID 532, localhost, executor driver, partition 129, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 5.0 (TID 527) in 175 ms on localhost (executor driver) (126/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 129.0 in stage 5.0 (TID 532)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127/.3.delta.339ed23a-b7f4-4961-94f4-83091353b919.TID530.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31f2b941
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=127),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/127]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ecd6a76
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,129,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 5.0 (TID 530). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 130.0 in stage 5.0 (TID 533, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 5.0 (TID 530) in 163 ms on localhost (executor driver) (127/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 130.0 in stage 5.0 (TID 533)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126/.3.delta.bd2f9cf0-ae00-4a7d-9381-bffe031d03b0.TID529.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=126),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/126]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cf0ee30
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 5.0 (TID 529). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 131.0 in stage 5.0 (TID 534, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 5.0 (TID 529) in 170 ms on localhost (executor driver) (128/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53ebad82
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 131.0 in stage 5.0 (TID 534)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,130,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3046080
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,058][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ed323d0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,131,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.3.delta.f5857af4-8dd4-4a1f-9f63-7f9cff5e8ef0.TID531.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.3.delta.30f1c18d-5ebc-401b-8a16-8430be90b404.TID533.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.3.delta.b00c8144-b1e3-44c8-9929-2a2ddc6b60be.TID532.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.3.delta.820b36ba-b932-4f58-ad7f-20948677738e.TID534.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.3.delta.f5857af4-8dd4-4a1f-9f63-7f9cff5e8ef0.TID531.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 128 (task 531, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 128 (task 531, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.3.delta.30f1c18d-5ebc-401b-8a16-8430be90b404.TID533.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 130 (task 533, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 130 (task 533, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.3.delta.820b36ba-b932-4f58-ad7f-20948677738e.TID534.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.3.delta.b00c8144-b1e3-44c8-9929-2a2ddc6b60be.TID532.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,188][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 131 (task 534, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 131 (task 534, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 129 (task 532, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 129 (task 532, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128/.3.delta.c4d7c915-972f-4438-bb10-8894d94fdaba.TID531.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=128),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/128]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 5.0 (TID 531). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 132.0 in stage 5.0 (TID 535, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 5.0 (TID 531) in 187 ms on localhost (executor driver) (129/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 132.0 in stage 5.0 (TID 535)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130/.3.delta.5c752d0b-687b-45a3-b9bd-81f9964ccb6b.TID533.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=130),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/130]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65b23a56
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131/.3.delta.44f25c11-a1ca-4926-b997-74fcf8327e54.TID534.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 5.0 (TID 533). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 133.0 in stage 5.0 (TID 536, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@212a1afa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 5.0 (TID 533) in 177 ms on localhost (executor driver) (130/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=131),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/131]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 133.0 in stage 5.0 (TID 536)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,132,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 5.0 (TID 534). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 134.0 in stage 5.0 (TID 537, localhost, executor driver, partition 134, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 5.0 (TID 534) in 174 ms on localhost (executor driver) (131/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 134.0 in stage 5.0 (TID 537)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64d57534
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e3f88a5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,133,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4acf5562
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ceabe3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,134,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129/.3.delta.1c8ffd6d-c0d9-4a4b-a8d0-bf2a7277c3eb.TID532.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=129),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/129]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 5.0 (TID 532). 5165 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 135.0 in stage 5.0 (TID 538, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 135.0 in stage 5.0 (TID 538)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 5.0 (TID 532) in 198 ms on localhost (executor driver) (132/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4141d3d5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3377373c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,135,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.3.delta.c4df38c8-f578-49da-8735-5049d62610a4.TID536.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.3.delta.babacaa0-5f36-4b37-b315-4636193a6893.TID535.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.3.delta.76924324-8ea3-47f8-9868-e9c158ce6341.TID537.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.3.delta.8838a09d-5696-4a5c-affe-522c11efeacc.TID538.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.3.delta.76924324-8ea3-47f8-9868-e9c158ce6341.TID537.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.3.delta.babacaa0-5f36-4b37-b315-4636193a6893.TID535.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.3.delta.c4df38c8-f578-49da-8735-5049d62610a4.TID536.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.3.delta.8838a09d-5696-4a5c-affe-522c11efeacc.TID538.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 134 (task 537, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 132 (task 535, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 134 (task 537, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 132 (task 535, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 135 (task 538, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 133 (task 536, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 135 (task 538, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 133 (task 536, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135/.3.delta.8d39b5e3-4a39-45e1-b9d1-dac5be1811d0.TID538.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134/.3.delta.37c25cfa-e44c-4268-aa05-5b8d40a670ab.TID537.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132/.3.delta.39fb0b44-44aa-4964-bf34-592479587d7a.TID535.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133/.3.delta.73a7a129-ef96-48a7-b4ae-e7ef9304656a.TID536.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=134),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/134]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=135),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/135]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=132),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/132]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=133),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/133]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 5.0 (TID 537). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 5.0 (TID 538). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 5.0 (TID 535). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 136.0 in stage 5.0 (TID 539, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 137.0 in stage 5.0 (TID 540, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 5.0 (TID 536). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 5.0 (TID 537) in 189 ms on localhost (executor driver) (133/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 136.0 in stage 5.0 (TID 539)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 137.0 in stage 5.0 (TID 540)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 5.0 (TID 538) in 178 ms on localhost (executor driver) (134/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 138.0 in stage 5.0 (TID 541, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 5.0 (TID 535) in 201 ms on localhost (executor driver) (135/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 139.0 in stage 5.0 (TID 542, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 5.0 (TID 536) in 197 ms on localhost (executor driver) (136/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 138.0 in stage 5.0 (TID 541)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 139.0 in stage 5.0 (TID 542)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec39d75
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f2b880
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c820b71
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,137,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2107838
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68741e47
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,138,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57fb5d39
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,136,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d68de15
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58762b6b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,139,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.3.delta.90f74a3a-a29e-4a21-9805-04763cbbbf44.TID540.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.3.delta.6013a3fc-eac5-4cb8-8de4-3bfc38497e92.TID541.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,521][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.3.delta.e765b16f-fb29-4447-b1b9-70d2e740513a.TID539.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.3.delta.5d6e9b97-ac4f-4a29-84a3-ee4d4e5b3151.TID542.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fbab5d0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34c59a3f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,586][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38d5523f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2725e74b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60636182
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78ef0bd3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ab9ea5b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ae47f8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@193a555e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@198b6439
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cc5ae61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c44bf86
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@679f8ff5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,608][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25f78593
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@345081ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3de1a069
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,625][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@269a7007
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f58b25a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f373b8a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f6530ed
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.3.delta.5d6e9b97-ac4f-4a29-84a3-ee4d4e5b3151.TID542.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,635][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.3.delta.90f74a3a-a29e-4a21-9805-04763cbbbf44.TID540.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,636][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 137 (task 540, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 137 (task 540, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 139 (task 542, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,638][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 139 (task 542, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.3.delta.e765b16f-fb29-4447-b1b9-70d2e740513a.TID539.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a8a754e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.3.delta.6013a3fc-eac5-4cb8-8de4-3bfc38497e92.TID541.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 136 (task 539, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30bad427
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 136 (task 539, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 138 (task 541, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 138 (task 541, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,646][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e742d1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1093f8b8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9aacfe1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fd7291f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@531a0ffe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c437b1d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,659][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34972b3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55803c14
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e6aca5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11baaef7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@592e8a99
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,670][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d1a6d34
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6efa7bb6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a73bd88
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a4901d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59892e10
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6493c95c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@533ba7bb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@703cf1b9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60d5a800
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1af6546f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@147e3ef5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@358b4fa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e009939
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@667de9ba
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@311fa16
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45a871ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f2bf137
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@692e951
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137/.3.delta.b8024067-f176-4f65-a8ac-3a99540b6615.TID540.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139/.3.delta.c413c4de-f18c-4c8f-b06a-a8655a8bba12.TID542.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=137),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/137]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a5f62df
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=139),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/139]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 5.0 (TID 540). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 5.0 (TID 542). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 140.0 in stage 5.0 (TID 543, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 141.0 in stage 5.0 (TID 544, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 140.0 in stage 5.0 (TID 543)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 5.0 (TID 540) in 298 ms on localhost (executor driver) (137/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 141.0 in stage 5.0 (TID 544)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 5.0 (TID 542) in 291 ms on localhost (executor driver) (138/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cfe655f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@855e333
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138/.3.delta.821d2f9d-a2bc-47e5-9aa6-6596ac693ae5.TID541.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c8c9fbe
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136/.3.delta.9d54161e-d4cd-46ee-ac53-ceb33fa2f0fb.TID539.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4625897d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=138),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/138]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bd43a92
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 5.0 (TID 541). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,141,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=136),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/136]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 142.0 in stage 5.0 (TID 545, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@664fe7bf
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 5.0 (TID 541) in 299 ms on localhost (executor driver) (139/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 142.0 in stage 5.0 (TID 545)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,140,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 5.0 (TID 539). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 143.0 in stage 5.0 (TID 546, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 5.0 (TID 539) in 309 ms on localhost (executor driver) (140/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 143.0 in stage 5.0 (TID 546)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dc52d1f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@534dabe2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7247762f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,142,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f7519f8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,725][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c7de7e2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6abdf0a5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,143,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,730][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d6a9af
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9fbf04
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd6c8bd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,742][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c476e52
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a2a2da4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ccbc27a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,748][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1571767e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6233bf7c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@99ff993
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b2522c8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75797b54
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a4ee2d8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c6bc163
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e9a8f44
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@87f018
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d229af2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fe02cec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35ea78fb
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.3.delta.e9623ee9-e1df-4546-be4c-cda09b776fb4.TID544.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a52496e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,779][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63cea7dc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d977005
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bdcfaec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.3.delta.d4d9ece5-411a-4ca1-829b-dbbac1fb5542.TID543.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.3.delta.3fb324cb-8a3d-4c10-98d1-21eeea6b39f0.TID546.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.3.delta.f300d201-4d07-407f-9555-cb97c50ac3e9.TID545.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43ddd1c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55bb6e20
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@532a3bca
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f9da0d9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42633f3b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ca79339
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e51050c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.3.delta.e9623ee9-e1df-4546-be4c-cda09b776fb4.TID544.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 141 (task 544, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 141 (task 544, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,893][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.3.delta.f300d201-4d07-407f-9555-cb97c50ac3e9.TID545.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,894][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 142 (task 545, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 142 (task 545, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.3.delta.3fb324cb-8a3d-4c10-98d1-21eeea6b39f0.TID546.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.3.delta.d4d9ece5-411a-4ca1-829b-dbbac1fb5542.TID543.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 143 (task 546, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 143 (task 546, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 140 (task 543, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 140 (task 543, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141/.3.delta.cae31211-5709-4c4c-b57d-c37c079c4251.TID544.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=141),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/141]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 5.0 (TID 544). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 144.0 in stage 5.0 (TID 547, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 5.0 (TID 544) in 231 ms on localhost (executor driver) (141/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 144.0 in stage 5.0 (TID 547)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ee633e4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69aecf61
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,144,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142/.3.delta.8e3ec463-0ce9-4aca-b6e9-bd4a1e474128.TID545.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=142),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/142]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 5.0 (TID 545). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 145.0 in stage 5.0 (TID 548, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 145.0 in stage 5.0 (TID 548)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 5.0 (TID 545) in 244 ms on localhost (executor driver) (142/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@487a1cff
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6392c496
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,145,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143/.3.delta.bf8732f8-3dca-493f-a433-ab98d46d228c.TID546.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140/.3.delta.da6d12b7-bfda-4741-bc8c-c363371aae3a.TID543.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=143),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/143]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=140),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/140]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 5.0 (TID 546). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 5.0 (TID 543). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 146.0 in stage 5.0 (TID 549, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 147.0 in stage 5.0 (TID 550, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 146.0 in stage 5.0 (TID 549)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 5.0 (TID 546) in 256 ms on localhost (executor driver) (143/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 147.0 in stage 5.0 (TID 550)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 5.0 (TID 543) in 266 ms on localhost (executor driver) (144/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31c15fb4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64943386
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,146,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,982][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@295dbcbd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b25e129
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,147,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:41,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cc8ff77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.3.delta.3f7e3749-6565-41a2-811e-9f642fc47f01.TID547.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17098b32
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.3.delta.0543a906-3def-4492-afe4-fc14e3402a45.TID548.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6747ecb1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21f8fc30
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ac09c3f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71cbc24e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29b19aa2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fceead8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6141b67a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.3.delta.107d5059-5c12-4524-a64a-c3777e9fcd32.TID549.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e37d1ae
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b762640
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.3.delta.ed432bb6-b2e6-49cf-b480-ef920d73cfa0.TID550.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@535689dc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fc817aa
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f020b5c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@151c60da
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e313cc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de93f7d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52ee9d77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.3.delta.3f7e3749-6565-41a2-811e-9f642fc47f01.TID547.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 144 (task 547, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24022d40
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 144 (task 547, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e95277f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a43fb07
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce0da1d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19bd8aec
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e74e87b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bfaaf71
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.3.delta.0543a906-3def-4492-afe4-fc14e3402a45.TID548.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,124][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4160b021
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 145 (task 548, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 145 (task 548, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34ffb80b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.3.delta.107d5059-5c12-4524-a64a-c3777e9fcd32.TID549.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d91b9df
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 146 (task 549, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 146 (task 549, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@532e123b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,136][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@178b41c7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.3.delta.ed432bb6-b2e6-49cf-b480-ef920d73cfa0.TID550.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e7d9cdd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 147 (task 550, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 147 (task 550, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ec2998c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,142][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d5eeba5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509614b0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@623ff10b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@481b0a39
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144/.3.delta.31cc8f82-409c-4e15-a9c7-04cb16efe1b3.TID547.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=144),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/144]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 5.0 (TID 547). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 148.0 in stage 5.0 (TID 551, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 5.0 (TID 547) in 220 ms on localhost (executor driver) (145/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 148.0 in stage 5.0 (TID 551)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22f2c35c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f2bc76
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42217026
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c1195b9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,148,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f0b66c0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd1f5da
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145/.3.delta.13a7e097-7680-4d70-8bb6-88df86c2577f.TID548.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=145),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/145]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b0d375f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 5.0 (TID 548). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 149.0 in stage 5.0 (TID 552, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 5.0 (TID 548) in 216 ms on localhost (executor driver) (146/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 149.0 in stage 5.0 (TID 552)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd3ea33
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146/.3.delta.a138d759-5fb5-4995-9c8c-83675961feab.TID549.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c8a2306
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,149,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=146),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/146]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147/.3.delta.69dccd3e-5d41-4f90-980e-f21dd44f5a53.TID550.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32e4d858
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 5.0 (TID 549). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 150.0 in stage 5.0 (TID 553, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=147),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/147]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 5.0 (TID 549) in 209 ms on localhost (executor driver) (147/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 150.0 in stage 5.0 (TID 553)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 5.0 (TID 550). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 151.0 in stage 5.0 (TID 554, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 5.0 (TID 550) in 211 ms on localhost (executor driver) (148/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 151.0 in stage 5.0 (TID 554)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,189][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@292654a7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@216e23fd
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@365d85a2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@222dad77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,191][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,150,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b3333d0
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,151,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76e2c996
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,204][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6447bfda
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70758d12
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a5f662b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a91b48f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.3.delta.3f45c3a2-a78c-442e-a9f4-ad66d166f5e5.TID551.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13716b68
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fb06909
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e0f20ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59fdda68
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@414fc014
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.3.delta.31bb2f14-22de-407b-b29e-f680a29b4f5e.TID552.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.3.delta.1cf7fe44-a8d7-4ec9-9a7b-ef300dd0197b.TID554.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dfb1115
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a946830
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.3.delta.68a219c4-a0d6-4c7f-85c4-9ca6afdfb387.TID553.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d8dd190
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62fdf555
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@375b33a6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e471895
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d75479c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40af443a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e07998a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68c2bf6f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f6c4c4c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3558570f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,281][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@270143e7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ac5b9af
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.3.delta.3f45c3a2-a78c-442e-a9f4-ad66d166f5e5.TID551.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 148 (task 551, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 148 (task 551, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.3.delta.31bb2f14-22de-407b-b29e-f680a29b4f5e.TID552.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 149 (task 552, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 149 (task 552, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.3.delta.1cf7fe44-a8d7-4ec9-9a7b-ef300dd0197b.TID554.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 151 (task 554, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 151 (task 554, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.3.delta.68a219c4-a0d6-4c7f-85c4-9ca6afdfb387.TID553.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37a68097
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit authorized for partition 150 (task 553, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed partition 150 (task 553, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40315943
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,346][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d0224d9
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,348][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1afdf017
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148/.3.delta.036e7334-bd31-48ac-90c1-89fe7cf61c25.TID551.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=148),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/148]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 5.0 (TID 551). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 152.0 in stage 5.0 (TID 555, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 5.0 (TID 551) in 191 ms on localhost (executor driver) (149/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 152.0 in stage 5.0 (TID 555)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19dc69e7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32814ac1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1995723
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,152,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,361][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@536dc0de
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb51286
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149/.3.delta.65b83bec-e8c2-4f83-a6e6-56348d9e6ef9.TID552.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a3d222f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,368][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=149),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/149]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 5.0 (TID 552). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 153.0 in stage 5.0 (TID 556, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 5.0 (TID 552) in 194 ms on localhost (executor driver) (150/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 153.0 in stage 5.0 (TID 556)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151/.3.delta.eb4a30f3-9e39-48c9-bb22-5aef1f06ea4b.TID554.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=151),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/151]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 5.0 (TID 554). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 154.0 in stage 5.0 (TID 557, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d4fbde
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 5.0 (TID 554) in 189 ms on localhost (executor driver) (151/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 154.0 in stage 5.0 (TID 557)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10f6ca4b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5602a133
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,153,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25df4d8e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b8cae5e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,154,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150/.3.delta.9d4154a3-18b8-4de0-a45c-b2dcaf2c175d.TID553.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d02b42a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=150),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/150]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 5.0 (TID 553). 4979 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 155.0 in stage 5.0 (TID 558, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 5.0 (TID 553) in 207 ms on localhost (executor driver) (152/200)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,392][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 155.0 in stage 5.0 (TID 558)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2313eb44
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37bcc1ea
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state,0,155,default),dfd1489f-ab85-4006-996b-815ebec09125) is active
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] for update
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aa4b42e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29bbd10f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eb6c5ed
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@261d97f5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19a742dc
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,415][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ee3db4e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7662e2d2
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c8a71d4
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f18653b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f51f43d
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e44ff77
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612f2bba
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dc2ab19
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dd25080
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7444a30a
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c2e24c3
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@441cd03c
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b85ce6f
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,432][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a8860e6
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@479d5f48
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6522fab7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,435][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40f1b6ca
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,437][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59676162
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74ad1219
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@628b979
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ba20890
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,442][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29ac1cf7
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@350dfe01
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@762d7aa8
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d901a75
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,448][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6492f094
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,450][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eb5f7f1
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@235022b5
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ebec718
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d5b800b
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c40ea2e
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,457][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e273899
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,458][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3659a042
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.3.delta.6bcf547f-0286-4e20-929c-e0a3c6ec8850.TID556.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,587][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.3.delta.c94a2772-950e-4afd-8b4f-038f47e45a07.TID555.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.3.delta.05f6732b-2bb0-4b60-9ff4-d595603d0963.TID557.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.3.delta.6e14e08b-89d5-42db-b262-665be43f352f.TID558.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Invoking stop() from shutdown hook
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Stopped Spark web UI at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 4 failed: start at StreamingFile.scala:61, took 10,280928 s
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 5 (start at StreamingFile.scala:61) failed in 10,089 s due to Stage cancelled because SparkContext was shut down
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@13cfade is aborting.
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@13cfade aborted.
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MapOutputTrackerMasterEndpoint stopped!
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Query [id = eeb06daf-41d7-4c11-830a-51392556e50b, runId = dfd1489f-ab85-4006-996b-815ebec09125] terminated with error
org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:92)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:296)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3384)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2783)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2783)
	at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2783)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5$$anonfun$apply$17.apply(MicroBatchExecution.scala:537)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5.apply(MicroBatchExecution.scala:532)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:531)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:198)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:279)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Caused by: org.apache.spark.SparkException: Job 4 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:932)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2126)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2039)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:64)
	... 35 common frames omitted
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.3.delta.6bcf547f-0286-4e20-929c-e0a3c6ec8850.TID556.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit denied for partition 153 (task 556, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,899][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 153 (task 556, attempt 0stage 5.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting commit for partition 153 (task 556, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborted commit for partition 153 (task 556, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.3.delta.c94a2772-950e-4afd-8b4f-038f47e45a07.TID555.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.3.delta.6e14e08b-89d5-42db-b262-665be43f352f.TID558.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit denied for partition 152 (task 555, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 152 (task 555, attempt 0stage 5.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting commit for partition 152 (task 555, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborted commit for partition 152 (task 555, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit denied for partition 155 (task 558, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 155 (task 558, attempt 0stage 5.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting commit for partition 155 (task 558, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborted commit for partition 155 (task 558, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Renamed temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.3.delta.05f6732b-2bb0-4b60-9ff4-d595603d0963.TID557.tmp to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Committed version 3 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154] to file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/3.delta
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Commit denied for partition 154 (task 557, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 154 (task 557, attempt 0stage 5.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborting commit for partition 154 (task 557, attempt 0stage 5.0)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,926][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Aborted commit for partition 154 (task 557, attempt 0stage 5.0)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155/.3.delta.3854e185-4abe-4961-939c-6b015cb7c330.TID558.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=155),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/155]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152/.3.delta.286a42d1-fe4c-4ec7-8c1f-d42004824daa.TID555.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 156.0 in stage 5.0 (TID 559, localhost, executor driver, partition 156, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,961][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=152),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/152]
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@15a6bfdf rejected from java.util.concurrent.ThreadPoolExecutor@6cf7f217[Shutting down, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 556]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 157.0 in stage 5.0 (TID 560, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
[1;31m[ERROR][0;39m [35m[2019-05-02 11:06:42,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logError][0;39m | Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@4704b770 rejected from java.util.concurrent.ThreadPoolExecutor@6cf7f217[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 557]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153/.3.delta.3b3dcf78-c7e2-416e-9805-713f195ce877.TID556.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=153),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/153]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore cleared
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManager stopped
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMaster stopped
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Writing atomically to file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/3.delta using temp file file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154/.3.delta.3a774b77-6b68-4ca2-81ee-6d795899f983.TID557.tmp
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Aborted version 3 for HDFSStateStore[id=(op=0,part=154),dir=file:/private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502/state/0/154]
[34m[INFO ][0;39m [35m[2019-05-02 11:06:42,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | OutputCommitCoordinator stopped!
[34m[INFO ][0;39m [35m[2019-05-02 11:06:43,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully stopped SparkContext
[34m[INFO ][0;39m [35m[2019-05-02 11:06:43,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Shutdown hook called
[34m[INFO ][0;39m [35m[2019-05-02 11:06:43,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Deleting directory /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/spark-eddaa0ac-7cd8-4e5b-84b9-7c84c518a5df
[34m[INFO ][0;39m [35m[2019-05-02 11:06:43,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Deleting directory /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/temporary-a09d51ab-22f1-4ded-9d5c-8843789ee502
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running Spark version 2.4.0
[31m[WARN ][0;39m [35m[2019-05-02 15:40:43,559][0;39m [33m[][0;39m [35m[org.apache.hadoop.util.NativeCodeLoader-><clinit>][0;39m | Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitted application: Spark Structured Streaming Job
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:43,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eiti); groups with view permissions: Set(); users  with modify permissions: Set(eiti); groups with modify permissions: Set()
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'sparkDriver' on port 57159.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering MapOutputTracker
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManagerMaster
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMasterEndpoint up
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created local directory at /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/blockmgr-dd710b76-ea1b-4fc7-99e7-863a3d353db1
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,647][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore started with capacity 912.3 MB
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering OutputCommitCoordinator
[34m[INFO ][0;39m [35m[2019-05-02 15:40:44,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'SparkUI' on port 4040.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Bound SparkUI to 0.0.0.0, and started at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting executor ID driver on host localhost
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57161.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Server created on mac-180:57161
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,284][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManager BlockManagerId(driver, mac-180, 57161, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering block manager mac-180:57161 with 912.3 MB RAM, BlockManagerId(driver, mac-180, 57161, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered BlockManager BlockManagerId(driver, mac-180, 57161, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Initialized BlockManager: BlockManagerId(driver, mac-180, 57161, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/').
[34m[INFO ][0;39m [35m[2019-05-02 15:40:45,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Warehouse path is 'file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/'.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:46,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered StateStoreCoordinator endpoint
[34m[INFO ][0;39m [35m[2019-05-02 15:40:49,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:49,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:49,079][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<name: string, country: string, city: string, phone: string, age: int ... 5 more fields>
[34m[INFO ][0;39m [35m[2019-05-02 15:40:49,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:49,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 461.36519 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 47.528826 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0 stored as values in memory (estimated size 221.8 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_0_piece0 in memory on mac-180:57161 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 0 from show at SparkSQL.scala:42
[34m[INFO ][0;39m [35m[2019-05-02 15:40:50,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<carrier: string, marital_status: string>
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 18.152737 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 26.437086 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 42.367164 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 67.885102 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1 stored as values in memory (estimated size 221.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_1_piece0 in memory on mac-180:57161 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 1 from show at SparkSQL.scala:55
[34m[INFO ][0;39m [35m[2019-05-02 15:40:51,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: show at SparkSQL.scala:55
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering RDD 6 (show at SparkSQL.scala:55)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 0 (show at SparkSQL.scala:55) with 200 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 1 (show at SparkSQL.scala:55)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List(ShuffleMapStage 0)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List()
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 1 (MapPartitionsRDD[10] at show at SparkSQL.scala:55), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2 stored as values in memory (estimated size 27.3 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,295][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.6 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_2_piece0 in memory on mac-180:57161 (size: 13.6 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,299][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 2 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 200 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at show at SparkSQL.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 1.0 with 200 tasks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 1.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 1.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 1.0 (TID 3)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 1.0 (TID 0)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 1.0 (TID 2)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,401][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 1.0 (TID 1)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 9 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 9 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 9 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,543][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 9.743567 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,569][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 14.667355 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 15.10008 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 1). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 3). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 0). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 2). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 4.0 in stage 1.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 5.0 in stage 1.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,681][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 4.0 in stage 1.0 (TID 4)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,683][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 6.0 in stage 1.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 7.0 in stage 1.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 5.0 in stage 1.0 (TID 5)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 7.0 in stage 1.0 (TID 7)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 6.0 in stage 1.0 (TID 6)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 2) in 305 ms on localhost (executor driver) (1/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 1) in 312 ms on localhost (executor driver) (2/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 3) in 311 ms on localhost (executor driver) (3/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 0) in 327 ms on localhost (executor driver) (4/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 1.0 (TID 7). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 1.0 (TID 5). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 8.0 in stage 1.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 9.0 in stage 1.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 8.0 in stage 1.0 (TID 8)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,718][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 1.0 (TID 7) in 34 ms on localhost (executor driver) (5/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,719][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 1.0 (TID 5) in 38 ms on localhost (executor driver) (6/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 9.0 in stage 1.0 (TID 9)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 1.0 (TID 4). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 10.0 in stage 1.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 10.0 in stage 1.0 (TID 10)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 1.0 (TID 4) in 46 ms on localhost (executor driver) (7/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,763][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 1.0 (TID 9). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 7 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 11.0 in stage 1.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,776][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 11.0 in stage 1.0 (TID 11)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 1.0 (TID 9) in 62 ms on localhost (executor driver) (8/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 1.0 (TID 6). 4314 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 12.0 in stage 1.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 1.0 (TID 10). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 5
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 13.0 in stage 1.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,787][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 1.0 (TID 8). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 12.0 in stage 1.0 (TID 12)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 1.0 (TID 6) in 106 ms on localhost (executor driver) (9/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 13.0 in stage 1.0 (TID 13)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 14.0 in stage 1.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 1.0 (TID 10) in 69 ms on localhost (executor driver) (10/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 1.0 (TID 8) in 78 ms on localhost (executor driver) (11/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 14.0 in stage 1.0 (TID 14)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 1.0 (TID 11). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 15.0 in stage 1.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,803][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 15.0 in stage 1.0 (TID 15)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,807][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 1.0 (TID 12). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 16.0 in stage 1.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,810][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 1.0 (TID 13). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 17.0 in stage 1.0 (TID 17, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 1.0 (TID 11) in 38 ms on localhost (executor driver) (12/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 1.0 (TID 12) in 28 ms on localhost (executor driver) (13/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 1.0 (TID 13) in 26 ms on localhost (executor driver) (14/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 16.0 in stage 1.0 (TID 16)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,815][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 17.0 in stage 1.0 (TID 17)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 1.0 (TID 14). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 18.0 in stage 1.0 (TID 18, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 18.0 in stage 1.0 (TID 18)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 1.0 (TID 14) in 33 ms on localhost (executor driver) (15/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,830][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 1.0 (TID 15). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 19.0 in stage 1.0 (TID 19, localhost, executor driver, partition 19, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 19.0 in stage 1.0 (TID 19)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 1.0 (TID 15) in 30 ms on localhost (executor driver) (16/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,840][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 1.0 (TID 18). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 1.0 (TID 17). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 20.0 in stage 1.0 (TID 20, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 21.0 in stage 1.0 (TID 21, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,849][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 21.0 in stage 1.0 (TID 21)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 20.0 in stage 1.0 (TID 20)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,851][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 1.0 (TID 17) in 41 ms on localhost (executor driver) (17/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 1.0 (TID 18) in 35 ms on localhost (executor driver) (18/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,862][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 1.0 (TID 16). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 22.0 in stage 1.0 (TID 22, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 1.0 (TID 16) in 58 ms on localhost (executor driver) (19/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 1.0 (TID 21). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 23.0 in stage 1.0 (TID 23, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 23.0 in stage 1.0 (TID 23)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 1.0 (TID 21) in 27 ms on localhost (executor driver) (20/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 22.0 in stage 1.0 (TID 22)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 1.0 (TID 20). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 24.0 in stage 1.0 (TID 24, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 1.0 (TID 20) in 39 ms on localhost (executor driver) (21/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 1.0 (TID 19). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 25.0 in stage 1.0 (TID 25, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 25.0 in stage 1.0 (TID 25)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,888][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 1.0 (TID 19) in 58 ms on localhost (executor driver) (22/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 24.0 in stage 1.0 (TID 24)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 1.0 (TID 22). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,895][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 26.0 in stage 1.0 (TID 26, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 26.0 in stage 1.0 (TID 26)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 1.0 (TID 22) in 33 ms on localhost (executor driver) (23/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,901][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,902][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,903][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 1.0 (TID 23). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 1.0 (TID 25). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,904][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 27.0 in stage 1.0 (TID 27, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 27.0 in stage 1.0 (TID 27)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,908][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 1.0 (TID 24). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,908][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 1.0 (TID 23) in 36 ms on localhost (executor driver) (24/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 28.0 in stage 1.0 (TID 28, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 1.0 (TID 26). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 29.0 in stage 1.0 (TID 29, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,910][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 28.0 in stage 1.0 (TID 28)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 29.0 in stage 1.0 (TID 29)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 30.0 in stage 1.0 (TID 30, localhost, executor driver, partition 30, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 1.0 (TID 25) in 28 ms on localhost (executor driver) (25/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 1.0 (TID 26) in 20 ms on localhost (executor driver) (26/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 1.0 (TID 24) in 33 ms on localhost (executor driver) (27/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,916][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 30.0 in stage 1.0 (TID 30)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 1.0 (TID 27). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 31.0 in stage 1.0 (TID 31, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 31.0 in stage 1.0 (TID 31)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 1.0 (TID 27) in 20 ms on localhost (executor driver) (28/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 1.0 (TID 29). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 32.0 in stage 1.0 (TID 32, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 32.0 in stage 1.0 (TID 32)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,933][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 1.0 (TID 29) in 23 ms on localhost (executor driver) (29/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 1.0 (TID 31). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 33.0 in stage 1.0 (TID 33, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 33.0 in stage 1.0 (TID 33)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 1.0 (TID 30). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 1.0 (TID 31) in 16 ms on localhost (executor driver) (30/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 34.0 in stage 1.0 (TID 34, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 34.0 in stage 1.0 (TID 34)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 1.0 (TID 30) in 34 ms on localhost (executor driver) (31/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 1.0 (TID 32). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 35.0 in stage 1.0 (TID 35, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 35.0 in stage 1.0 (TID 35)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 1.0 (TID 32) in 21 ms on localhost (executor driver) (32/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 1.0 (TID 33). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 36.0 in stage 1.0 (TID 36, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 36.0 in stage 1.0 (TID 36)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 1.0 (TID 33) in 24 ms on localhost (executor driver) (33/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 1.0 (TID 28). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 1.0 (TID 35). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 37.0 in stage 1.0 (TID 37, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 38.0 in stage 1.0 (TID 38, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 37.0 in stage 1.0 (TID 37)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 1.0 (TID 28) in 57 ms on localhost (executor driver) (34/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 1.0 (TID 35) in 19 ms on localhost (executor driver) (35/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,974][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 1.0 (TID 36). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,975][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 39.0 in stage 1.0 (TID 39, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 39.0 in stage 1.0 (TID 39)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 1.0 (TID 36) in 23 ms on localhost (executor driver) (36/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 38.0 in stage 1.0 (TID 38)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 1.0 (TID 37). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 40.0 in stage 1.0 (TID 40, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 40.0 in stage 1.0 (TID 40)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 1.0 (TID 37) in 21 ms on localhost (executor driver) (37/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,991][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 1.0 (TID 39). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 41.0 in stage 1.0 (TID 41, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 41.0 in stage 1.0 (TID 41)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 1.0 (TID 39) in 20 ms on localhost (executor driver) (38/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 1.0 (TID 38). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 1.0 (TID 40). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:52,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 42.0 in stage 1.0 (TID 42, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 42.0 in stage 1.0 (TID 42)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,002][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 43.0 in stage 1.0 (TID 43, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 1.0 (TID 38) in 39 ms on localhost (executor driver) (39/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 1.0 (TID 40) in 23 ms on localhost (executor driver) (40/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 43.0 in stage 1.0 (TID 43)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 1.0 (TID 34). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 44.0 in stage 1.0 (TID 44, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 1.0 (TID 34) in 72 ms on localhost (executor driver) (41/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,017][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 1.0 (TID 41). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 45.0 in stage 1.0 (TID 45, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 44.0 in stage 1.0 (TID 44)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 45.0 in stage 1.0 (TID 45)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 1.0 (TID 41) in 28 ms on localhost (executor driver) (42/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 1.0 (TID 43). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 46.0 in stage 1.0 (TID 46, localhost, executor driver, partition 46, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 1.0 (TID 45). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 47.0 in stage 1.0 (TID 47, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 1.0 (TID 43) in 36 ms on localhost (executor driver) (43/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 47.0 in stage 1.0 (TID 47)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 1.0 (TID 45) in 22 ms on localhost (executor driver) (44/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 1.0 (TID 44). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 48.0 in stage 1.0 (TID 48, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 1.0 (TID 44) in 34 ms on localhost (executor driver) (45/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 46.0 in stage 1.0 (TID 46)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 48.0 in stage 1.0 (TID 48)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 1.0 (TID 47). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 49.0 in stage 1.0 (TID 49, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 49.0 in stage 1.0 (TID 49)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 1.0 (TID 47) in 30 ms on localhost (executor driver) (46/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 1.0 (TID 46). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 1.0 (TID 48). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 50.0 in stage 1.0 (TID 50, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 51.0 in stage 1.0 (TID 51, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 1.0 (TID 46) in 39 ms on localhost (executor driver) (47/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 50.0 in stage 1.0 (TID 50)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 51.0 in stage 1.0 (TID 51)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 1.0 (TID 48) in 32 ms on localhost (executor driver) (48/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 1.0 (TID 42). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 1.0 (TID 50). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 1.0 (TID 51). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 52.0 in stage 1.0 (TID 52, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 53.0 in stage 1.0 (TID 53, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 54.0 in stage 1.0 (TID 54, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 1.0 (TID 42) in 101 ms on localhost (executor driver) (49/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 52.0 in stage 1.0 (TID 52)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 1.0 (TID 50) in 27 ms on localhost (executor driver) (50/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 53.0 in stage 1.0 (TID 53)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 1.0 (TID 51) in 27 ms on localhost (executor driver) (51/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 1.0 (TID 49). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 55.0 in stage 1.0 (TID 55, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 1.0 (TID 49) in 43 ms on localhost (executor driver) (52/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 54.0 in stage 1.0 (TID 54)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 55.0 in stage 1.0 (TID 55)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 1.0 (TID 52). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 56.0 in stage 1.0 (TID 56, localhost, executor driver, partition 56, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 56.0 in stage 1.0 (TID 56)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 1.0 (TID 52) in 23 ms on localhost (executor driver) (53/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 1.0 (TID 55). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 1.0 (TID 54). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 57.0 in stage 1.0 (TID 57, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 58.0 in stage 1.0 (TID 58, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 1.0 (TID 55) in 29 ms on localhost (executor driver) (54/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 1.0 (TID 54) in 39 ms on localhost (executor driver) (55/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 58.0 in stage 1.0 (TID 58)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 57.0 in stage 1.0 (TID 57)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 1.0 (TID 53). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 59.0 in stage 1.0 (TID 59, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 1.0 (TID 53) in 54 ms on localhost (executor driver) (56/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 59.0 in stage 1.0 (TID 59)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 1.0 (TID 58). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 60.0 in stage 1.0 (TID 60, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 60.0 in stage 1.0 (TID 60)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 1.0 (TID 58) in 26 ms on localhost (executor driver) (57/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 1.0 (TID 56). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 61.0 in stage 1.0 (TID 61, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 1.0 (TID 56) in 49 ms on localhost (executor driver) (58/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 61.0 in stage 1.0 (TID 61)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 1.0 (TID 57). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 62.0 in stage 1.0 (TID 62, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 1.0 (TID 57) in 42 ms on localhost (executor driver) (59/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 62.0 in stage 1.0 (TID 62)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 1.0 (TID 60). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 63.0 in stage 1.0 (TID 63, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 1.0 (TID 60) in 28 ms on localhost (executor driver) (60/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 1.0 (TID 59). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 63.0 in stage 1.0 (TID 63)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 64.0 in stage 1.0 (TID 64, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 1.0 (TID 59) in 45 ms on localhost (executor driver) (61/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 64.0 in stage 1.0 (TID 64)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 1.0 (TID 62). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 65.0 in stage 1.0 (TID 65, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,202][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 1.0 (TID 62) in 34 ms on localhost (executor driver) (62/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 65.0 in stage 1.0 (TID 65)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 1.0 (TID 63). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 1.0 (TID 64). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 66.0 in stage 1.0 (TID 66, localhost, executor driver, partition 66, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 1.0 (TID 61). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 67.0 in stage 1.0 (TID 67, localhost, executor driver, partition 67, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 66.0 in stage 1.0 (TID 66)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,211][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 68.0 in stage 1.0 (TID 68, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,212][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 67.0 in stage 1.0 (TID 67)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,212][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,213][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 1.0 (TID 63) in 33 ms on localhost (executor driver) (63/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,213][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 68.0 in stage 1.0 (TID 68)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,214][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,215][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 1.0 (TID 64) in 30 ms on localhost (executor driver) (64/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,218][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 1.0 (TID 61) in 58 ms on localhost (executor driver) (65/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 1.0 (TID 65). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 69.0 in stage 1.0 (TID 69, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 69.0 in stage 1.0 (TID 69)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,228][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 1.0 (TID 65) in 29 ms on localhost (executor driver) (66/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,233][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 1.0 (TID 66). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,233][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 1.0 (TID 67). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,234][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 70.0 in stage 1.0 (TID 70, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 71.0 in stage 1.0 (TID 71, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,235][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 1.0 (TID 68). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 71.0 in stage 1.0 (TID 71)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 70.0 in stage 1.0 (TID 70)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,237][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 1.0 (TID 66) in 31 ms on localhost (executor driver) (67/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 72.0 in stage 1.0 (TID 72, localhost, executor driver, partition 72, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 1.0 (TID 67) in 30 ms on localhost (executor driver) (68/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 1.0 (TID 68) in 31 ms on localhost (executor driver) (69/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 72.0 in stage 1.0 (TID 72)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,247][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 1.0 (TID 71). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 73.0 in stage 1.0 (TID 73, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,253][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 73.0 in stage 1.0 (TID 73)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 1.0 (TID 71) in 19 ms on localhost (executor driver) (70/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 1.0 (TID 72). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 74.0 in stage 1.0 (TID 74, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,256][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 1.0 (TID 70). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 75.0 in stage 1.0 (TID 75, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 74.0 in stage 1.0 (TID 74)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 1.0 (TID 72) in 19 ms on localhost (executor driver) (71/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 75.0 in stage 1.0 (TID 75)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,259][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 1.0 (TID 69). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 1.0 (TID 70) in 28 ms on localhost (executor driver) (72/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,264][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,266][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 76.0 in stage 1.0 (TID 76, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,267][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 76.0 in stage 1.0 (TID 76)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,270][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 1.0 (TID 69) in 44 ms on localhost (executor driver) (73/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 1.0 (TID 75). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 77.0 in stage 1.0 (TID 77, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 77.0 in stage 1.0 (TID 77)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 1.0 (TID 75) in 26 ms on localhost (executor driver) (74/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,286][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 1.0 (TID 73). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 78.0 in stage 1.0 (TID 78, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,289][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 1.0 (TID 73) in 38 ms on localhost (executor driver) (75/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 78.0 in stage 1.0 (TID 78)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 1.0 (TID 76). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 79.0 in stage 1.0 (TID 79, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,297][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 1.0 (TID 74). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,298][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 1.0 (TID 77). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,300][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 1.0 (TID 76) in 33 ms on localhost (executor driver) (76/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 79.0 in stage 1.0 (TID 79)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 80.0 in stage 1.0 (TID 80, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,304][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 81.0 in stage 1.0 (TID 81, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 81.0 in stage 1.0 (TID 81)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 1.0 (TID 74) in 50 ms on localhost (executor driver) (77/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,306][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 1.0 (TID 77) in 26 ms on localhost (executor driver) (78/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,307][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 1.0 (TID 78). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,308][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 80.0 in stage 1.0 (TID 80)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 82.0 in stage 1.0 (TID 82, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 82.0 in stage 1.0 (TID 82)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 1.0 (TID 78) in 27 ms on localhost (executor driver) (79/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 1.0 (TID 79). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,317][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 83.0 in stage 1.0 (TID 83, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 1.0 (TID 79) in 22 ms on localhost (executor driver) (80/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 83.0 in stage 1.0 (TID 83)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 1.0 (TID 81). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 84.0 in stage 1.0 (TID 84, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 84.0 in stage 1.0 (TID 84)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 1.0 (TID 81) in 20 ms on localhost (executor driver) (81/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 1.0 (TID 80). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 85.0 in stage 1.0 (TID 85, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 85.0 in stage 1.0 (TID 85)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 1.0 (TID 80) in 26 ms on localhost (executor driver) (82/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 1.0 (TID 82). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 86.0 in stage 1.0 (TID 86, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 1.0 (TID 83). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,342][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 87.0 in stage 1.0 (TID 87, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 1.0 (TID 82) in 33 ms on localhost (executor driver) (83/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,343][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 87.0 in stage 1.0 (TID 87)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 1.0 (TID 83) in 27 ms on localhost (executor driver) (84/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 86.0 in stage 1.0 (TID 86)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,349][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 1.0 (TID 84). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 1.0 (TID 85). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 88.0 in stage 1.0 (TID 88, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,360][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 89.0 in stage 1.0 (TID 89, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 89.0 in stage 1.0 (TID 89)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,363][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 1.0 (TID 85) in 37 ms on localhost (executor driver) (85/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 1.0 (TID 84) in 41 ms on localhost (executor driver) (86/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 88.0 in stage 1.0 (TID 88)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 1.0 (TID 86). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 90.0 in stage 1.0 (TID 90, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 1.0 (TID 86) in 33 ms on localhost (executor driver) (87/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 90.0 in stage 1.0 (TID 90)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 1.0 (TID 87). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 91.0 in stage 1.0 (TID 91, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 1.0 (TID 88). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 1.0 (TID 87) in 35 ms on localhost (executor driver) (88/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 91.0 in stage 1.0 (TID 91)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 92.0 in stage 1.0 (TID 92, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 92.0 in stage 1.0 (TID 92)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 1.0 (TID 88) in 23 ms on localhost (executor driver) (89/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 1.0 (TID 89). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 93.0 in stage 1.0 (TID 93, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 93.0 in stage 1.0 (TID 93)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 1.0 (TID 89) in 31 ms on localhost (executor driver) (90/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,392][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 1.0 (TID 90). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 94.0 in stage 1.0 (TID 94, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 1.0 (TID 92). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 94.0 in stage 1.0 (TID 94)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 95.0 in stage 1.0 (TID 95, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 1.0 (TID 90) in 32 ms on localhost (executor driver) (91/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 1.0 (TID 92) in 27 ms on localhost (executor driver) (92/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 95.0 in stage 1.0 (TID 95)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,406][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,407][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 1.0 (TID 93). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 96.0 in stage 1.0 (TID 96, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 96.0 in stage 1.0 (TID 96)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 1.0 (TID 91). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 97.0 in stage 1.0 (TID 97, localhost, executor driver, partition 97, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 1.0 (TID 93) in 23 ms on localhost (executor driver) (93/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 1.0 (TID 91) in 37 ms on localhost (executor driver) (94/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 97.0 in stage 1.0 (TID 97)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 1.0 (TID 94). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 98.0 in stage 1.0 (TID 98, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 98.0 in stage 1.0 (TID 98)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 1.0 (TID 94) in 23 ms on localhost (executor driver) (95/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 1.0 (TID 96). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 99.0 in stage 1.0 (TID 99, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 99.0 in stage 1.0 (TID 99)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 1.0 (TID 96) in 15 ms on localhost (executor driver) (96/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,425][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 1.0 (TID 97). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,426][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 100.0 in stage 1.0 (TID 100, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,427][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 100.0 in stage 1.0 (TID 100)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 1.0 (TID 97) in 18 ms on localhost (executor driver) (97/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,443][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 1.0 (TID 99). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 101.0 in stage 1.0 (TID 101, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,444][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 101.0 in stage 1.0 (TID 101)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 1.0 (TID 99) in 25 ms on localhost (executor driver) (98/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 1.0 (TID 100). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 102.0 in stage 1.0 (TID 102, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,455][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 102.0 in stage 1.0 (TID 102)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 1.0 (TID 100) in 30 ms on localhost (executor driver) (99/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 1.0 (TID 95). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 103.0 in stage 1.0 (TID 103, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,459][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,461][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 1.0 (TID 95) in 61 ms on localhost (executor driver) (100/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,464][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 1.0 (TID 98). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,465][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 104.0 in stage 1.0 (TID 104, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 103.0 in stage 1.0 (TID 103)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 1.0 (TID 98) in 49 ms on localhost (executor driver) (101/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 1.0 (TID 102). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 105.0 in stage 1.0 (TID 105, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 105.0 in stage 1.0 (TID 105)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 1.0 (TID 102) in 17 ms on localhost (executor driver) (102/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,471][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 104.0 in stage 1.0 (TID 104)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,480][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 1.0 (TID 103). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 106.0 in stage 1.0 (TID 106, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,482][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 106.0 in stage 1.0 (TID 106)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 1.0 (TID 103) in 24 ms on localhost (executor driver) (103/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,496][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 1.0 (TID 104). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,497][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 107.0 in stage 1.0 (TID 107, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 1.0 (TID 104) in 35 ms on localhost (executor driver) (104/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,500][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 107.0 in stage 1.0 (TID 107)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 1.0 (TID 101). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 108.0 in stage 1.0 (TID 108, localhost, executor driver, partition 108, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,507][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,509][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 1.0 (TID 101) in 65 ms on localhost (executor driver) (105/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 1.0 (TID 106). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 108.0 in stage 1.0 (TID 108)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 109.0 in stage 1.0 (TID 109, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 1.0 (TID 106) in 33 ms on localhost (executor driver) (106/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 109.0 in stage 1.0 (TID 109)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,515][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 1.0 (TID 107). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,516][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 110.0 in stage 1.0 (TID 110, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 110.0 in stage 1.0 (TID 110)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 1.0 (TID 107) in 21 ms on localhost (executor driver) (107/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 1.0 (TID 105). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,523][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 111.0 in stage 1.0 (TID 111, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,524][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 1.0 (TID 105) in 56 ms on localhost (executor driver) (108/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,526][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 111.0 in stage 1.0 (TID 111)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 1.0 (TID 109). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,529][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 1.0 (TID 108). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,530][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 112.0 in stage 1.0 (TID 112, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 113.0 in stage 1.0 (TID 113, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,531][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 112.0 in stage 1.0 (TID 112)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,532][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 113.0 in stage 1.0 (TID 113)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 1.0 (TID 108) in 27 ms on localhost (executor driver) (109/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,533][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 1.0 (TID 109) in 21 ms on localhost (executor driver) (110/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,535][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,538][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 1.0 (TID 111). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 114.0 in stage 1.0 (TID 114, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 114.0 in stage 1.0 (TID 114)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 1.0 (TID 112). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 1.0 (TID 111) in 25 ms on localhost (executor driver) (111/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,567][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 1.0 (TID 114). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 1.0 (TID 113). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,572][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 1.0 (TID 110). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 115.0 in stage 1.0 (TID 115, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 115.0 in stage 1.0 (TID 115)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 116.0 in stage 1.0 (TID 116, localhost, executor driver, partition 116, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,575][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 117.0 in stage 1.0 (TID 117, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 118.0 in stage 1.0 (TID 118, localhost, executor driver, partition 118, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 1.0 (TID 112) in 48 ms on localhost (executor driver) (112/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 1.0 (TID 110) in 63 ms on localhost (executor driver) (113/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,579][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 1.0 (TID 114) in 34 ms on localhost (executor driver) (114/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,580][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 1.0 (TID 113) in 49 ms on localhost (executor driver) (115/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 117.0 in stage 1.0 (TID 117)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,581][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,590][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 1.0 (TID 115). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 119.0 in stage 1.0 (TID 119, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 119.0 in stage 1.0 (TID 119)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 1.0 (TID 115) in 21 ms on localhost (executor driver) (116/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,600][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 116.0 in stage 1.0 (TID 116)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,602][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 1.0 (TID 119). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 120.0 in stage 1.0 (TID 120, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 120.0 in stage 1.0 (TID 120)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,604][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 1.0 (TID 119) in 13 ms on localhost (executor driver) (117/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 118.0 in stage 1.0 (TID 118)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 1.0 (TID 116). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 1.0 (TID 117). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,619][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 121.0 in stage 1.0 (TID 121, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 122.0 in stage 1.0 (TID 122, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 122.0 in stage 1.0 (TID 122)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 1.0 (TID 117) in 48 ms on localhost (executor driver) (118/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 121.0 in stage 1.0 (TID 121)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 1.0 (TID 116) in 50 ms on localhost (executor driver) (119/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 1.0 (TID 118). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 123.0 in stage 1.0 (TID 123, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,641][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 1.0 (TID 121). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 124.0 in stage 1.0 (TID 124, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,643][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 1.0 (TID 118) in 67 ms on localhost (executor driver) (120/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 123.0 in stage 1.0 (TID 123)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 1.0 (TID 121) in 25 ms on localhost (executor driver) (121/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,644][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 124.0 in stage 1.0 (TID 124)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 1.0 (TID 122). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 125.0 in stage 1.0 (TID 125, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,652][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 1.0 (TID 120). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,657][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 1.0 (TID 122) in 37 ms on localhost (executor driver) (122/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 1.0 (TID 123). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,658][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 125.0 in stage 1.0 (TID 125)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,660][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 126.0 in stage 1.0 (TID 126, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,662][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 1.0 (TID 124). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 127.0 in stage 1.0 (TID 127, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,665][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 128.0 in stage 1.0 (TID 128, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,666][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 126.0 in stage 1.0 (TID 126)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 1.0 (TID 123) in 26 ms on localhost (executor driver) (123/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 1.0 (TID 124) in 25 ms on localhost (executor driver) (124/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,668][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 1.0 (TID 120) in 66 ms on localhost (executor driver) (125/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,669][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 127.0 in stage 1.0 (TID 127)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 128.0 in stage 1.0 (TID 128)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 1.0 (TID 126). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 129.0 in stage 1.0 (TID 129, localhost, executor driver, partition 129, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 1.0 (TID 126) in 24 ms on localhost (executor driver) (126/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 1.0 (TID 127). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 129.0 in stage 1.0 (TID 129)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 130.0 in stage 1.0 (TID 130, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 130.0 in stage 1.0 (TID 130)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 1.0 (TID 125). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,687][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 1.0 (TID 127) in 24 ms on localhost (executor driver) (127/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 131.0 in stage 1.0 (TID 131, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 1.0 (TID 125) in 39 ms on localhost (executor driver) (128/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 131.0 in stage 1.0 (TID 131)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,694][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 1.0 (TID 129). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,704][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 132.0 in stage 1.0 (TID 132, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 1.0 (TID 129) in 24 ms on localhost (executor driver) (129/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 132.0 in stage 1.0 (TID 132)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 1.0 (TID 130). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 133.0 in stage 1.0 (TID 133, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 133.0 in stage 1.0 (TID 133)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 1.0 (TID 130) in 26 ms on localhost (executor driver) (130/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 1.0 (TID 128). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 134.0 in stage 1.0 (TID 134, localhost, executor driver, partition 134, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,713][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 1.0 (TID 128) in 50 ms on localhost (executor driver) (131/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 134.0 in stage 1.0 (TID 134)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,720][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 1.0 (TID 132). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 135.0 in stage 1.0 (TID 135, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,721][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 135.0 in stage 1.0 (TID 135)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,723][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 1.0 (TID 132) in 19 ms on localhost (executor driver) (132/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 1.0 (TID 131). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,729][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 1.0 (TID 134). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 136.0 in stage 1.0 (TID 136, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 137.0 in stage 1.0 (TID 137, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,735][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 1.0 (TID 135). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 138.0 in stage 1.0 (TID 138, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 136.0 in stage 1.0 (TID 136)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 1.0 (TID 134) in 25 ms on localhost (executor driver) (133/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,736][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 137.0 in stage 1.0 (TID 137)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,738][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 1.0 (TID 131) in 50 ms on localhost (executor driver) (134/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 138.0 in stage 1.0 (TID 138)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 1.0 (TID 135) in 19 ms on localhost (executor driver) (135/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 1.0 (TID 138). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 1.0 (TID 133). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 1.0 (TID 136). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 139.0 in stage 1.0 (TID 139, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 140.0 in stage 1.0 (TID 140, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,761][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 141.0 in stage 1.0 (TID 141, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 1.0 (TID 138) in 28 ms on localhost (executor driver) (136/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 1.0 (TID 137). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 1.0 (TID 133) in 57 ms on localhost (executor driver) (137/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 1.0 (TID 136) in 35 ms on localhost (executor driver) (138/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,768][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 142.0 in stage 1.0 (TID 142, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,768][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 142.0 in stage 1.0 (TID 142)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,770][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 1.0 (TID 137) in 37 ms on localhost (executor driver) (139/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 140.0 in stage 1.0 (TID 140)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 139.0 in stage 1.0 (TID 139)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 1.0 (TID 142). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,782][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 143.0 in stage 1.0 (TID 143, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 143.0 in stage 1.0 (TID 143)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 1.0 (TID 142) in 16 ms on localhost (executor driver) (140/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 1.0 (TID 139). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,794][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 144.0 in stage 1.0 (TID 144, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 1.0 (TID 139) in 39 ms on localhost (executor driver) (141/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 1.0 (TID 143). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 145.0 in stage 1.0 (TID 145, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 144.0 in stage 1.0 (TID 144)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 145.0 in stage 1.0 (TID 145)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 1.0 (TID 140). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,799][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 1.0 (TID 143) in 17 ms on localhost (executor driver) (142/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,800][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 146.0 in stage 1.0 (TID 146, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,801][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 146.0 in stage 1.0 (TID 146)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 1.0 (TID 140) in 43 ms on localhost (executor driver) (143/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,805][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,811][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 1.0 (TID 145). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 147.0 in stage 1.0 (TID 147, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 147.0 in stage 1.0 (TID 147)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 1.0 (TID 145) in 17 ms on localhost (executor driver) (144/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 1.0 (TID 146). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 148.0 in stage 1.0 (TID 148, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,819][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,821][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 1.0 (TID 146) in 21 ms on localhost (executor driver) (145/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 148.0 in stage 1.0 (TID 148)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 1.0 (TID 144). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 149.0 in stage 1.0 (TID 149, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 149.0 in stage 1.0 (TID 149)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 1.0 (TID 144) in 33 ms on localhost (executor driver) (146/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,827][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 1.0 (TID 147). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 150.0 in stage 1.0 (TID 150, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 1.0 (TID 147) in 19 ms on localhost (executor driver) (147/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 150.0 in stage 1.0 (TID 150)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,839][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,843][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,844][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 1.0 (TID 149). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,845][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 151.0 in stage 1.0 (TID 151, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,846][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 151.0 in stage 1.0 (TID 151)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,847][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 1.0 (TID 150). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 152.0 in stage 1.0 (TID 152, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,848][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 152.0 in stage 1.0 (TID 152)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 1.0 (TID 149) in 26 ms on localhost (executor driver) (148/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,850][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 1.0 (TID 150) in 22 ms on localhost (executor driver) (149/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,854][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 1.0 (TID 152). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 1.0 (TID 148). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 153.0 in stage 1.0 (TID 153, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 141.0 in stage 1.0 (TID 141)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 1.0 (TID 151). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 153.0 in stage 1.0 (TID 153)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 154.0 in stage 1.0 (TID 154, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 155.0 in stage 1.0 (TID 155, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 155.0 in stage 1.0 (TID 155)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 154.0 in stage 1.0 (TID 154)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 1.0 (TID 152) in 22 ms on localhost (executor driver) (150/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,872][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 1.0 (TID 148) in 53 ms on localhost (executor driver) (151/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,875][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 1.0 (TID 151) in 30 ms on localhost (executor driver) (152/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 1.0 (TID 155). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,880][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 156.0 in stage 1.0 (TID 156, localhost, executor driver, partition 156, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 156.0 in stage 1.0 (TID 156)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 1.0 (TID 154). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 1.0 (TID 155) in 17 ms on localhost (executor driver) (153/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,883][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 157.0 in stage 1.0 (TID 157, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 157.0 in stage 1.0 (TID 157)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 1.0 (TID 154) in 21 ms on localhost (executor driver) (154/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,889][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 1.0 (TID 156). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,897][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 158.0 in stage 1.0 (TID 158, localhost, executor driver, partition 158, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,898][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 158.0 in stage 1.0 (TID 158)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 1.0 (TID 156) in 19 ms on localhost (executor driver) (155/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,900][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 1.0 (TID 157). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,901][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 159.0 in stage 1.0 (TID 159, localhost, executor driver, partition 159, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 159.0 in stage 1.0 (TID 159)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,905][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 1.0 (TID 157) in 22 ms on localhost (executor driver) (156/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,906][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 1.0 (TID 158). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 160.0 in stage 1.0 (TID 160, localhost, executor driver, partition 160, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 160.0 in stage 1.0 (TID 160)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,917][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 1.0 (TID 158) in 20 ms on localhost (executor driver) (157/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 1.0 (TID 159). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 161.0 in stage 1.0 (TID 161, localhost, executor driver, partition 161, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 161.0 in stage 1.0 (TID 161)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 1.0 (TID 159) in 21 ms on localhost (executor driver) (158/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,928][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 1.0 (TID 160). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 162.0 in stage 1.0 (TID 162, localhost, executor driver, partition 162, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 162.0 in stage 1.0 (TID 162)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 1.0 (TID 160) in 21 ms on localhost (executor driver) (159/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 1.0 (TID 161). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 163.0 in stage 1.0 (TID 163, localhost, executor driver, partition 163, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,936][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 163.0 in stage 1.0 (TID 163)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 1.0 (TID 161) in 19 ms on localhost (executor driver) (160/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,939][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 1.0 (TID 141). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 164.0 in stage 1.0 (TID 164, localhost, executor driver, partition 164, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 164.0 in stage 1.0 (TID 164)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 1.0 (TID 141) in 187 ms on localhost (executor driver) (161/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 1.0 (TID 162). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 1.0 (TID 163). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 165.0 in stage 1.0 (TID 165, localhost, executor driver, partition 165, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 166.0 in stage 1.0 (TID 166, localhost, executor driver, partition 166, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 165.0 in stage 1.0 (TID 165)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 166.0 in stage 1.0 (TID 166)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 1.0 (TID 163) in 18 ms on localhost (executor driver) (162/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 1.0 (TID 162) in 22 ms on localhost (executor driver) (163/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 1.0 (TID 166). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 167.0 in stage 1.0 (TID 167, localhost, executor driver, partition 167, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 1.0 (TID 165). 4314 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 167.0 in stage 1.0 (TID 167)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,979][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 168.0 in stage 1.0 (TID 168, localhost, executor driver, partition 168, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 1.0 (TID 166) in 28 ms on localhost (executor driver) (164/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,980][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 168.0 in stage 1.0 (TID 168)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,981][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 1.0 (TID 165) in 31 ms on localhost (executor driver) (165/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 1.0 (TID 164). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 169.0 in stage 1.0 (TID 169, localhost, executor driver, partition 169, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 169.0 in stage 1.0 (TID 169)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 1.0 (TID 164) in 40 ms on localhost (executor driver) (166/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,990][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 1.0 (TID 153). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 1.0 (TID 168). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 170.0 in stage 1.0 (TID 170, localhost, executor driver, partition 170, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 171.0 in stage 1.0 (TID 171, localhost, executor driver, partition 171, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 170.0 in stage 1.0 (TID 170)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 1.0 (TID 168) in 16 ms on localhost (executor driver) (167/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 1.0 (TID 153) in 132 ms on localhost (executor driver) (168/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 171.0 in stage 1.0 (TID 171)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:53,999][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,003][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 1.0 (TID 170). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 172.0 in stage 1.0 (TID 172, localhost, executor driver, partition 172, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 172.0 in stage 1.0 (TID 172)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 1.0 (TID 170) in 16 ms on localhost (executor driver) (169/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 1.0 (TID 171). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 173.0 in stage 1.0 (TID 173, localhost, executor driver, partition 173, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 1.0 (TID 171) in 19 ms on localhost (executor driver) (170/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 1.0 (TID 169). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 174.0 in stage 1.0 (TID 174, localhost, executor driver, partition 174, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 1.0 (TID 167). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 174.0 in stage 1.0 (TID 174)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 173.0 in stage 1.0 (TID 173)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 175.0 in stage 1.0 (TID 175, localhost, executor driver, partition 175, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 1.0 (TID 169) in 34 ms on localhost (executor driver) (171/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 1.0 (TID 167) in 41 ms on localhost (executor driver) (172/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,021][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 175.0 in stage 1.0 (TID 175)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,023][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 1.0 (TID 174). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,032][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 176.0 in stage 1.0 (TID 176, localhost, executor driver, partition 176, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 1.0 (TID 174) in 21 ms on localhost (executor driver) (173/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 1.0 (TID 175). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,037][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 177.0 in stage 1.0 (TID 177, localhost, executor driver, partition 177, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 1.0 (TID 173). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 178.0 in stage 1.0 (TID 178, localhost, executor driver, partition 178, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 176.0 in stage 1.0 (TID 176)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 177.0 in stage 1.0 (TID 177)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 1.0 (TID 172). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 1.0 (TID 175) in 23 ms on localhost (executor driver) (174/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 178.0 in stage 1.0 (TID 178)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 1.0 (TID 173) in 31 ms on localhost (executor driver) (175/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,044][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 179.0 in stage 1.0 (TID 179, localhost, executor driver, partition 179, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 179.0 in stage 1.0 (TID 179)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 1.0 (TID 172) in 42 ms on localhost (executor driver) (176/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 1.0 (TID 177). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 180.0 in stage 1.0 (TID 180, localhost, executor driver, partition 180, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 1.0 (TID 176). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 181.0 in stage 1.0 (TID 181, localhost, executor driver, partition 181, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,070][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 1.0 (TID 177) in 33 ms on localhost (executor driver) (177/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 180.0 in stage 1.0 (TID 180)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 1.0 (TID 178). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 182.0 in stage 1.0 (TID 182, localhost, executor driver, partition 182, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 181.0 in stage 1.0 (TID 181)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 1.0 (TID 176) in 41 ms on localhost (executor driver) (178/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 1.0 (TID 179). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 1.0 (TID 178) in 35 ms on localhost (executor driver) (179/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,074][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 182.0 in stage 1.0 (TID 182)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 183.0 in stage 1.0 (TID 183, localhost, executor driver, partition 183, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 1.0 (TID 179) in 33 ms on localhost (executor driver) (180/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 183.0 in stage 1.0 (TID 183)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 1.0 (TID 180). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 184.0 in stage 1.0 (TID 184, localhost, executor driver, partition 184, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 1.0 (TID 180) in 18 ms on localhost (executor driver) (181/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 1.0 (TID 181). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 184.0 in stage 1.0 (TID 184)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 1.0 (TID 182). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 185.0 in stage 1.0 (TID 185, localhost, executor driver, partition 185, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 186.0 in stage 1.0 (TID 186, localhost, executor driver, partition 186, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 1.0 (TID 183). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 185.0 in stage 1.0 (TID 185)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 187.0 in stage 1.0 (TID 187, localhost, executor driver, partition 187, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 186.0 in stage 1.0 (TID 186)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 1.0 (TID 181) in 22 ms on localhost (executor driver) (182/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 187.0 in stage 1.0 (TID 187)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 1.0 (TID 182) in 22 ms on localhost (executor driver) (183/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 1.0 (TID 183) in 21 ms on localhost (executor driver) (184/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 1.0 (TID 184). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 188.0 in stage 1.0 (TID 188, localhost, executor driver, partition 188, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 1.0 (TID 185). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 1.0 (TID 184) in 23 ms on localhost (executor driver) (185/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 189.0 in stage 1.0 (TID 189, localhost, executor driver, partition 189, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 1.0 (TID 186). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 190.0 in stage 1.0 (TID 190, localhost, executor driver, partition 190, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 1.0 (TID 185) in 22 ms on localhost (executor driver) (186/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 188.0 in stage 1.0 (TID 188)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 189.0 in stage 1.0 (TID 189)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 1.0 (TID 187). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 1.0 (TID 186) in 20 ms on localhost (executor driver) (187/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 190.0 in stage 1.0 (TID 190)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 191.0 in stage 1.0 (TID 191, localhost, executor driver, partition 191, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 1.0 (TID 187) in 26 ms on localhost (executor driver) (188/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 191.0 in stage 1.0 (TID 191)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 1.0 (TID 189). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 192.0 in stage 1.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 1.0 (TID 190). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 193.0 in stage 1.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 1.0 (TID 189) in 22 ms on localhost (executor driver) (189/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 1.0 (TID 188). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 1.0 (TID 190) in 23 ms on localhost (executor driver) (190/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 193.0 in stage 1.0 (TID 193)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 192.0 in stage 1.0 (TID 192)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,130][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 1.0 (TID 191). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,131][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 194.0 in stage 1.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,144][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 195.0 in stage 1.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 194.0 in stage 1.0 (TID 194)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 1.0 (TID 188) in 44 ms on localhost (executor driver) (191/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 195.0 in stage 1.0 (TID 195)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 1.0 (TID 193). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 1.0 (TID 191) in 43 ms on localhost (executor driver) (192/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 1.0 (TID 192). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 196.0 in stage 1.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,160][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 197.0 in stage 1.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 1.0 (TID 193) in 36 ms on localhost (executor driver) (193/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 1.0 (TID 194). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 1.0 (TID 192) in 40 ms on localhost (executor driver) (194/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 198.0 in stage 1.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 196.0 in stage 1.0 (TID 196)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,170][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 1.0 (TID 194) in 39 ms on localhost (executor driver) (195/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 197.0 in stage 1.0 (TID 197)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 1.0 (TID 195). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 199.0 in stage 1.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 199.0 in stage 1.0 (TID 199)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 198.0 in stage 1.0 (TID 198)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 1.0 (TID 195) in 28 ms on localhost (executor driver) (196/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 9 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 7 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 1.0 (TID 196). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 1.0 (TID 196) in 32 ms on localhost (executor driver) (197/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,192][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 1.0 (TID 197). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 1.0 (TID 199). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,194][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 1.0 (TID 198). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 1.0 (TID 197) in 33 ms on localhost (executor driver) (198/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,195][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 1.0 (TID 199) in 22 ms on localhost (executor driver) (199/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,196][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 1.0 (TID 198) in 28 ms on localhost (executor driver) (200/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 1.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,200][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 1 (show at SparkSQL.scala:55) finished in 1,928 s
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 0 finished: show at SparkSQL.scala:55, took 2,025004 s
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 10.235679 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,230][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Invoking stop() from shutdown hook
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,252][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Stopped Spark web UI at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MapOutputTrackerMasterEndpoint stopped!
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore cleared
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManager stopped
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMaster stopped
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | OutputCommitCoordinator stopped!
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,376][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully stopped SparkContext
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Shutdown hook called
[34m[INFO ][0;39m [35m[2019-05-02 15:40:54,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Deleting directory /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/spark-d47d250a-a8e3-40d1-853e-efe101c52a8f
[34m[INFO ][0;39m [35m[2019-05-02 15:41:37,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running Spark version 2.4.0
[31m[WARN ][0;39m [35m[2019-05-02 15:41:38,386][0;39m [33m[][0;39m [35m[org.apache.hadoop.util.NativeCodeLoader-><clinit>][0;39m | Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitted application: Spark Structured Streaming Job
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls to: eiti
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing view acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Changing modify acls groups to: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:38,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eiti); groups with view permissions: Set(); users  with modify permissions: Set(eiti); groups with modify permissions: Set()
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'sparkDriver' on port 57170.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering MapOutputTracker
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManagerMaster
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,206][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMasterEndpoint up
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created local directory at /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/blockmgr-564eb8dd-bde9-48cd-9e53-91230b9bad73
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore started with capacity 912.3 MB
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering OutputCommitCoordinator
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'SparkUI' on port 4040.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,519][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Bound SparkUI to 0.0.0.0, and started at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting executor ID driver on host localhost
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57171.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Server created on mac-180:57171
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,744][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering BlockManager BlockManagerId(driver, mac-180, 57171, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering block manager mac-180:57171 with 912.3 MB RAM, BlockManagerId(driver, mac-180, 57171, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered BlockManager BlockManagerId(driver, mac-180, 57171, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:39,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Initialized BlockManager: BlockManagerId(driver, mac-180, 57171, None)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:40,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/').
[34m[INFO ][0;39m [35m[2019-05-02 15:41:40,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Warehouse path is 'file:/Users/eiti/git-repository/structured-streaming/spark-warehouse/'.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:40,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registered StateStoreCoordinator endpoint
[34m[INFO ][0;39m [35m[2019-05-02 15:41:42,610][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:42,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:42,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<name: string, country: string, city: string, phone: string, age: int ... 5 more fields>
[34m[INFO ][0;39m [35m[2019-05-02 15:41:42,624][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 249.253714 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,522][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 50.597375 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0 stored as values in memory (estimated size 221.8 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,709][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 912.1 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,712][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_0_piece0 in memory on mac-180:57171 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,715][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 0 from show at SparkSQL.scala:42
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,753][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 10502883 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: show at SparkSQL.scala:42
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 0 (show at SparkSQL.scala:42) with 1 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 0 (show at SparkSQL.scala:42)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List()
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List()
[34m[INFO ][0;39m [35m[2019-05-02 15:41:43,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkSQL.scala:42), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1 stored as values in memory (estimated size 13.8 KB, free 912.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 912.0 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_1_piece0 in memory on mac-180:57171 (size: 7.2 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 1 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkSQL.scala:42) (first 15 tasks are for partitions Vector(0))
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 0.0 with 1 tasks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8605 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 0.0 (TID 0)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.7.csv, range: 0-6975, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 28.852285 ms
[31m[WARN ][0;39m [35m[2019-05-02 15:41:44,292][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logWarning][0;39m | CSV header does not conform to the schema.
 Header: id, country, city, phone, age, carrier, marital_status
 Schema: name, country, city, phone, age, carrier, marital_status
Expected: name but found: id
CSV file: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.7.csv
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 0.0 (TID 0). 3339 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,344][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 0.0 (TID 0) in 260 ms on localhost (executor driver) (1/1)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,347][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 0.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 0 (show at SparkSQL.scala:42) finished in 0,386 s
[34m[INFO ][0;39m [35m[2019-05-02 15:41:44,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 0 finished: show at SparkSQL.scala:42, took 0,435021 s
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pruning directories with: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,025][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Post-Scan Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,026][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Output Data Schema: struct<carrier: string, marital_status: string>
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,027][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Pushed Filters: 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 30.806391 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 15.903236 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 51.137269 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 100.588145 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2 stored as values in memory (estimated size 221.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_2_piece0 in memory on mac-180:57171 (size: 20.7 KB, free: 912.3 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,391][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 2 from show at SparkSQL.scala:55
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Planning scan with bin packing, max size: 10502883 bytes, open cost is considered as scanning 4194304 bytes.
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,502][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting job: show at SparkSQL.scala:55
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Registering RDD 6 (show at SparkSQL.scala:55)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Got job 1 (show at SparkSQL.scala:55) with 200 output partitions
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Final stage: ResultStage 2 (show at SparkSQL.scala:55)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Parents of final stage: List(ShuffleMapStage 1)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Missing parents: List(ShuffleMapStage 1)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at show at SparkSQL.scala:55), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,520][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_3 stored as values in memory (estimated size 29.0 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.7 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_3_piece0 in memory on mac-180:57171 (size: 13.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,548][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 3 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at show at SparkSQL.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,554][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 1.0 with 4 tasks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8594 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 8594 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 16
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 8595 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,560][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 8356 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 1.0 (TID 1)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,561][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 1.0 (TID 2)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 1.0 (TID 4)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 1.0 (TID 3)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,588][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed broadcast_1_piece0 on mac-180:57171 in memory (size: 7.2 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 10
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 15
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 12
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 18
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 9
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 30
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 28
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 27
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 17
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 5
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 13
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 21
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 8.41996 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 25
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 7
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 24
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 8
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 22
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 23
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,596][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 14
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 26
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 6
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 11
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 19
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 20
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Cleaned accumulator 29
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 9.073104 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 8.780766 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 17.932746 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.5.csv, range: 0-6897, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.8.csv, range: 0-6714, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.7.csv, range: 0-6975, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.4.csv, range: 0-6819, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.6.csv, range: 0-6934, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.10.csv, range: 0-6789, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,745][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.2.csv, range: 0-6869, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.3.csv, range: 0-6907, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.1.csv, range: 0-6730, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Reading File path: file:///Users/eiti/git-repository/structured-streaming/dataset/raw_data/user-record.9.csv, range: 0-6858, partition values: [empty row]
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 4). 2395 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 1). 2352 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,885][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 1.0 (TID 4) in 325 ms on localhost (executor driver) (1/4)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,886][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 1.0 (TID 1) in 330 ms on localhost (executor driver) (2/4)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,888][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 3). 2352 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,890][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 1.0 (TID 3) in 331 ms on localhost (executor driver) (3/4)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,907][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 2). 2352 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 1.0 (TID 2) in 350 ms on localhost (executor driver) (4/4)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,909][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 1.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,911][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ShuffleMapStage 1 (show at SparkSQL.scala:55) finished in 0,396 s
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,912][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | looking for newly runnable stages
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | running: Set()
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,914][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | waiting: Set(ResultStage 2)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | failed: Set()
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting ResultStage 2 (MapPartitionsRDD[10] at show at SparkSQL.scala:55), which has no missing parents
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_4 stored as values in memory (estimated size 28.2 KB, free 911.8 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.8 KB, free 911.7 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Added broadcast_4_piece0 in memory on mac-180:57171 (size: 13.8 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Created broadcast 4 from broadcast at DAGScheduler.scala:1161
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at show at SparkSQL.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,958][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Adding task set 2.0 with 200 tasks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 2.0 in stage 2.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 3.0 in stage 2.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,966][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 4.0 in stage 2.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 2.0 in stage 2.0 (TID 6)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 1.0 in stage 2.0 (TID 5)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 3.0 in stage 2.0 (TID 7)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 4.0 in stage 2.0 (TID 8)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,994][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:45,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,033][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 2.0 (TID 7). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 5.0 in stage 2.0 (TID 9, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,034][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 2.0 (TID 8). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 2.0 (TID 5). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 5.0 in stage 2.0 (TID 9)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 2.0 (TID 6). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 6.0 in stage 2.0 (TID 10, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 3.0 in stage 2.0 (TID 7) in 73 ms on localhost (executor driver) (1/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,038][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 7.0 in stage 2.0 (TID 11, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 4.0 in stage 2.0 (TID 8) in 74 ms on localhost (executor driver) (2/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 7.0 in stage 2.0 (TID 11)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 8.0 in stage 2.0 (TID 12, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 6.0 in stage 2.0 (TID 10)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 1.0 in stage 2.0 (TID 5) in 78 ms on localhost (executor driver) (3/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,043][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 2.0 in stage 2.0 (TID 6) in 78 ms on localhost (executor driver) (4/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 8.0 in stage 2.0 (TID 12)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,047][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,051][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 2.0 (TID 9). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,053][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,054][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 9.0 in stage 2.0 (TID 13, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 2.0 (TID 11). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 10.0 in stage 2.0 (TID 14, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 9.0 in stage 2.0 (TID 13)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 5.0 in stage 2.0 (TID 9) in 23 ms on localhost (executor driver) (5/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 2.0 (TID 10). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 11.0 in stage 2.0 (TID 15, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,063][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 2.0 (TID 12). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 10.0 in stage 2.0 (TID 14)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,064][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 7.0 in stage 2.0 (TID 11) in 26 ms on localhost (executor driver) (6/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 11.0 in stage 2.0 (TID 15)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,066][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 12.0 in stage 2.0 (TID 16, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 6.0 in stage 2.0 (TID 10) in 32 ms on localhost (executor driver) (7/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 12.0 in stage 2.0 (TID 16)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 8.0 in stage 2.0 (TID 12) in 28 ms on localhost (executor driver) (8/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,080][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,085][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 2.0 (TID 14). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 2.0 (TID 13). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 13.0 in stage 2.0 (TID 17, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 14.0 in stage 2.0 (TID 18, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,088][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 13.0 in stage 2.0 (TID 17)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 9.0 in stage 2.0 (TID 13) in 38 ms on localhost (executor driver) (9/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 14.0 in stage 2.0 (TID 18)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 10.0 in stage 2.0 (TID 14) in 34 ms on localhost (executor driver) (10/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 2.0 (TID 16). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 15.0 in stage 2.0 (TID 19, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 15.0 in stage 2.0 (TID 19)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,097][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 2.0 (TID 15). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 12.0 in stage 2.0 (TID 16) in 34 ms on localhost (executor driver) (11/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 16.0 in stage 2.0 (TID 20, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 16.0 in stage 2.0 (TID 20)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 11.0 in stage 2.0 (TID 15) in 40 ms on localhost (executor driver) (12/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 2.0 (TID 19). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,106][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 17.0 in stage 2.0 (TID 21, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 17.0 in stage 2.0 (TID 21)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 2.0 (TID 18). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,110][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 15.0 in stage 2.0 (TID 19) in 16 ms on localhost (executor driver) (13/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 18.0 in stage 2.0 (TID 22, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 2.0 (TID 17). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 20.0 in stage 2.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 18.0 in stage 2.0 (TID 22)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 14.0 in stage 2.0 (TID 18) in 27 ms on localhost (executor driver) (14/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 13.0 in stage 2.0 (TID 17) in 30 ms on localhost (executor driver) (15/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 20.0 in stage 2.0 (TID 23)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,119][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 2.0 (TID 21). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 21.0 in stage 2.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,123][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 21.0 in stage 2.0 (TID 24)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 2.0 (TID 20). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,126][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 17.0 in stage 2.0 (TID 21) in 20 ms on localhost (executor driver) (16/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 22.0 in stage 2.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 22.0 in stage 2.0 (TID 25)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,129][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 16.0 in stage 2.0 (TID 20) in 28 ms on localhost (executor driver) (17/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,137][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 2.0 (TID 24). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 23.0 in stage 2.0 (TID 26, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,139][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 23.0 in stage 2.0 (TID 26)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 21.0 in stage 2.0 (TID 24) in 19 ms on localhost (executor driver) (18/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,145][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 2.0 (TID 22). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,146][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 24.0 in stage 2.0 (TID 27, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,147][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 24.0 in stage 2.0 (TID 27)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 18.0 in stage 2.0 (TID 22) in 38 ms on localhost (executor driver) (19/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,149][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,150][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,153][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 2.0 (TID 23). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 2.0 (TID 27). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,157][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 25.0 in stage 2.0 (TID 28, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 2.0 (TID 26). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,162][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 26.0 in stage 2.0 (TID 29, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 25.0 in stage 2.0 (TID 28)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 27.0 in stage 2.0 (TID 30, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,165][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 26.0 in stage 2.0 (TID 29)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,168][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 2.0 (TID 25). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 20.0 in stage 2.0 (TID 23) in 56 ms on localhost (executor driver) (20/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 27.0 in stage 2.0 (TID 30)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 28.0 in stage 2.0 (TID 31, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 24.0 in stage 2.0 (TID 27) in 29 ms on localhost (executor driver) (21/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,175][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 23.0 in stage 2.0 (TID 26) in 38 ms on localhost (executor driver) (22/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 28.0 in stage 2.0 (TID 31)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,176][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 22.0 in stage 2.0 (TID 25) in 51 ms on localhost (executor driver) (23/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,178][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,180][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 2.0 (TID 28). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 29.0 in stage 2.0 (TID 32, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,185][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,186][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 25.0 in stage 2.0 (TID 28) in 30 ms on localhost (executor driver) (24/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,187][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 29.0 in stage 2.0 (TID 32)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,193][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 2.0 (TID 29). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,197][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 2.0 (TID 30). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,198][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 26.0 in stage 2.0 (TID 29) in 37 ms on localhost (executor driver) (25/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,199][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 31.0 in stage 2.0 (TID 33)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,201][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 27.0 in stage 2.0 (TID 30) in 36 ms on localhost (executor driver) (26/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,203][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 2.0 (TID 31). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,204][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,205][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 32.0 in stage 2.0 (TID 34)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,207][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,208][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 33.0 in stage 2.0 (TID 35)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 28.0 in stage 2.0 (TID 31) in 36 ms on localhost (executor driver) (27/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,209][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,210][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,216][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,217][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,219][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,220][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 2.0 (TID 33). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,221][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 2.0 (TID 34). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,222][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 34.0 in stage 2.0 (TID 36)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,223][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,224][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 31.0 in stage 2.0 (TID 33) in 28 ms on localhost (executor driver) (28/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,225][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 2.0 (TID 35). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,226][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 35.0 in stage 2.0 (TID 37)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 32.0 in stage 2.0 (TID 34) in 28 ms on localhost (executor driver) (29/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 2.0 (TID 32). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,227][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 36.0 in stage 2.0 (TID 38)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,229][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,231][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 33.0 in stage 2.0 (TID 35) in 27 ms on localhost (executor driver) (30/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,232][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,233][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 29.0 in stage 2.0 (TID 32) in 52 ms on localhost (executor driver) (31/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,236][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 37.0 in stage 2.0 (TID 39)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,238][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 2.0 (TID 36). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,239][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,240][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 2.0 (TID 37). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,241][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 38.0 in stage 2.0 (TID 40)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,242][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 34.0 in stage 2.0 (TID 36) in 21 ms on localhost (executor driver) (32/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 2.0 (TID 38). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,243][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,244][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,245][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,246][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 39.0 in stage 2.0 (TID 41)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,248][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 35.0 in stage 2.0 (TID 37) in 26 ms on localhost (executor driver) (33/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,249][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 40.0 in stage 2.0 (TID 42)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,250][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,251][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 36.0 in stage 2.0 (TID 38) in 25 ms on localhost (executor driver) (34/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,254][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 2.0 (TID 39). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,255][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,257][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 37.0 in stage 2.0 (TID 39) in 24 ms on localhost (executor driver) (35/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,258][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 41.0 in stage 2.0 (TID 43)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 2.0 (TID 40). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,260][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,261][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 42.0 in stage 2.0 (TID 44)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,265][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 38.0 in stage 2.0 (TID 40) in 26 ms on localhost (executor driver) (36/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,268][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 2.0 (TID 42). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,269][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,271][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 40.0 in stage 2.0 (TID 42) in 25 ms on localhost (executor driver) (37/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,273][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 43.0 in stage 2.0 (TID 45)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,275][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 2.0 (TID 41). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,276][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,277][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,278][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 39.0 in stage 2.0 (TID 41) in 34 ms on localhost (executor driver) (38/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,279][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 44.0 in stage 2.0 (TID 46)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,280][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,282][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 2.0 (TID 44). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 2.0 (TID 43). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,285][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,287][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,288][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 47.0 in stage 2.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 41.0 in stage 2.0 (TID 43) in 35 ms on localhost (executor driver) (39/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,290][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 47.0 in stage 2.0 (TID 48)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 42.0 in stage 2.0 (TID 44) in 30 ms on localhost (executor driver) (40/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 45.0 in stage 2.0 (TID 47)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,291][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,296][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 2.0 (TID 45). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 48.0 in stage 2.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,301][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,302][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 48.0 in stage 2.0 (TID 49)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,303][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 43.0 in stage 2.0 (TID 45) in 34 ms on localhost (executor driver) (41/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,305][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 2.0 (TID 46). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 2.0 (TID 48). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,313][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 49.0 in stage 2.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 50.0 in stage 2.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,315][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 2.0 (TID 47). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 44.0 in stage 2.0 (TID 46) in 41 ms on localhost (executor driver) (42/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 50.0 in stage 2.0 (TID 51)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 49.0 in stage 2.0 (TID 50)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 51.0 in stage 2.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 47.0 in stage 2.0 (TID 48) in 32 ms on localhost (executor driver) (43/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 2.0 (TID 49). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,321][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 45.0 in stage 2.0 (TID 47) in 34 ms on localhost (executor driver) (44/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 52.0 in stage 2.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 51.0 in stage 2.0 (TID 52)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 48.0 in stage 2.0 (TID 49) in 24 ms on localhost (executor driver) (45/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 52.0 in stage 2.0 (TID 53)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,326][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 2.0 (TID 51). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,330][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 2.0 (TID 50). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 53.0 in stage 2.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,331][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,332][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 54.0 in stage 2.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,333][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 53.0 in stage 2.0 (TID 54)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,334][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 54.0 in stage 2.0 (TID 55)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,341][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 50.0 in stage 2.0 (TID 51) in 26 ms on localhost (executor driver) (46/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,345][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 49.0 in stage 2.0 (TID 50) in 32 ms on localhost (executor driver) (47/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 2.0 (TID 53). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 55.0 in stage 2.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 2.0 (TID 52). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,353][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 55.0 in stage 2.0 (TID 56)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 52.0 in stage 2.0 (TID 53) in 33 ms on localhost (executor driver) (48/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,355][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,362][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 57.0 in stage 2.0 (TID 57, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 51.0 in stage 2.0 (TID 52) in 49 ms on localhost (executor driver) (49/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 57.0 in stage 2.0 (TID 57)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 2.0 (TID 54). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 2.0 (TID 56). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,370][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 58.0 in stage 2.0 (TID 58, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 2.0 (TID 55). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 59.0 in stage 2.0 (TID 59, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 58.0 in stage 2.0 (TID 58)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 53.0 in stage 2.0 (TID 54) in 42 ms on localhost (executor driver) (50/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 59.0 in stage 2.0 (TID 59)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,374][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 60.0 in stage 2.0 (TID 60, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,375][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 55.0 in stage 2.0 (TID 56) in 27 ms on localhost (executor driver) (51/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 60.0 in stage 2.0 (TID 60)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 54.0 in stage 2.0 (TID 55) in 49 ms on localhost (executor driver) (52/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,381][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,382][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 2.0 (TID 59). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 2.0 (TID 58). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 61.0 in stage 2.0 (TID 61, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,388][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 62.0 in stage 2.0 (TID 62, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,389][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 61.0 in stage 2.0 (TID 61)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 2.0 (TID 57). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,390][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 59.0 in stage 2.0 (TID 59) in 19 ms on localhost (executor driver) (53/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 63.0 in stage 2.0 (TID 63, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 58.0 in stage 2.0 (TID 58) in 25 ms on localhost (executor driver) (54/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,394][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 2.0 (TID 60). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 63.0 in stage 2.0 (TID 63)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 64.0 in stage 2.0 (TID 64, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,398][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 57.0 in stage 2.0 (TID 57) in 34 ms on localhost (executor driver) (55/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,399][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 64.0 in stage 2.0 (TID 64)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,400][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 60.0 in stage 2.0 (TID 60) in 26 ms on localhost (executor driver) (56/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,403][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 62.0 in stage 2.0 (TID 62)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,405][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,408][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 2.0 (TID 63). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,409][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 65.0 in stage 2.0 (TID 65, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,410][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 65.0 in stage 2.0 (TID 65)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,411][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 2.0 (TID 64). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 68.0 in stage 2.0 (TID 66, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 63.0 in stage 2.0 (TID 63) in 17 ms on localhost (executor driver) (57/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,413][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 68.0 in stage 2.0 (TID 66)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,414][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 64.0 in stage 2.0 (TID 64) in 17 ms on localhost (executor driver) (58/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,416][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,417][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 2.0 (TID 61). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,418][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,419][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 69.0 in stage 2.0 (TID 67, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,421][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 69.0 in stage 2.0 (TID 67)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,422][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 61.0 in stage 2.0 (TID 61) in 35 ms on localhost (executor driver) (59/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,423][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,424][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 2.0 (TID 66). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,428][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,429][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 70.0 in stage 2.0 (TID 68, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,430][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 70.0 in stage 2.0 (TID 68)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,431][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 68.0 in stage 2.0 (TID 66) in 20 ms on localhost (executor driver) (60/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,433][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 2.0 (TID 65). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,434][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 71.0 in stage 2.0 (TID 69, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 65.0 in stage 2.0 (TID 65) in 27 ms on localhost (executor driver) (61/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,436][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,438][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 2.0 (TID 62). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,439][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 73.0 in stage 2.0 (TID 70, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 71.0 in stage 2.0 (TID 69)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,441][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 62.0 in stage 2.0 (TID 62) in 53 ms on localhost (executor driver) (62/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,445][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 73.0 in stage 2.0 (TID 70)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,446][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 2.0 (TID 67). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,447][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 74.0 in stage 2.0 (TID 71, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,449][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 69.0 in stage 2.0 (TID 67) in 30 ms on localhost (executor driver) (63/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,451][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,452][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,453][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,454][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 74.0 in stage 2.0 (TID 71)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,467][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 2.0 (TID 69). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 75.0 in stage 2.0 (TID 72, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,468][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 75.0 in stage 2.0 (TID 72)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,470][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 71.0 in stage 2.0 (TID 69) in 37 ms on localhost (executor driver) (64/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 2.0 (TID 70). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,472][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 76.0 in stage 2.0 (TID 73, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,473][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 76.0 in stage 2.0 (TID 73)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,474][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,475][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 73.0 in stage 2.0 (TID 70) in 36 ms on localhost (executor driver) (65/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,477][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,479][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 4 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,481][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,483][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 2.0 (TID 71). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,484][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 2.0 (TID 68). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,485][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 77.0 in stage 2.0 (TID 74, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,486][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 2.0 (TID 72). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 78.0 in stage 2.0 (TID 75, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,487][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 2.0 (TID 73). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,488][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 77.0 in stage 2.0 (TID 74)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 79.0 in stage 2.0 (TID 76, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,489][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 78.0 in stage 2.0 (TID 75)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 80.0 in stage 2.0 (TID 77, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,492][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 79.0 in stage 2.0 (TID 76)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,495][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 74.0 in stage 2.0 (TID 71) in 49 ms on localhost (executor driver) (66/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 75.0 in stage 2.0 (TID 72) in 31 ms on localhost (executor driver) (67/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 76.0 in stage 2.0 (TID 73) in 26 ms on localhost (executor driver) (68/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,498][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 80.0 in stage 2.0 (TID 77)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,499][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 70.0 in stage 2.0 (TID 68) in 70 ms on localhost (executor driver) (69/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,501][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,503][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,504][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,505][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 2.0 (TID 75). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,506][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 2.0 (TID 74). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,508][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 81.0 in stage 2.0 (TID 78, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,510][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 82.0 in stage 2.0 (TID 79, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,511][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 2.0 (TID 76). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,512][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 83.0 in stage 2.0 (TID 80, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 77.0 in stage 2.0 (TID 74) in 28 ms on localhost (executor driver) (70/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 2.0 (TID 77). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 82.0 in stage 2.0 (TID 79)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 78.0 in stage 2.0 (TID 75) in 26 ms on localhost (executor driver) (71/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 83.0 in stage 2.0 (TID 80)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,513][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 81.0 in stage 2.0 (TID 78)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,514][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 84.0 in stage 2.0 (TID 81, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,517][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 79.0 in stage 2.0 (TID 76) in 29 ms on localhost (executor driver) (72/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 84.0 in stage 2.0 (TID 81)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,518][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 80.0 in stage 2.0 (TID 77) in 26 ms on localhost (executor driver) (73/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,525][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,539][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 13 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 2.0 (TID 81). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,541][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed broadcast_3_piece0 on mac-180:57171 in memory (size: 13.7 KB, free: 912.2 MB)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,542][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 85.0 in stage 2.0 (TID 82, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,544][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,545][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 85.0 in stage 2.0 (TID 82)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 84.0 in stage 2.0 (TID 81) in 32 ms on localhost (executor driver) (74/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 2.0 (TID 78). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,546][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,547][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 2.0 (TID 80). 4314 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,549][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 86.0 in stage 2.0 (TID 83, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,551][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 86.0 in stage 2.0 (TID 83)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,552][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 81.0 in stage 2.0 (TID 78) in 45 ms on localhost (executor driver) (75/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,553][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 87.0 in stage 2.0 (TID 84, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 87.0 in stage 2.0 (TID 84)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,559][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 83.0 in stage 2.0 (TID 80) in 47 ms on localhost (executor driver) (76/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,562][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 2.0 (TID 82). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 88.0 in stage 2.0 (TID 85, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,563][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,564][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 88.0 in stage 2.0 (TID 85)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,565][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,566][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 85.0 in stage 2.0 (TID 82) in 24 ms on localhost (executor driver) (77/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,570][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 2.0 (TID 84). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 89.0 in stage 2.0 (TID 86, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,571][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 89.0 in stage 2.0 (TID 86)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,573][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 87.0 in stage 2.0 (TID 84) in 16 ms on localhost (executor driver) (78/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,574][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 2.0 (TID 83). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,575][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 90.0 in stage 2.0 (TID 87, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,576][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 90.0 in stage 2.0 (TID 87)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 86.0 in stage 2.0 (TID 83) in 28 ms on localhost (executor driver) (79/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,577][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 2.0 (TID 79). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 2.0 (TID 86). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,582][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,583][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 91.0 in stage 2.0 (TID 88, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,584][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,585][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 92.0 in stage 2.0 (TID 89, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,585][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 91.0 in stage 2.0 (TID 88)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,589][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 82.0 in stage 2.0 (TID 79) in 79 ms on localhost (executor driver) (80/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,591][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 89.0 in stage 2.0 (TID 86) in 21 ms on localhost (executor driver) (81/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,592][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 92.0 in stage 2.0 (TID 89)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,593][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,594][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 2.0 (TID 87). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,595][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 93.0 in stage 2.0 (TID 90, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,597][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 90.0 in stage 2.0 (TID 87) in 22 ms on localhost (executor driver) (82/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 2.0 (TID 88). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,598][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 93.0 in stage 2.0 (TID 90)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,599][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 94.0 in stage 2.0 (TID 91, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,601][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 94.0 in stage 2.0 (TID 91)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,603][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 91.0 in stage 2.0 (TID 88) in 20 ms on localhost (executor driver) (83/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,605][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 2.0 (TID 89). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,606][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 95.0 in stage 2.0 (TID 92, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,607][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,609][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 92.0 in stage 2.0 (TID 89) in 24 ms on localhost (executor driver) (84/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,611][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 2.0 (TID 91). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 96.0 in stage 2.0 (TID 93, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 95.0 in stage 2.0 (TID 92)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,612][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 96.0 in stage 2.0 (TID 93)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,613][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 2.0 (TID 90). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,614][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 97.0 in stage 2.0 (TID 94, localhost, executor driver, partition 97, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 94.0 in stage 2.0 (TID 91) in 16 ms on localhost (executor driver) (85/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,615][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 97.0 in stage 2.0 (TID 94)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,616][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 93.0 in stage 2.0 (TID 90) in 21 ms on localhost (executor driver) (86/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,617][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,618][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 2.0 (TID 85). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,620][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,621][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,622][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 2.0 (TID 93). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,623][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 98.0 in stage 2.0 (TID 95, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 99.0 in stage 2.0 (TID 96, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,626][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 98.0 in stage 2.0 (TID 95)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,627][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 2.0 (TID 92). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,628][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 100.0 in stage 2.0 (TID 97, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,629][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 96.0 in stage 2.0 (TID 93) in 17 ms on localhost (executor driver) (87/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 88.0 in stage 2.0 (TID 85) in 67 ms on localhost (executor driver) (88/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,630][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 2.0 (TID 94). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 95.0 in stage 2.0 (TID 92) in 24 ms on localhost (executor driver) (89/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,631][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 100.0 in stage 2.0 (TID 97)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,632][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 101.0 in stage 2.0 (TID 98, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 101.0 in stage 2.0 (TID 98)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,634][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 97.0 in stage 2.0 (TID 94) in 20 ms on localhost (executor driver) (90/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 2.0 (TID 95). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,637][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 102.0 in stage 2.0 (TID 99, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,639][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 98.0 in stage 2.0 (TID 95) in 17 ms on localhost (executor driver) (91/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,640][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 102.0 in stage 2.0 (TID 99)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 2.0 (TID 97). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,642][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 99.0 in stage 2.0 (TID 96)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,645][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 103.0 in stage 2.0 (TID 100, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 100.0 in stage 2.0 (TID 97) in 20 ms on localhost (executor driver) (92/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,648][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,649][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,650][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,651][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 2.0 (TID 99). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,653][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 103.0 in stage 2.0 (TID 100)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,654][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 104.0 in stage 2.0 (TID 101, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 2.0 (TID 96). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,655][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 104.0 in stage 2.0 (TID 101)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,656][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 102.0 in stage 2.0 (TID 99) in 19 ms on localhost (executor driver) (93/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,661][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,663][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,667][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 105.0 in stage 2.0 (TID 102, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,671][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 2.0 (TID 100). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,672][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 2.0 (TID 101). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 2.0 (TID 98). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 106.0 in stage 2.0 (TID 103, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,673][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 105.0 in stage 2.0 (TID 102)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,674][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 107.0 in stage 2.0 (TID 104, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,675][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 106.0 in stage 2.0 (TID 103)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,676][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 99.0 in stage 2.0 (TID 96) in 51 ms on localhost (executor driver) (94/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,677][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 109.0 in stage 2.0 (TID 105, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,678][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 104.0 in stage 2.0 (TID 101) in 25 ms on localhost (executor driver) (95/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,679][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 109.0 in stage 2.0 (TID 105)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 103.0 in stage 2.0 (TID 100) in 36 ms on localhost (executor driver) (96/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,680][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 101.0 in stage 2.0 (TID 98) in 48 ms on localhost (executor driver) (97/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,682][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 107.0 in stage 2.0 (TID 104)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,684][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,685][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,686][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,688][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,690][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 2.0 (TID 105). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,691][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 110.0 in stage 2.0 (TID 106, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,692][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 2.0 (TID 103). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,693][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 110.0 in stage 2.0 (TID 106)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,695][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 111.0 in stage 2.0 (TID 107, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,696][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 109.0 in stage 2.0 (TID 105) in 19 ms on localhost (executor driver) (98/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 111.0 in stage 2.0 (TID 107)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 106.0 in stage 2.0 (TID 103) in 24 ms on localhost (executor driver) (99/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,697][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 2.0 (TID 102). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,699][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 112.0 in stage 2.0 (TID 108, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,700][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 112.0 in stage 2.0 (TID 108)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 105.0 in stage 2.0 (TID 102) in 31 ms on localhost (executor driver) (100/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,701][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,702][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,703][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,706][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 2.0 (TID 106). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 2.0 (TID 107). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,707][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 113.0 in stage 2.0 (TID 109, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,708][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 114.0 in stage 2.0 (TID 110, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 110.0 in stage 2.0 (TID 106) in 19 ms on localhost (executor driver) (101/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 114.0 in stage 2.0 (TID 110)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,710][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 113.0 in stage 2.0 (TID 109)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,711][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 111.0 in stage 2.0 (TID 107) in 16 ms on localhost (executor driver) (102/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,714][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 2.0 (TID 104). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,716][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,717][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 115.0 in stage 2.0 (TID 111, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 2.0 (TID 110). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 2.0 (TID 109). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,722][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 107.0 in stage 2.0 (TID 104) in 48 ms on localhost (executor driver) (103/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 117.0 in stage 2.0 (TID 112, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,724][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 119.0 in stage 2.0 (TID 113, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,726][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 113.0 in stage 2.0 (TID 109) in 19 ms on localhost (executor driver) (104/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 119.0 in stage 2.0 (TID 113)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,727][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 114.0 in stage 2.0 (TID 110) in 19 ms on localhost (executor driver) (105/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 117.0 in stage 2.0 (TID 112)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,728][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 115.0 in stage 2.0 (TID 111)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,731][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 2.0 (TID 108). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 120.0 in stage 2.0 (TID 114, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,732][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,733][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 112.0 in stage 2.0 (TID 108) in 35 ms on localhost (executor driver) (106/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 120.0 in stage 2.0 (TID 114)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,734][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,737][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 2.0 (TID 113). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,740][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 121.0 in stage 2.0 (TID 115, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 119.0 in stage 2.0 (TID 113) in 19 ms on localhost (executor driver) (107/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,743][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 121.0 in stage 2.0 (TID 115)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,746][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 2.0 (TID 112). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,747][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 122.0 in stage 2.0 (TID 116, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,749][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 117.0 in stage 2.0 (TID 112) in 26 ms on localhost (executor driver) (108/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 122.0 in stage 2.0 (TID 116)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,750][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,751][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 2.0 (TID 111). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,752][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 123.0 in stage 2.0 (TID 117, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 115.0 in stage 2.0 (TID 111) in 39 ms on localhost (executor driver) (109/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,754][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 123.0 in stage 2.0 (TID 117)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 2.0 (TID 115). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,755][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,756][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 124.0 in stage 2.0 (TID 118, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,757][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,758][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 124.0 in stage 2.0 (TID 118)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,759][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 121.0 in stage 2.0 (TID 115) in 20 ms on localhost (executor driver) (110/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 2.0 (TID 116). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,760][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,764][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 2.0 (TID 114). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,765][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 125.0 in stage 2.0 (TID 119, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,766][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,767][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 126.0 in stage 2.0 (TID 120, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,768][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 125.0 in stage 2.0 (TID 119)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,769][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 2.0 (TID 117). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,772][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 122.0 in stage 2.0 (TID 116) in 26 ms on localhost (executor driver) (111/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,773][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 2.0 (TID 118). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,775][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 127.0 in stage 2.0 (TID 121, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 128.0 in stage 2.0 (TID 122, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,777][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 120.0 in stage 2.0 (TID 114) in 45 ms on localhost (executor driver) (112/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 128.0 in stage 2.0 (TID 122)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,778][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 127.0 in stage 2.0 (TID 121)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,780][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 123.0 in stage 2.0 (TID 117) in 28 ms on localhost (executor driver) (113/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,783][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 124.0 in stage 2.0 (TID 118) in 27 ms on localhost (executor driver) (114/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,784][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,785][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 2.0 (TID 119). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,786][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 130.0 in stage 2.0 (TID 123, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 130.0 in stage 2.0 (TID 123)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 125.0 in stage 2.0 (TID 119) in 24 ms on localhost (executor driver) (115/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,788][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 2.0 (TID 122). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,789][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 131.0 in stage 2.0 (TID 124, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,791][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 131.0 in stage 2.0 (TID 124)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 128.0 in stage 2.0 (TID 122) in 15 ms on localhost (executor driver) (116/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,792][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,793][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,795][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 2.0 (TID 121). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 132.0 in stage 2.0 (TID 125, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,796][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 2.0 (TID 123). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,797][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 126.0 in stage 2.0 (TID 120)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 133.0 in stage 2.0 (TID 126, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,798][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 132.0 in stage 2.0 (TID 125)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 127.0 in stage 2.0 (TID 121) in 26 ms on localhost (executor driver) (117/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 133.0 in stage 2.0 (TID 126)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,802][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 2.0 (TID 124). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 130.0 in stage 2.0 (TID 123) in 18 ms on localhost (executor driver) (118/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,804][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,806][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 134.0 in stage 2.0 (TID 127, localhost, executor driver, partition 134, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 134.0 in stage 2.0 (TID 127)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,808][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,809][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 131.0 in stage 2.0 (TID 124) in 20 ms on localhost (executor driver) (119/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,812][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 2.0 (TID 126). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 135.0 in stage 2.0 (TID 128, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,813][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 2.0 (TID 120). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,814][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 135.0 in stage 2.0 (TID 128)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,816][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 136.0 in stage 2.0 (TID 129, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,818][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 133.0 in stage 2.0 (TID 126) in 20 ms on localhost (executor driver) (120/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 136.0 in stage 2.0 (TID 129)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 126.0 in stage 2.0 (TID 120) in 53 ms on localhost (executor driver) (121/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,820][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 2.0 (TID 125). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 2.0 (TID 127). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,822][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 137.0 in stage 2.0 (TID 130, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,823][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 138.0 in stage 2.0 (TID 131, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,824][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 132.0 in stage 2.0 (TID 125) in 29 ms on localhost (executor driver) (122/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 134.0 in stage 2.0 (TID 127) in 19 ms on localhost (executor driver) (123/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,825][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 137.0 in stage 2.0 (TID 130)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,826][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 138.0 in stage 2.0 (TID 131)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,828][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 2.0 (TID 128). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,829][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 139.0 in stage 2.0 (TID 132, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,831][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 139.0 in stage 2.0 (TID 132)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 135.0 in stage 2.0 (TID 128) in 19 ms on localhost (executor driver) (124/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,832][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,833][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 2.0 (TID 129). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 140.0 in stage 2.0 (TID 133, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,834][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,835][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 136.0 in stage 2.0 (TID 129) in 20 ms on localhost (executor driver) (125/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,836][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 2.0 (TID 130). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,837][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,838][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 141.0 in stage 2.0 (TID 134, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,841][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 141.0 in stage 2.0 (TID 134)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 137.0 in stage 2.0 (TID 130) in 20 ms on localhost (executor driver) (126/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,842][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 140.0 in stage 2.0 (TID 133)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,853][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 2.0 (TID 131). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 142.0 in stage 2.0 (TID 135, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,855][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 142.0 in stage 2.0 (TID 135)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,856][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 2.0 (TID 132). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,857][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 143.0 in stage 2.0 (TID 136, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 138.0 in stage 2.0 (TID 131) in 35 ms on localhost (executor driver) (127/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,858][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 143.0 in stage 2.0 (TID 136)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,859][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 139.0 in stage 2.0 (TID 132) in 30 ms on localhost (executor driver) (128/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,861][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,863][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,864][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,866][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,867][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 2.0 (TID 135). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 2.0 (TID 133). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,868][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 144.0 in stage 2.0 (TID 137, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 145.0 in stage 2.0 (TID 138, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,869][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 144.0 in stage 2.0 (TID 137)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 140.0 in stage 2.0 (TID 133) in 37 ms on localhost (executor driver) (129/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,871][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 145.0 in stage 2.0 (TID 138)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,873][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 142.0 in stage 2.0 (TID 135) in 19 ms on localhost (executor driver) (130/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,877][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,878][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,881][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 2.0 (TID 137). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 146.0 in stage 2.0 (TID 139, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,882][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 2.0 (TID 138). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 147.0 in stage 2.0 (TID 140, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 146.0 in stage 2.0 (TID 139)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 147.0 in stage 2.0 (TID 140)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,884][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 144.0 in stage 2.0 (TID 137) in 16 ms on localhost (executor driver) (131/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,887][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 145.0 in stage 2.0 (TID 138) in 18 ms on localhost (executor driver) (132/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,891][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,892][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,896][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 2.0 (TID 140). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,908][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,913][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 2.0 (TID 139). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 2.0 (TID 136). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 8 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,915][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 148.0 in stage 2.0 (TID 141, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,918][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 149.0 in stage 2.0 (TID 142, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,919][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 150.0 in stage 2.0 (TID 143, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,920][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 143.0 in stage 2.0 (TID 136) in 63 ms on localhost (executor driver) (133/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 2.0 (TID 134). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,921][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 147.0 in stage 2.0 (TID 140) in 38 ms on localhost (executor driver) (134/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 151.0 in stage 2.0 (TID 144, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,922][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 146.0 in stage 2.0 (TID 139) in 40 ms on localhost (executor driver) (135/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,923][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 151.0 in stage 2.0 (TID 144)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 148.0 in stage 2.0 (TID 141)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,924][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 141.0 in stage 2.0 (TID 134) in 86 ms on localhost (executor driver) (136/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,925][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 149.0 in stage 2.0 (TID 142)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,929][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,930][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,931][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,932][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,934][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 2.0 (TID 144). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,935][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 152.0 in stage 2.0 (TID 145, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,937][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 151.0 in stage 2.0 (TID 144) in 15 ms on localhost (executor driver) (137/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 2.0 (TID 141). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,938][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 152.0 in stage 2.0 (TID 145)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,940][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 153.0 in stage 2.0 (TID 146, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,941][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 148.0 in stage 2.0 (TID 141) in 26 ms on localhost (executor driver) (138/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,942][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 153.0 in stage 2.0 (TID 146)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 2.0 (TID 142). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,943][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 150.0 in stage 2.0 (TID 143)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 154.0 in stage 2.0 (TID 147, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,944][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 154.0 in stage 2.0 (TID 147)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,945][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,946][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 149.0 in stage 2.0 (TID 142) in 29 ms on localhost (executor driver) (139/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,947][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,948][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,949][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 2.0 (TID 145). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 155.0 in stage 2.0 (TID 148, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,950][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 155.0 in stage 2.0 (TID 148)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,951][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 2.0 (TID 146). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,952][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 152.0 in stage 2.0 (TID 145) in 17 ms on localhost (executor driver) (140/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,953][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,954][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 156.0 in stage 2.0 (TID 149, localhost, executor driver, partition 156, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,955][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 2.0 (TID 147). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 156.0 in stage 2.0 (TID 149)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,956][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,957][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 153.0 in stage 2.0 (TID 146) in 17 ms on localhost (executor driver) (141/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,959][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,960][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 157.0 in stage 2.0 (TID 150, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 157.0 in stage 2.0 (TID 150)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,962][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 154.0 in stage 2.0 (TID 147) in 20 ms on localhost (executor driver) (142/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,963][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 2.0 (TID 143). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,964][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 2.0 (TID 148). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,965][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 158.0 in stage 2.0 (TID 151, localhost, executor driver, partition 158, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,967][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 160.0 in stage 2.0 (TID 152, localhost, executor driver, partition 160, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,968][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 158.0 in stage 2.0 (TID 151)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,969][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 2.0 (TID 149). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,971][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 2.0 (TID 150). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 150.0 in stage 2.0 (TID 143) in 54 ms on localhost (executor driver) (143/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,972][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 160.0 in stage 2.0 (TID 152)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,973][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 161.0 in stage 2.0 (TID 153, localhost, executor driver, partition 161, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,976][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 162.0 in stage 2.0 (TID 154, localhost, executor driver, partition 162, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,977][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 161.0 in stage 2.0 (TID 153)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,978][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 162.0 in stage 2.0 (TID 154)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,983][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 2.0 (TID 151). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 155.0 in stage 2.0 (TID 148) in 29 ms on localhost (executor driver) (144/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,984][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,985][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 163.0 in stage 2.0 (TID 155, localhost, executor driver, partition 163, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,986][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,988][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 157.0 in stage 2.0 (TID 150) in 28 ms on localhost (executor driver) (145/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,989][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 163.0 in stage 2.0 (TID 155)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,992][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 156.0 in stage 2.0 (TID 149) in 38 ms on localhost (executor driver) (146/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,993][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 158.0 in stage 2.0 (TID 151) in 28 ms on localhost (executor driver) (147/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 2.0 (TID 154). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,995][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 2.0 (TID 153). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 164.0 in stage 2.0 (TID 156, localhost, executor driver, partition 164, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,996][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 2.0 (TID 152). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 165.0 in stage 2.0 (TID 157, localhost, executor driver, partition 165, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,997][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 164.0 in stage 2.0 (TID 156)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 166.0 in stage 2.0 (TID 158, localhost, executor driver, partition 166, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 165.0 in stage 2.0 (TID 157)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:46,998][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 160.0 in stage 2.0 (TID 152) in 33 ms on localhost (executor driver) (148/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,000][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 166.0 in stage 2.0 (TID 158)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,001][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 162.0 in stage 2.0 (TID 154) in 24 ms on localhost (executor driver) (149/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,004][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 161.0 in stage 2.0 (TID 153) in 32 ms on localhost (executor driver) (150/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,005][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 2.0 (TID 155). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,006][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 167.0 in stage 2.0 (TID 159, localhost, executor driver, partition 167, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,007][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,008][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 167.0 in stage 2.0 (TID 159)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,009][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 163.0 in stage 2.0 (TID 155) in 24 ms on localhost (executor driver) (151/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,010][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 2.0 (TID 157). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 168.0 in stage 2.0 (TID 160, localhost, executor driver, partition 168, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 2.0 (TID 158). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,011][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 2.0 (TID 156). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 169.0 in stage 2.0 (TID 161, localhost, executor driver, partition 169, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,012][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 168.0 in stage 2.0 (TID 160)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 170.0 in stage 2.0 (TID 162, localhost, executor driver, partition 170, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,013][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 169.0 in stage 2.0 (TID 161)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 166.0 in stage 2.0 (TID 158) in 16 ms on localhost (executor driver) (152/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 170.0 in stage 2.0 (TID 162)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,014][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,015][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 165.0 in stage 2.0 (TID 157) in 19 ms on localhost (executor driver) (153/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,016][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 164.0 in stage 2.0 (TID 156) in 21 ms on localhost (executor driver) (154/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,018][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,019][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 2.0 (TID 159). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,020][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 171.0 in stage 2.0 (TID 163, localhost, executor driver, partition 171, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,022][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 167.0 in stage 2.0 (TID 159) in 15 ms on localhost (executor driver) (155/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,024][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,028][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 2.0 (TID 160). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,029][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 172.0 in stage 2.0 (TID 164, localhost, executor driver, partition 172, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 172.0 in stage 2.0 (TID 164)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,031][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 168.0 in stage 2.0 (TID 160) in 20 ms on localhost (executor driver) (156/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,035][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,036][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 2.0 (TID 162). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,039][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 173.0 in stage 2.0 (TID 165, localhost, executor driver, partition 173, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,040][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 2.0 (TID 164). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 174.0 in stage 2.0 (TID 166, localhost, executor driver, partition 174, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 173.0 in stage 2.0 (TID 165)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 171.0 in stage 2.0 (TID 163)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,041][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 170.0 in stage 2.0 (TID 162) in 28 ms on localhost (executor driver) (157/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 174.0 in stage 2.0 (TID 166)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,042][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 2.0 (TID 161). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,045][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 172.0 in stage 2.0 (TID 164) in 15 ms on localhost (executor driver) (158/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,046][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 175.0 in stage 2.0 (TID 167, localhost, executor driver, partition 175, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,048][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,049][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 175.0 in stage 2.0 (TID 167)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,050][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 169.0 in stage 2.0 (TID 161) in 38 ms on localhost (executor driver) (159/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,052][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 2.0 (TID 163). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,055][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 2.0 (TID 165). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,056][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 2.0 (TID 166). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,057][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 176.0 in stage 2.0 (TID 168, localhost, executor driver, partition 176, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 177.0 in stage 2.0 (TID 169, localhost, executor driver, partition 177, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 178.0 in stage 2.0 (TID 170, localhost, executor driver, partition 178, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,060][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 177.0 in stage 2.0 (TID 169)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,059][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 176.0 in stage 2.0 (TID 168)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,061][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 173.0 in stage 2.0 (TID 165) in 22 ms on localhost (executor driver) (160/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 178.0 in stage 2.0 (TID 170)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,062][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 2.0 (TID 167). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,065][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 171.0 in stage 2.0 (TID 163) in 45 ms on localhost (executor driver) (161/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,067][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 179.0 in stage 2.0 (TID 171, localhost, executor driver, partition 179, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,068][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 174.0 in stage 2.0 (TID 166) in 28 ms on localhost (executor driver) (162/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,069][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 179.0 in stage 2.0 (TID 171)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,071][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,072][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 2.0 (TID 169). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,073][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 175.0 in stage 2.0 (TID 167) in 25 ms on localhost (executor driver) (163/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 180.0 in stage 2.0 (TID 172, localhost, executor driver, partition 180, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,075][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 2.0 (TID 168). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 181.0 in stage 2.0 (TID 173, localhost, executor driver, partition 181, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,076][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 180.0 in stage 2.0 (TID 172)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,077][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 181.0 in stage 2.0 (TID 173)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 2.0 (TID 170). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,078][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 176.0 in stage 2.0 (TID 168) in 21 ms on localhost (executor driver) (164/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,081][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 182.0 in stage 2.0 (TID 174, localhost, executor driver, partition 182, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,082][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 177.0 in stage 2.0 (TID 169) in 25 ms on localhost (executor driver) (165/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,083][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 182.0 in stage 2.0 (TID 174)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 2.0 (TID 171). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,084][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,086][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 178.0 in stage 2.0 (TID 170) in 27 ms on localhost (executor driver) (166/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,087][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 2.0 (TID 172). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,089][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 183.0 in stage 2.0 (TID 175, localhost, executor driver, partition 183, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,090][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 184.0 in stage 2.0 (TID 176, localhost, executor driver, partition 184, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,091][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 183.0 in stage 2.0 (TID 175)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 2.0 (TID 173). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 179.0 in stage 2.0 (TID 171) in 25 ms on localhost (executor driver) (167/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,092][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 184.0 in stage 2.0 (TID 176)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,093][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 185.0 in stage 2.0 (TID 177, localhost, executor driver, partition 185, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,094][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 180.0 in stage 2.0 (TID 172) in 20 ms on localhost (executor driver) (168/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 185.0 in stage 2.0 (TID 177)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,095][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,096][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 181.0 in stage 2.0 (TID 173) in 21 ms on localhost (executor driver) (169/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,098][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,099][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,100][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,101][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 2.0 (TID 174). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 2.0 (TID 175). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,102][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 186.0 in stage 2.0 (TID 178, localhost, executor driver, partition 186, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,103][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 2.0 (TID 176). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 187.0 in stage 2.0 (TID 179, localhost, executor driver, partition 187, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,104][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 186.0 in stage 2.0 (TID 178)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,105][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 188.0 in stage 2.0 (TID 180, localhost, executor driver, partition 188, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 182.0 in stage 2.0 (TID 174) in 25 ms on localhost (executor driver) (170/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,107][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 188.0 in stage 2.0 (TID 180)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 184.0 in stage 2.0 (TID 176) in 18 ms on localhost (executor driver) (171/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 2.0 (TID 177). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 187.0 in stage 2.0 (TID 179)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,108][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 183.0 in stage 2.0 (TID 175) in 19 ms on localhost (executor driver) (172/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,109][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 189.0 in stage 2.0 (TID 181, localhost, executor driver, partition 189, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 189.0 in stage 2.0 (TID 181)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 185.0 in stage 2.0 (TID 177) in 18 ms on localhost (executor driver) (173/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,111][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,112][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,113][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,114][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,115][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 2.0 (TID 178). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,116][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 2.0 (TID 179). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,117][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 191.0 in stage 2.0 (TID 182, localhost, executor driver, partition 191, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,118][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 193.0 in stage 2.0 (TID 183, localhost, executor driver, partition 193, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 187.0 in stage 2.0 (TID 179) in 17 ms on localhost (executor driver) (174/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,120][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 193.0 in stage 2.0 (TID 183)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 2.0 (TID 180). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 186.0 in stage 2.0 (TID 178) in 19 ms on localhost (executor driver) (175/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 2.0 (TID 181). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,121][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 191.0 in stage 2.0 (TID 182)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,122][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 194.0 in stage 2.0 (TID 184, localhost, executor driver, partition 194, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,125][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 195.0 in stage 2.0 (TID 185, localhost, executor driver, partition 195, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 188.0 in stage 2.0 (TID 180) in 22 ms on localhost (executor driver) (176/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 189.0 in stage 2.0 (TID 181) in 18 ms on localhost (executor driver) (177/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 194.0 in stage 2.0 (TID 184)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 195.0 in stage 2.0 (TID 185)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,127][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,128][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,132][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 2.0 (TID 183). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 5 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 196.0 in stage 2.0 (TID 186, localhost, executor driver, partition 196, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,133][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,134][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 196.0 in stage 2.0 (TID 186)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,135][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 193.0 in stage 2.0 (TID 183) in 17 ms on localhost (executor driver) (178/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 2.0 (TID 185). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 2.0 (TID 182). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 2.0 (TID 184). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,138][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 197.0 in stage 2.0 (TID 187, localhost, executor driver, partition 197, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 198.0 in stage 2.0 (TID 188, localhost, executor driver, partition 198, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,140][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 199.0 in stage 2.0 (TID 189, localhost, executor driver, partition 199, PROCESS_LOCAL, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 197.0 in stage 2.0 (TID 187)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,141][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 198.0 in stage 2.0 (TID 188)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 194.0 in stage 2.0 (TID 184) in 21 ms on localhost (executor driver) (179/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,143][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 199.0 in stage 2.0 (TID 189)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,148][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,151][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 191.0 in stage 2.0 (TID 182) in 34 ms on localhost (executor driver) (180/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,152][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 2.0 (TID 186). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,154][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,155][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 195.0 in stage 2.0 (TID 185) in 30 ms on localhost (executor driver) (181/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,156][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,158][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,159][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 0.0 in stage 2.0 (TID 190, localhost, executor driver, partition 0, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,161][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,163][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 196.0 in stage 2.0 (TID 186) in 30 ms on localhost (executor driver) (182/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 2.0 (TID 187). 4271 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,166][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 2.0 (TID 189). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,167][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 19.0 in stage 2.0 (TID 191, localhost, executor driver, partition 19, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 30.0 in stage 2.0 (TID 192, localhost, executor driver, partition 30, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,169][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 19.0 in stage 2.0 (TID 191)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 197.0 in stage 2.0 (TID 187) in 33 ms on localhost (executor driver) (183/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,171][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 0.0 in stage 2.0 (TID 190)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,172][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 2.0 (TID 188). 4228 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,173][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 199.0 in stage 2.0 (TID 189) in 33 ms on localhost (executor driver) (184/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,174][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 30.0 in stage 2.0 (TID 192)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 46.0 in stage 2.0 (TID 193, localhost, executor driver, partition 46, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,177][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,179][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,181][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 198.0 in stage 2.0 (TID 188) in 42 ms on localhost (executor driver) (185/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 6 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 46.0 in stage 2.0 (TID 193)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,182][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 3 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,183][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,184][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,190][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 2.0 (TID 190). 4497 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,310][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 2.0 (TID 192). 4497 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,311][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 2.0 (TID 193). 4454 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 2.0 (TID 191). 4497 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,312][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 56.0 in stage 2.0 (TID 194, localhost, executor driver, partition 56, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,314][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 66.0 in stage 2.0 (TID 195, localhost, executor driver, partition 66, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 67.0 in stage 2.0 (TID 196, localhost, executor driver, partition 67, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,316][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 72.0 in stage 2.0 (TID 197, localhost, executor driver, partition 72, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,318][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 0.0 in stage 2.0 (TID 190) in 160 ms on localhost (executor driver) (186/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 66.0 in stage 2.0 (TID 195)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 72.0 in stage 2.0 (TID 197)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 46.0 in stage 2.0 (TID 193) in 142 ms on localhost (executor driver) (187/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 67.0 in stage 2.0 (TID 196)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,319][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 56.0 in stage 2.0 (TID 194)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,320][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 19.0 in stage 2.0 (TID 191) in 153 ms on localhost (executor driver) (188/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,323][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,324][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 30.0 in stage 2.0 (TID 192) in 156 ms on localhost (executor driver) (189/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,325][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,327][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,328][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,329][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 2.0 (TID 197). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,335][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 2.0 (TID 195). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,336][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 108.0 in stage 2.0 (TID 198, localhost, executor driver, partition 108, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 108.0 in stage 2.0 (TID 198)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,337][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 116.0 in stage 2.0 (TID 199, localhost, executor driver, partition 116, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 116.0 in stage 2.0 (TID 199)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,339][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 66.0 in stage 2.0 (TID 195) in 25 ms on localhost (executor driver) (190/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,340][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 72.0 in stage 2.0 (TID 197) in 24 ms on localhost (executor driver) (191/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 2.0 (TID 194). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,350][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 118.0 in stage 2.0 (TID 200, localhost, executor driver, partition 118, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,351][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,352][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 56.0 in stage 2.0 (TID 194) in 42 ms on localhost (executor driver) (192/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,354][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 118.0 in stage 2.0 (TID 200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,356][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 2.0 (TID 196). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,357][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 129.0 in stage 2.0 (TID 201, localhost, executor driver, partition 129, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,358][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 129.0 in stage 2.0 (TID 201)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,359][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 67.0 in stage 2.0 (TID 196) in 44 ms on localhost (executor driver) (193/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,364][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 2.0 (TID 199). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 2.0 (TID 198). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 159.0 in stage 2.0 (TID 202, localhost, executor driver, partition 159, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,365][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 190.0 in stage 2.0 (TID 203, localhost, executor driver, partition 190, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 159.0 in stage 2.0 (TID 202)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,366][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 116.0 in stage 2.0 (TID 199) in 30 ms on localhost (executor driver) (194/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 190.0 in stage 2.0 (TID 203)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,367][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 2 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,369][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 108.0 in stage 2.0 (TID 198) in 33 ms on localhost (executor driver) (195/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,371][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,372][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 1 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,373][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,377][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 2.0 (TID 201). 4454 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,378][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Starting task 192.0 in stage 2.0 (TID 204, localhost, executor driver, partition 192, ANY, 7767 bytes)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,379][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Running task 192.0 in stage 2.0 (TID 204)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 129.0 in stage 2.0 (TID 201) in 23 ms on localhost (executor driver) (196/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 2.0 (TID 202). 4454 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,380][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 2.0 (TID 200). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,383][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 159.0 in stage 2.0 (TID 202) in 19 ms on localhost (executor driver) (197/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 118.0 in stage 2.0 (TID 200) in 32 ms on localhost (executor driver) (198/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,384][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Started 0 remote fetches in 0 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,385][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 2.0 (TID 203). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,387][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 190.0 in stage 2.0 (TID 203) in 21 ms on localhost (executor driver) (199/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,393][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 2.0 (TID 204). 4411 bytes result sent to driver
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Finished task 192.0 in stage 2.0 (TID 204) in 17 ms on localhost (executor driver) (200/200)
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,395][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Removed TaskSet 2.0, whose tasks have all completed, from pool 
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,396][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | ResultStage 2 (show at SparkSQL.scala:55) finished in 1,454 s
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,397][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Job 1 finished: show at SparkSQL.scala:55, took 1,894935 s
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,412][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Code generated in 11.937985 ms
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,420][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Invoking stop() from shutdown hook
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,456][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Stopped Spark web UI at http://mac-180:4040
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,469][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MapOutputTrackerMasterEndpoint stopped!
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | MemoryStore cleared
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,537][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManager stopped
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,540][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | BlockManagerMaster stopped
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,542][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | OutputCommitCoordinator stopped!
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,556][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Successfully stopped SparkContext
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,557][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Shutdown hook called
[34m[INFO ][0;39m [35m[2019-05-02 15:41:47,558][0;39m [33m[][0;39m [35m[org.apache.spark.internal.Logging$class->logInfo][0;39m | Deleting directory /private/var/folders/fd/s_6smjqn7mngnfdw8rz9t4w00000gp/T/spark-e916ff8a-57fd-4d15-b6ed-fbe39d509ae7
